{
  "best_global_step": 2364,
  "best_metric": 0.9779629629629629,
  "best_model_checkpoint": "VPC3_TP_EutoSat_Vit/models/tiny/checkpoint-2364",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2364,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008460236886632826,
      "grad_norm": 14.466089248657227,
      "learning_rate": 4.9974619289340105e-05,
      "loss": 1.9739,
      "step": 10
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 20.900371551513672,
      "learning_rate": 4.994641849971799e-05,
      "loss": 1.1346,
      "step": 20
    },
    {
      "epoch": 0.025380710659898477,
      "grad_norm": 14.140461921691895,
      "learning_rate": 4.991821771009588e-05,
      "loss": 0.6714,
      "step": 30
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 14.910873413085938,
      "learning_rate": 4.9890016920473776e-05,
      "loss": 0.4596,
      "step": 40
    },
    {
      "epoch": 0.04230118443316413,
      "grad_norm": 35.95499801635742,
      "learning_rate": 4.986181613085167e-05,
      "loss": 0.4352,
      "step": 50
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 10.581116676330566,
      "learning_rate": 4.983361534122956e-05,
      "loss": 0.319,
      "step": 60
    },
    {
      "epoch": 0.05922165820642978,
      "grad_norm": 11.34449291229248,
      "learning_rate": 4.9805414551607446e-05,
      "loss": 0.2842,
      "step": 70
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 7.4420576095581055,
      "learning_rate": 4.9777213761985334e-05,
      "loss": 0.2789,
      "step": 80
    },
    {
      "epoch": 0.07614213197969544,
      "grad_norm": 21.182126998901367,
      "learning_rate": 4.974901297236323e-05,
      "loss": 0.2123,
      "step": 90
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 11.74959659576416,
      "learning_rate": 4.972081218274112e-05,
      "loss": 0.2109,
      "step": 100
    },
    {
      "epoch": 0.09306260575296109,
      "grad_norm": 24.90926170349121,
      "learning_rate": 4.969261139311901e-05,
      "loss": 0.1604,
      "step": 110
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.184607982635498,
      "learning_rate": 4.96644106034969e-05,
      "loss": 0.3748,
      "step": 120
    },
    {
      "epoch": 0.10998307952622674,
      "grad_norm": 12.008848190307617,
      "learning_rate": 4.963620981387479e-05,
      "loss": 0.1721,
      "step": 130
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 10.822035789489746,
      "learning_rate": 4.960800902425268e-05,
      "loss": 0.1741,
      "step": 140
    },
    {
      "epoch": 0.12690355329949238,
      "grad_norm": 3.1626784801483154,
      "learning_rate": 4.957980823463057e-05,
      "loss": 0.1298,
      "step": 150
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 6.791316032409668,
      "learning_rate": 4.9551607445008465e-05,
      "loss": 0.1967,
      "step": 160
    },
    {
      "epoch": 0.14382402707275804,
      "grad_norm": 4.2050347328186035,
      "learning_rate": 4.952340665538635e-05,
      "loss": 0.1122,
      "step": 170
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 11.0927095413208,
      "learning_rate": 4.949520586576424e-05,
      "loss": 0.1621,
      "step": 180
    },
    {
      "epoch": 0.16074450084602368,
      "grad_norm": 25.3814697265625,
      "learning_rate": 4.9467005076142136e-05,
      "loss": 0.374,
      "step": 190
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 2.0944905281066895,
      "learning_rate": 4.9438804286520024e-05,
      "loss": 0.1641,
      "step": 200
    },
    {
      "epoch": 0.17766497461928935,
      "grad_norm": 14.078400611877441,
      "learning_rate": 4.941060349689792e-05,
      "loss": 0.2302,
      "step": 210
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 13.332756996154785,
      "learning_rate": 4.9382402707275806e-05,
      "loss": 0.2209,
      "step": 220
    },
    {
      "epoch": 0.19458544839255498,
      "grad_norm": 1.499985694885254,
      "learning_rate": 4.9354201917653694e-05,
      "loss": 0.3221,
      "step": 230
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 1.4748750925064087,
      "learning_rate": 4.932600112803158e-05,
      "loss": 0.1699,
      "step": 240
    },
    {
      "epoch": 0.21150592216582065,
      "grad_norm": 28.762161254882812,
      "learning_rate": 4.929780033840948e-05,
      "loss": 0.1859,
      "step": 250
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 21.489336013793945,
      "learning_rate": 4.926959954878737e-05,
      "loss": 0.0832,
      "step": 260
    },
    {
      "epoch": 0.22842639593908629,
      "grad_norm": 1.1055177450180054,
      "learning_rate": 4.924139875916526e-05,
      "loss": 0.1289,
      "step": 270
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 22.156885147094727,
      "learning_rate": 4.921319796954315e-05,
      "loss": 0.1383,
      "step": 280
    },
    {
      "epoch": 0.24534686971235195,
      "grad_norm": 13.688899040222168,
      "learning_rate": 4.9184997179921036e-05,
      "loss": 0.1253,
      "step": 290
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 2.1891090869903564,
      "learning_rate": 4.915679639029893e-05,
      "loss": 0.1817,
      "step": 300
    },
    {
      "epoch": 0.2622673434856176,
      "grad_norm": 29.75678253173828,
      "learning_rate": 4.912859560067682e-05,
      "loss": 0.1101,
      "step": 310
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 19.95785140991211,
      "learning_rate": 4.910039481105471e-05,
      "loss": 0.1785,
      "step": 320
    },
    {
      "epoch": 0.27918781725888325,
      "grad_norm": 4.945294380187988,
      "learning_rate": 4.907219402143261e-05,
      "loss": 0.2358,
      "step": 330
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 26.60957145690918,
      "learning_rate": 4.904399323181049e-05,
      "loss": 0.1177,
      "step": 340
    },
    {
      "epoch": 0.2961082910321489,
      "grad_norm": 44.35723876953125,
      "learning_rate": 4.9015792442188384e-05,
      "loss": 0.1052,
      "step": 350
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.2594661712646484,
      "learning_rate": 4.898759165256627e-05,
      "loss": 0.1825,
      "step": 360
    },
    {
      "epoch": 0.3130287648054145,
      "grad_norm": 1.4883270263671875,
      "learning_rate": 4.8959390862944167e-05,
      "loss": 0.1231,
      "step": 370
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 17.421049118041992,
      "learning_rate": 4.8931190073322055e-05,
      "loss": 0.1644,
      "step": 380
    },
    {
      "epoch": 0.3299492385786802,
      "grad_norm": 16.858835220336914,
      "learning_rate": 4.890298928369995e-05,
      "loss": 0.1424,
      "step": 390
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 14.830533027648926,
      "learning_rate": 4.887478849407784e-05,
      "loss": 0.1687,
      "step": 400
    },
    {
      "epoch": 0.34686971235194586,
      "grad_norm": 2.4005239009857178,
      "learning_rate": 4.8846587704455725e-05,
      "loss": 0.1471,
      "step": 410
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.5430868268013,
      "learning_rate": 4.881838691483362e-05,
      "loss": 0.1136,
      "step": 420
    },
    {
      "epoch": 0.3637901861252115,
      "grad_norm": 0.6713274717330933,
      "learning_rate": 4.879018612521151e-05,
      "loss": 0.3007,
      "step": 430
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.46859073638916,
      "learning_rate": 4.87619853355894e-05,
      "loss": 0.0564,
      "step": 440
    },
    {
      "epoch": 0.38071065989847713,
      "grad_norm": 0.944525957107544,
      "learning_rate": 4.8733784545967284e-05,
      "loss": 0.1091,
      "step": 450
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.24216057360172272,
      "learning_rate": 4.870558375634518e-05,
      "loss": 0.0261,
      "step": 460
    },
    {
      "epoch": 0.3976311336717428,
      "grad_norm": 17.511394500732422,
      "learning_rate": 4.867738296672307e-05,
      "loss": 0.1677,
      "step": 470
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 13.479783058166504,
      "learning_rate": 4.864918217710096e-05,
      "loss": 0.2508,
      "step": 480
    },
    {
      "epoch": 0.41455160744500846,
      "grad_norm": 19.93234634399414,
      "learning_rate": 4.8620981387478856e-05,
      "loss": 0.0422,
      "step": 490
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 4.957183837890625,
      "learning_rate": 4.8592780597856744e-05,
      "loss": 0.0953,
      "step": 500
    },
    {
      "epoch": 0.43147208121827413,
      "grad_norm": 2.8080811500549316,
      "learning_rate": 4.856457980823463e-05,
      "loss": 0.0667,
      "step": 510
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 26.37185287475586,
      "learning_rate": 4.853637901861252e-05,
      "loss": 0.2009,
      "step": 520
    },
    {
      "epoch": 0.44839255499153974,
      "grad_norm": 1.484768033027649,
      "learning_rate": 4.8508178228990415e-05,
      "loss": 0.038,
      "step": 530
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 20.85687255859375,
      "learning_rate": 4.847997743936831e-05,
      "loss": 0.1368,
      "step": 540
    },
    {
      "epoch": 0.4653130287648054,
      "grad_norm": 2.726987361907959,
      "learning_rate": 4.84517766497462e-05,
      "loss": 0.1399,
      "step": 550
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 15.755430221557617,
      "learning_rate": 4.8423575860124085e-05,
      "loss": 0.0465,
      "step": 560
    },
    {
      "epoch": 0.48223350253807107,
      "grad_norm": 28.094520568847656,
      "learning_rate": 4.839537507050197e-05,
      "loss": 0.199,
      "step": 570
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 0.03665974736213684,
      "learning_rate": 4.836717428087987e-05,
      "loss": 0.1026,
      "step": 580
    },
    {
      "epoch": 0.49915397631133673,
      "grad_norm": 0.3312017023563385,
      "learning_rate": 4.8338973491257756e-05,
      "loss": 0.204,
      "step": 590
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 0.2591623365879059,
      "learning_rate": 4.831077270163565e-05,
      "loss": 0.1357,
      "step": 600
    },
    {
      "epoch": 0.5160744500846024,
      "grad_norm": 23.12666130065918,
      "learning_rate": 4.828257191201354e-05,
      "loss": 0.114,
      "step": 610
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.457749366760254,
      "learning_rate": 4.825437112239143e-05,
      "loss": 0.0955,
      "step": 620
    },
    {
      "epoch": 0.5329949238578681,
      "grad_norm": 19.274295806884766,
      "learning_rate": 4.822617033276932e-05,
      "loss": 0.318,
      "step": 630
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 22.72943115234375,
      "learning_rate": 4.819796954314721e-05,
      "loss": 0.146,
      "step": 640
    },
    {
      "epoch": 0.5499153976311336,
      "grad_norm": 6.262524604797363,
      "learning_rate": 4.8169768753525104e-05,
      "loss": 0.1691,
      "step": 650
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 20.436107635498047,
      "learning_rate": 4.814156796390299e-05,
      "loss": 0.1831,
      "step": 660
    },
    {
      "epoch": 0.5668358714043993,
      "grad_norm": 13.359298706054688,
      "learning_rate": 4.811336717428088e-05,
      "loss": 0.0537,
      "step": 670
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 7.079187393188477,
      "learning_rate": 4.8085166384658775e-05,
      "loss": 0.0709,
      "step": 680
    },
    {
      "epoch": 0.583756345177665,
      "grad_norm": 0.7319515347480774,
      "learning_rate": 4.805696559503666e-05,
      "loss": 0.1109,
      "step": 690
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 23.68626594543457,
      "learning_rate": 4.802876480541456e-05,
      "loss": 0.0784,
      "step": 700
    },
    {
      "epoch": 0.6006768189509306,
      "grad_norm": 0.6795468926429749,
      "learning_rate": 4.8000564015792445e-05,
      "loss": 0.1495,
      "step": 710
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 0.15101884305477142,
      "learning_rate": 4.7972363226170333e-05,
      "loss": 0.1307,
      "step": 720
    },
    {
      "epoch": 0.6175972927241963,
      "grad_norm": 10.494664192199707,
      "learning_rate": 4.794416243654822e-05,
      "loss": 0.1626,
      "step": 730
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 18.630586624145508,
      "learning_rate": 4.7915961646926116e-05,
      "loss": 0.1586,
      "step": 740
    },
    {
      "epoch": 0.6345177664974619,
      "grad_norm": 0.2620302140712738,
      "learning_rate": 4.788776085730401e-05,
      "loss": 0.0755,
      "step": 750
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 0.09258006513118744,
      "learning_rate": 4.78595600676819e-05,
      "loss": 0.1077,
      "step": 760
    },
    {
      "epoch": 0.6514382402707276,
      "grad_norm": 0.4374638497829437,
      "learning_rate": 4.783135927805979e-05,
      "loss": 0.1392,
      "step": 770
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.67353755235672,
      "learning_rate": 4.7803158488437675e-05,
      "loss": 0.0857,
      "step": 780
    },
    {
      "epoch": 0.6683587140439933,
      "grad_norm": 19.41292381286621,
      "learning_rate": 4.777495769881557e-05,
      "loss": 0.1199,
      "step": 790
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.23480162024497986,
      "learning_rate": 4.774675690919346e-05,
      "loss": 0.0371,
      "step": 800
    },
    {
      "epoch": 0.6852791878172588,
      "grad_norm": 0.12986932694911957,
      "learning_rate": 4.771855611957135e-05,
      "loss": 0.2893,
      "step": 810
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 1.1319631338119507,
      "learning_rate": 4.769035532994924e-05,
      "loss": 0.0735,
      "step": 820
    },
    {
      "epoch": 0.7021996615905245,
      "grad_norm": 9.579446792602539,
      "learning_rate": 4.766215454032713e-05,
      "loss": 0.1398,
      "step": 830
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 33.17691421508789,
      "learning_rate": 4.763395375070502e-05,
      "loss": 0.1564,
      "step": 840
    },
    {
      "epoch": 0.7191201353637902,
      "grad_norm": 7.179660797119141,
      "learning_rate": 4.760575296108291e-05,
      "loss": 0.1506,
      "step": 850
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 4.116767883300781,
      "learning_rate": 4.7577552171460806e-05,
      "loss": 0.0688,
      "step": 860
    },
    {
      "epoch": 0.7360406091370558,
      "grad_norm": 14.570455551147461,
      "learning_rate": 4.7549351381838694e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 0.619854748249054,
      "learning_rate": 4.752115059221658e-05,
      "loss": 0.1513,
      "step": 880
    },
    {
      "epoch": 0.7529610829103215,
      "grad_norm": 5.441271781921387,
      "learning_rate": 4.7492949802594476e-05,
      "loss": 0.261,
      "step": 890
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 2.6095757484436035,
      "learning_rate": 4.7464749012972364e-05,
      "loss": 0.0479,
      "step": 900
    },
    {
      "epoch": 0.7698815566835872,
      "grad_norm": 18.807838439941406,
      "learning_rate": 4.743654822335026e-05,
      "loss": 0.0865,
      "step": 910
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 19.832582473754883,
      "learning_rate": 4.740834743372815e-05,
      "loss": 0.2682,
      "step": 920
    },
    {
      "epoch": 0.7868020304568528,
      "grad_norm": 23.313390731811523,
      "learning_rate": 4.7380146644106035e-05,
      "loss": 0.1621,
      "step": 930
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 2.7553422451019287,
      "learning_rate": 4.735194585448392e-05,
      "loss": 0.1222,
      "step": 940
    },
    {
      "epoch": 0.8037225042301185,
      "grad_norm": 0.5432969331741333,
      "learning_rate": 4.732374506486182e-05,
      "loss": 0.083,
      "step": 950
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 11.276805877685547,
      "learning_rate": 4.729554427523971e-05,
      "loss": 0.0629,
      "step": 960
    },
    {
      "epoch": 0.8206429780033841,
      "grad_norm": 5.896979331970215,
      "learning_rate": 4.72673434856176e-05,
      "loss": 0.1201,
      "step": 970
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 16.9703426361084,
      "learning_rate": 4.7239142695995495e-05,
      "loss": 0.121,
      "step": 980
    },
    {
      "epoch": 0.8375634517766497,
      "grad_norm": 0.12442143261432648,
      "learning_rate": 4.7210941906373376e-05,
      "loss": 0.1755,
      "step": 990
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 0.058043692260980606,
      "learning_rate": 4.718274111675127e-05,
      "loss": 0.1251,
      "step": 1000
    },
    {
      "epoch": 0.8544839255499154,
      "grad_norm": 42.14734649658203,
      "learning_rate": 4.715454032712916e-05,
      "loss": 0.1367,
      "step": 1010
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 26.698923110961914,
      "learning_rate": 4.7126339537507054e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.871404399323181,
      "grad_norm": 3.701037645339966,
      "learning_rate": 4.709813874788495e-05,
      "loss": 0.2048,
      "step": 1030
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 12.624013900756836,
      "learning_rate": 4.706993795826283e-05,
      "loss": 0.1073,
      "step": 1040
    },
    {
      "epoch": 0.8883248730964467,
      "grad_norm": 30.081945419311523,
      "learning_rate": 4.7041737168640724e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 24.828798294067383,
      "learning_rate": 4.701353637901861e-05,
      "loss": 0.087,
      "step": 1060
    },
    {
      "epoch": 0.9052453468697124,
      "grad_norm": 27.589454650878906,
      "learning_rate": 4.698533558939651e-05,
      "loss": 0.0654,
      "step": 1070
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.207147598266602,
      "learning_rate": 4.6957134799774395e-05,
      "loss": 0.0868,
      "step": 1080
    },
    {
      "epoch": 0.922165820642978,
      "grad_norm": 1.1621407270431519,
      "learning_rate": 4.692893401015229e-05,
      "loss": 0.0359,
      "step": 1090
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 42.396610260009766,
      "learning_rate": 4.690073322053018e-05,
      "loss": 0.1143,
      "step": 1100
    },
    {
      "epoch": 0.9390862944162437,
      "grad_norm": 21.23570442199707,
      "learning_rate": 4.6872532430908066e-05,
      "loss": 0.1539,
      "step": 1110
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.07133467495441437,
      "learning_rate": 4.684433164128596e-05,
      "loss": 0.0776,
      "step": 1120
    },
    {
      "epoch": 0.9560067681895094,
      "grad_norm": 1.5074037313461304,
      "learning_rate": 4.681613085166385e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 18.812101364135742,
      "learning_rate": 4.678793006204174e-05,
      "loss": 0.0749,
      "step": 1140
    },
    {
      "epoch": 0.9729272419627749,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.675972927241963e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.9813874788494078,
      "grad_norm": 2.271929979324341,
      "learning_rate": 4.673152848279752e-05,
      "loss": 0.1919,
      "step": 1160
    },
    {
      "epoch": 0.9898477157360406,
      "grad_norm": 5.057013034820557,
      "learning_rate": 4.6703327693175414e-05,
      "loss": 0.0771,
      "step": 1170
    },
    {
      "epoch": 0.9983079526226735,
      "grad_norm": 10.19404411315918,
      "learning_rate": 4.66751269035533e-05,
      "loss": 0.0594,
      "step": 1180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9690740740740741,
      "eval_loss": 0.11386065185070038,
      "eval_runtime": 246.4452,
      "eval_samples_per_second": 21.912,
      "eval_steps_per_second": 2.739,
      "step": 1182
    },
    {
      "epoch": 1.0067681895093064,
      "grad_norm": 0.0524885393679142,
      "learning_rate": 4.6646926113931197e-05,
      "loss": 0.1154,
      "step": 1190
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 0.2056097388267517,
      "learning_rate": 4.6618725324309085e-05,
      "loss": 0.0667,
      "step": 1200
    },
    {
      "epoch": 1.023688663282572,
      "grad_norm": 0.31934717297554016,
      "learning_rate": 4.659052453468697e-05,
      "loss": 0.0517,
      "step": 1210
    },
    {
      "epoch": 1.0321489001692048,
      "grad_norm": 0.44508466124534607,
      "learning_rate": 4.656232374506486e-05,
      "loss": 0.0806,
      "step": 1220
    },
    {
      "epoch": 1.0406091370558375,
      "grad_norm": 17.873205184936523,
      "learning_rate": 4.6534122955442755e-05,
      "loss": 0.1168,
      "step": 1230
    },
    {
      "epoch": 1.0490693739424704,
      "grad_norm": 0.1031579002737999,
      "learning_rate": 4.650592216582065e-05,
      "loss": 0.0885,
      "step": 1240
    },
    {
      "epoch": 1.0575296108291032,
      "grad_norm": 1.859145998954773,
      "learning_rate": 4.647772137619854e-05,
      "loss": 0.0546,
      "step": 1250
    },
    {
      "epoch": 1.0659898477157361,
      "grad_norm": 2.6971371173858643,
      "learning_rate": 4.6449520586576426e-05,
      "loss": 0.0586,
      "step": 1260
    },
    {
      "epoch": 1.0744500846023688,
      "grad_norm": 3.4226748943328857,
      "learning_rate": 4.6421319796954314e-05,
      "loss": 0.1291,
      "step": 1270
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.06498179584741592,
      "learning_rate": 4.639311900733221e-05,
      "loss": 0.0912,
      "step": 1280
    },
    {
      "epoch": 1.0913705583756346,
      "grad_norm": 2.8320469856262207,
      "learning_rate": 4.6364918217710097e-05,
      "loss": 0.0783,
      "step": 1290
    },
    {
      "epoch": 1.0998307952622675,
      "grad_norm": 0.09660017490386963,
      "learning_rate": 4.633671742808799e-05,
      "loss": 0.0907,
      "step": 1300
    },
    {
      "epoch": 1.1082910321489001,
      "grad_norm": 0.13180534541606903,
      "learning_rate": 4.630851663846588e-05,
      "loss": 0.0413,
      "step": 1310
    },
    {
      "epoch": 1.116751269035533,
      "grad_norm": 0.16015172004699707,
      "learning_rate": 4.628031584884377e-05,
      "loss": 0.0407,
      "step": 1320
    },
    {
      "epoch": 1.125211505922166,
      "grad_norm": 9.34089469909668,
      "learning_rate": 4.625211505922166e-05,
      "loss": 0.1045,
      "step": 1330
    },
    {
      "epoch": 1.1336717428087986,
      "grad_norm": 24.051116943359375,
      "learning_rate": 4.622391426959955e-05,
      "loss": 0.0467,
      "step": 1340
    },
    {
      "epoch": 1.1421319796954315,
      "grad_norm": 9.480792045593262,
      "learning_rate": 4.6195713479977445e-05,
      "loss": 0.1429,
      "step": 1350
    },
    {
      "epoch": 1.1505922165820643,
      "grad_norm": 0.2971787750720978,
      "learning_rate": 4.616751269035533e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 1.1590524534686972,
      "grad_norm": 1.4138188362121582,
      "learning_rate": 4.613931190073322e-05,
      "loss": 0.0279,
      "step": 1370
    },
    {
      "epoch": 1.16751269035533,
      "grad_norm": 26.05870246887207,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0514,
      "step": 1380
    },
    {
      "epoch": 1.1759729272419628,
      "grad_norm": 0.014784063212573528,
      "learning_rate": 4.6082910321489e-05,
      "loss": 0.0145,
      "step": 1390
    },
    {
      "epoch": 1.1844331641285957,
      "grad_norm": 3.2919983863830566,
      "learning_rate": 4.60547095318669e-05,
      "loss": 0.0022,
      "step": 1400
    },
    {
      "epoch": 1.1928934010152283,
      "grad_norm": 20.8558349609375,
      "learning_rate": 4.6026508742244786e-05,
      "loss": 0.1509,
      "step": 1410
    },
    {
      "epoch": 1.2013536379018612,
      "grad_norm": 1.2578448057174683,
      "learning_rate": 4.5998307952622674e-05,
      "loss": 0.0209,
      "step": 1420
    },
    {
      "epoch": 1.2098138747884941,
      "grad_norm": 20.923458099365234,
      "learning_rate": 4.597010716300056e-05,
      "loss": 0.0547,
      "step": 1430
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 0.0193844735622406,
      "learning_rate": 4.594190637337846e-05,
      "loss": 0.178,
      "step": 1440
    },
    {
      "epoch": 1.2267343485617597,
      "grad_norm": 0.34279999136924744,
      "learning_rate": 4.591370558375635e-05,
      "loss": 0.0055,
      "step": 1450
    },
    {
      "epoch": 1.2351945854483926,
      "grad_norm": 0.713297963142395,
      "learning_rate": 4.588550479413424e-05,
      "loss": 0.0185,
      "step": 1460
    },
    {
      "epoch": 1.2436548223350254,
      "grad_norm": 0.06155781447887421,
      "learning_rate": 4.585730400451213e-05,
      "loss": 0.0267,
      "step": 1470
    },
    {
      "epoch": 1.252115059221658,
      "grad_norm": 15.050272941589355,
      "learning_rate": 4.5829103214890015e-05,
      "loss": 0.1215,
      "step": 1480
    },
    {
      "epoch": 1.260575296108291,
      "grad_norm": 2.018648386001587,
      "learning_rate": 4.580090242526791e-05,
      "loss": 0.0928,
      "step": 1490
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 26.905744552612305,
      "learning_rate": 4.57727016356458e-05,
      "loss": 0.0494,
      "step": 1500
    },
    {
      "epoch": 1.2774957698815568,
      "grad_norm": 0.08350187540054321,
      "learning_rate": 4.574450084602369e-05,
      "loss": 0.0409,
      "step": 1510
    },
    {
      "epoch": 1.2859560067681894,
      "grad_norm": 0.1177479475736618,
      "learning_rate": 4.571630005640159e-05,
      "loss": 0.1218,
      "step": 1520
    },
    {
      "epoch": 1.2944162436548223,
      "grad_norm": 14.32288932800293,
      "learning_rate": 4.568809926677947e-05,
      "loss": 0.1414,
      "step": 1530
    },
    {
      "epoch": 1.3028764805414552,
      "grad_norm": 0.8191991448402405,
      "learning_rate": 4.5659898477157363e-05,
      "loss": 0.0487,
      "step": 1540
    },
    {
      "epoch": 1.3113367174280879,
      "grad_norm": 1.2151057720184326,
      "learning_rate": 4.563169768753525e-05,
      "loss": 0.0101,
      "step": 1550
    },
    {
      "epoch": 1.3197969543147208,
      "grad_norm": 22.795188903808594,
      "learning_rate": 4.5603496897913146e-05,
      "loss": 0.056,
      "step": 1560
    },
    {
      "epoch": 1.3282571912013537,
      "grad_norm": 24.174396514892578,
      "learning_rate": 4.5575296108291034e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 1.3367174280879865,
      "grad_norm": 20.76497459411621,
      "learning_rate": 4.554709531866892e-05,
      "loss": 0.2546,
      "step": 1580
    },
    {
      "epoch": 1.3451776649746192,
      "grad_norm": 44.310550689697266,
      "learning_rate": 4.551889452904681e-05,
      "loss": 0.1427,
      "step": 1590
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 0.04374610632658005,
      "learning_rate": 4.5490693739424705e-05,
      "loss": 0.1959,
      "step": 1600
    },
    {
      "epoch": 1.362098138747885,
      "grad_norm": 6.750633716583252,
      "learning_rate": 4.54624929498026e-05,
      "loss": 0.0342,
      "step": 1610
    },
    {
      "epoch": 1.3705583756345177,
      "grad_norm": 0.28728750348091125,
      "learning_rate": 4.543429216018049e-05,
      "loss": 0.0333,
      "step": 1620
    },
    {
      "epoch": 1.3790186125211505,
      "grad_norm": 1.095624566078186,
      "learning_rate": 4.540609137055838e-05,
      "loss": 0.055,
      "step": 1630
    },
    {
      "epoch": 1.3874788494077834,
      "grad_norm": 0.1793481707572937,
      "learning_rate": 4.5377890580936263e-05,
      "loss": 0.0789,
      "step": 1640
    },
    {
      "epoch": 1.3959390862944163,
      "grad_norm": 0.10460668057203293,
      "learning_rate": 4.534968979131416e-05,
      "loss": 0.1204,
      "step": 1650
    },
    {
      "epoch": 1.404399323181049,
      "grad_norm": 0.17484290897846222,
      "learning_rate": 4.5321489001692046e-05,
      "loss": 0.0569,
      "step": 1660
    },
    {
      "epoch": 1.4128595600676819,
      "grad_norm": 2.5536487102508545,
      "learning_rate": 4.529328821206994e-05,
      "loss": 0.0966,
      "step": 1670
    },
    {
      "epoch": 1.4213197969543148,
      "grad_norm": 0.033308885991573334,
      "learning_rate": 4.5265087422447836e-05,
      "loss": 0.0455,
      "step": 1680
    },
    {
      "epoch": 1.4297800338409474,
      "grad_norm": 0.03772977367043495,
      "learning_rate": 4.523688663282572e-05,
      "loss": 0.1548,
      "step": 1690
    },
    {
      "epoch": 1.4382402707275803,
      "grad_norm": 0.09216587990522385,
      "learning_rate": 4.520868584320361e-05,
      "loss": 0.05,
      "step": 1700
    },
    {
      "epoch": 1.4467005076142132,
      "grad_norm": 0.03644145280122757,
      "learning_rate": 4.51804850535815e-05,
      "loss": 0.0294,
      "step": 1710
    },
    {
      "epoch": 1.455160744500846,
      "grad_norm": 0.005973259452730417,
      "learning_rate": 4.5152284263959394e-05,
      "loss": 0.0558,
      "step": 1720
    },
    {
      "epoch": 1.463620981387479,
      "grad_norm": 0.24085456132888794,
      "learning_rate": 4.512408347433728e-05,
      "loss": 0.055,
      "step": 1730
    },
    {
      "epoch": 1.4720812182741116,
      "grad_norm": 0.006745295133441687,
      "learning_rate": 4.509588268471518e-05,
      "loss": 0.0501,
      "step": 1740
    },
    {
      "epoch": 1.4805414551607445,
      "grad_norm": 0.49678128957748413,
      "learning_rate": 4.5067681895093065e-05,
      "loss": 0.0194,
      "step": 1750
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.2952556610107422,
      "learning_rate": 4.503948110547095e-05,
      "loss": 0.0893,
      "step": 1760
    },
    {
      "epoch": 1.49746192893401,
      "grad_norm": 1.9802641868591309,
      "learning_rate": 4.501128031584885e-05,
      "loss": 0.0114,
      "step": 1770
    },
    {
      "epoch": 1.505922165820643,
      "grad_norm": 0.016201358288526535,
      "learning_rate": 4.4983079526226736e-05,
      "loss": 0.1306,
      "step": 1780
    },
    {
      "epoch": 1.5143824027072759,
      "grad_norm": 0.2131015509366989,
      "learning_rate": 4.495487873660463e-05,
      "loss": 0.0282,
      "step": 1790
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 0.1275821179151535,
      "learning_rate": 4.492667794698252e-05,
      "loss": 0.0732,
      "step": 1800
    },
    {
      "epoch": 1.5313028764805414,
      "grad_norm": 32.563453674316406,
      "learning_rate": 4.4898477157360406e-05,
      "loss": 0.0461,
      "step": 1810
    },
    {
      "epoch": 1.5397631133671743,
      "grad_norm": 0.01262142974883318,
      "learning_rate": 4.48702763677383e-05,
      "loss": 0.0382,
      "step": 1820
    },
    {
      "epoch": 1.548223350253807,
      "grad_norm": 3.734633207321167,
      "learning_rate": 4.484207557811619e-05,
      "loss": 0.0036,
      "step": 1830
    },
    {
      "epoch": 1.5566835871404399,
      "grad_norm": 0.026379531249403954,
      "learning_rate": 4.4813874788494084e-05,
      "loss": 0.0045,
      "step": 1840
    },
    {
      "epoch": 1.5651438240270727,
      "grad_norm": 0.006282446440309286,
      "learning_rate": 4.478567399887197e-05,
      "loss": 0.0065,
      "step": 1850
    },
    {
      "epoch": 1.5736040609137056,
      "grad_norm": 0.3327971398830414,
      "learning_rate": 4.475747320924986e-05,
      "loss": 0.0198,
      "step": 1860
    },
    {
      "epoch": 1.5820642978003385,
      "grad_norm": 0.11799824237823486,
      "learning_rate": 4.472927241962775e-05,
      "loss": 0.1285,
      "step": 1870
    },
    {
      "epoch": 1.5905245346869712,
      "grad_norm": 0.005150949582457542,
      "learning_rate": 4.470107163000564e-05,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 1.598984771573604,
      "grad_norm": 20.945222854614258,
      "learning_rate": 4.467287084038354e-05,
      "loss": 0.0764,
      "step": 1890
    },
    {
      "epoch": 1.6074450084602367,
      "grad_norm": 14.346229553222656,
      "learning_rate": 4.4644670050761425e-05,
      "loss": 0.052,
      "step": 1900
    },
    {
      "epoch": 1.6159052453468696,
      "grad_norm": 0.4961164593696594,
      "learning_rate": 4.461646926113931e-05,
      "loss": 0.0594,
      "step": 1910
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 0.05455700308084488,
      "learning_rate": 4.45882684715172e-05,
      "loss": 0.1213,
      "step": 1920
    },
    {
      "epoch": 1.6328257191201354,
      "grad_norm": 35.61746597290039,
      "learning_rate": 4.4560067681895096e-05,
      "loss": 0.1965,
      "step": 1930
    },
    {
      "epoch": 1.6412859560067683,
      "grad_norm": 0.14853937923908234,
      "learning_rate": 4.4531866892272984e-05,
      "loss": 0.071,
      "step": 1940
    },
    {
      "epoch": 1.649746192893401,
      "grad_norm": 29.400121688842773,
      "learning_rate": 4.450366610265088e-05,
      "loss": 0.1181,
      "step": 1950
    },
    {
      "epoch": 1.6582064297800339,
      "grad_norm": 26.16289520263672,
      "learning_rate": 4.4475465313028766e-05,
      "loss": 0.0451,
      "step": 1960
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 16.397777557373047,
      "learning_rate": 4.4447264523406654e-05,
      "loss": 0.0818,
      "step": 1970
    },
    {
      "epoch": 1.6751269035532994,
      "grad_norm": 0.09849713742733002,
      "learning_rate": 4.441906373378455e-05,
      "loss": 0.0955,
      "step": 1980
    },
    {
      "epoch": 1.6835871404399323,
      "grad_norm": 7.682143211364746,
      "learning_rate": 4.439086294416244e-05,
      "loss": 0.1323,
      "step": 1990
    },
    {
      "epoch": 1.6920473773265652,
      "grad_norm": 0.6320121884346008,
      "learning_rate": 4.436266215454033e-05,
      "loss": 0.1091,
      "step": 2000
    },
    {
      "epoch": 1.700507614213198,
      "grad_norm": 0.12847696244716644,
      "learning_rate": 4.433446136491822e-05,
      "loss": 0.0281,
      "step": 2010
    },
    {
      "epoch": 1.708967851099831,
      "grad_norm": 15.028797149658203,
      "learning_rate": 4.430626057529611e-05,
      "loss": 0.0261,
      "step": 2020
    },
    {
      "epoch": 1.7174280879864636,
      "grad_norm": 0.01604713872075081,
      "learning_rate": 4.4278059785674e-05,
      "loss": 0.0013,
      "step": 2030
    },
    {
      "epoch": 1.7258883248730963,
      "grad_norm": 17.731983184814453,
      "learning_rate": 4.424985899605189e-05,
      "loss": 0.0434,
      "step": 2040
    },
    {
      "epoch": 1.7343485617597292,
      "grad_norm": 0.12152490019798279,
      "learning_rate": 4.4221658206429785e-05,
      "loss": 0.0606,
      "step": 2050
    },
    {
      "epoch": 1.742808798646362,
      "grad_norm": 0.003514975542202592,
      "learning_rate": 4.419345741680767e-05,
      "loss": 0.0556,
      "step": 2060
    },
    {
      "epoch": 1.751269035532995,
      "grad_norm": 2.6348941326141357,
      "learning_rate": 4.416525662718556e-05,
      "loss": 0.1486,
      "step": 2070
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 21.712257385253906,
      "learning_rate": 4.413705583756345e-05,
      "loss": 0.1412,
      "step": 2080
    },
    {
      "epoch": 1.7681895093062607,
      "grad_norm": 0.0020400604698807,
      "learning_rate": 4.4108855047941344e-05,
      "loss": 0.069,
      "step": 2090
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 13.40526294708252,
      "learning_rate": 4.408065425831924e-05,
      "loss": 0.0379,
      "step": 2100
    },
    {
      "epoch": 1.785109983079526,
      "grad_norm": 0.07841428369283676,
      "learning_rate": 4.4052453468697127e-05,
      "loss": 0.0338,
      "step": 2110
    },
    {
      "epoch": 1.793570219966159,
      "grad_norm": 21.989072799682617,
      "learning_rate": 4.4024252679075015e-05,
      "loss": 0.0383,
      "step": 2120
    },
    {
      "epoch": 1.8020304568527918,
      "grad_norm": 8.322708129882812,
      "learning_rate": 4.39960518894529e-05,
      "loss": 0.1942,
      "step": 2130
    },
    {
      "epoch": 1.8104906937394247,
      "grad_norm": 0.019643452018499374,
      "learning_rate": 4.39678510998308e-05,
      "loss": 0.0736,
      "step": 2140
    },
    {
      "epoch": 1.8189509306260576,
      "grad_norm": 37.64115524291992,
      "learning_rate": 4.3939650310208685e-05,
      "loss": 0.1089,
      "step": 2150
    },
    {
      "epoch": 1.8274111675126905,
      "grad_norm": 12.482965469360352,
      "learning_rate": 4.391144952058658e-05,
      "loss": 0.1011,
      "step": 2160
    },
    {
      "epoch": 1.8358714043993232,
      "grad_norm": 0.03910377621650696,
      "learning_rate": 4.3883248730964475e-05,
      "loss": 0.093,
      "step": 2170
    },
    {
      "epoch": 1.844331641285956,
      "grad_norm": 1.2610856294631958,
      "learning_rate": 4.3855047941342356e-05,
      "loss": 0.0736,
      "step": 2180
    },
    {
      "epoch": 1.8527918781725887,
      "grad_norm": 15.85295295715332,
      "learning_rate": 4.382684715172025e-05,
      "loss": 0.1832,
      "step": 2190
    },
    {
      "epoch": 1.8612521150592216,
      "grad_norm": 0.31547269225120544,
      "learning_rate": 4.379864636209814e-05,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 1.8697123519458545,
      "grad_norm": 0.3832317292690277,
      "learning_rate": 4.377044557247603e-05,
      "loss": 0.0473,
      "step": 2210
    },
    {
      "epoch": 1.8781725888324874,
      "grad_norm": 0.0396120585501194,
      "learning_rate": 4.374224478285392e-05,
      "loss": 0.0631,
      "step": 2220
    },
    {
      "epoch": 1.8866328257191203,
      "grad_norm": 0.14707453548908234,
      "learning_rate": 4.371404399323181e-05,
      "loss": 0.0929,
      "step": 2230
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 0.01668008789420128,
      "learning_rate": 4.3685843203609704e-05,
      "loss": 0.0821,
      "step": 2240
    },
    {
      "epoch": 1.9035532994923858,
      "grad_norm": 0.11122526228427887,
      "learning_rate": 4.365764241398759e-05,
      "loss": 0.1329,
      "step": 2250
    },
    {
      "epoch": 1.9120135363790185,
      "grad_norm": 35.64632797241211,
      "learning_rate": 4.362944162436549e-05,
      "loss": 0.0724,
      "step": 2260
    },
    {
      "epoch": 1.9204737732656514,
      "grad_norm": 0.12160845100879669,
      "learning_rate": 4.3601240834743375e-05,
      "loss": 0.0693,
      "step": 2270
    },
    {
      "epoch": 1.9289340101522843,
      "grad_norm": 0.010136724449694157,
      "learning_rate": 4.357304004512127e-05,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 1.9373942470389172,
      "grad_norm": 0.020088551566004753,
      "learning_rate": 4.354483925549915e-05,
      "loss": 0.0402,
      "step": 2290
    },
    {
      "epoch": 1.94585448392555,
      "grad_norm": 0.01234954409301281,
      "learning_rate": 4.3516638465877045e-05,
      "loss": 0.0293,
      "step": 2300
    },
    {
      "epoch": 1.9543147208121827,
      "grad_norm": 1.4190717935562134,
      "learning_rate": 4.348843767625494e-05,
      "loss": 0.1906,
      "step": 2310
    },
    {
      "epoch": 1.9627749576988156,
      "grad_norm": 0.010624142363667488,
      "learning_rate": 4.346023688663283e-05,
      "loss": 0.0392,
      "step": 2320
    },
    {
      "epoch": 1.9712351945854483,
      "grad_norm": 22.869890213012695,
      "learning_rate": 4.343203609701072e-05,
      "loss": 0.0536,
      "step": 2330
    },
    {
      "epoch": 1.9796954314720812,
      "grad_norm": 0.01851845346391201,
      "learning_rate": 4.3403835307388604e-05,
      "loss": 0.0733,
      "step": 2340
    },
    {
      "epoch": 1.988155668358714,
      "grad_norm": 25.321544647216797,
      "learning_rate": 4.33756345177665e-05,
      "loss": 0.0828,
      "step": 2350
    },
    {
      "epoch": 1.996615905245347,
      "grad_norm": 0.037506792694330215,
      "learning_rate": 4.334743372814439e-05,
      "loss": 0.046,
      "step": 2360
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9779629629629629,
      "eval_loss": 0.09348412603139877,
      "eval_runtime": 246.6577,
      "eval_samples_per_second": 21.893,
      "eval_steps_per_second": 2.737,
      "step": 2364
    }
  ],
  "logging_steps": 10,
  "max_steps": 17730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.886680730640384e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
