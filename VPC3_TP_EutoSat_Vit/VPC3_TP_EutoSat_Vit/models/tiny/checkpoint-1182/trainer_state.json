{
  "best_global_step": 1182,
  "best_metric": 0.9690740740740741,
  "best_model_checkpoint": "VPC3_TP_EutoSat_Vit/models/tiny/checkpoint-1182",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1182,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008460236886632826,
      "grad_norm": 14.466089248657227,
      "learning_rate": 4.9974619289340105e-05,
      "loss": 1.9739,
      "step": 10
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 20.900371551513672,
      "learning_rate": 4.994641849971799e-05,
      "loss": 1.1346,
      "step": 20
    },
    {
      "epoch": 0.025380710659898477,
      "grad_norm": 14.140461921691895,
      "learning_rate": 4.991821771009588e-05,
      "loss": 0.6714,
      "step": 30
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 14.910873413085938,
      "learning_rate": 4.9890016920473776e-05,
      "loss": 0.4596,
      "step": 40
    },
    {
      "epoch": 0.04230118443316413,
      "grad_norm": 35.95499801635742,
      "learning_rate": 4.986181613085167e-05,
      "loss": 0.4352,
      "step": 50
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 10.581116676330566,
      "learning_rate": 4.983361534122956e-05,
      "loss": 0.319,
      "step": 60
    },
    {
      "epoch": 0.05922165820642978,
      "grad_norm": 11.34449291229248,
      "learning_rate": 4.9805414551607446e-05,
      "loss": 0.2842,
      "step": 70
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 7.4420576095581055,
      "learning_rate": 4.9777213761985334e-05,
      "loss": 0.2789,
      "step": 80
    },
    {
      "epoch": 0.07614213197969544,
      "grad_norm": 21.182126998901367,
      "learning_rate": 4.974901297236323e-05,
      "loss": 0.2123,
      "step": 90
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 11.74959659576416,
      "learning_rate": 4.972081218274112e-05,
      "loss": 0.2109,
      "step": 100
    },
    {
      "epoch": 0.09306260575296109,
      "grad_norm": 24.90926170349121,
      "learning_rate": 4.969261139311901e-05,
      "loss": 0.1604,
      "step": 110
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.184607982635498,
      "learning_rate": 4.96644106034969e-05,
      "loss": 0.3748,
      "step": 120
    },
    {
      "epoch": 0.10998307952622674,
      "grad_norm": 12.008848190307617,
      "learning_rate": 4.963620981387479e-05,
      "loss": 0.1721,
      "step": 130
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 10.822035789489746,
      "learning_rate": 4.960800902425268e-05,
      "loss": 0.1741,
      "step": 140
    },
    {
      "epoch": 0.12690355329949238,
      "grad_norm": 3.1626784801483154,
      "learning_rate": 4.957980823463057e-05,
      "loss": 0.1298,
      "step": 150
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 6.791316032409668,
      "learning_rate": 4.9551607445008465e-05,
      "loss": 0.1967,
      "step": 160
    },
    {
      "epoch": 0.14382402707275804,
      "grad_norm": 4.2050347328186035,
      "learning_rate": 4.952340665538635e-05,
      "loss": 0.1122,
      "step": 170
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 11.0927095413208,
      "learning_rate": 4.949520586576424e-05,
      "loss": 0.1621,
      "step": 180
    },
    {
      "epoch": 0.16074450084602368,
      "grad_norm": 25.3814697265625,
      "learning_rate": 4.9467005076142136e-05,
      "loss": 0.374,
      "step": 190
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 2.0944905281066895,
      "learning_rate": 4.9438804286520024e-05,
      "loss": 0.1641,
      "step": 200
    },
    {
      "epoch": 0.17766497461928935,
      "grad_norm": 14.078400611877441,
      "learning_rate": 4.941060349689792e-05,
      "loss": 0.2302,
      "step": 210
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 13.332756996154785,
      "learning_rate": 4.9382402707275806e-05,
      "loss": 0.2209,
      "step": 220
    },
    {
      "epoch": 0.19458544839255498,
      "grad_norm": 1.499985694885254,
      "learning_rate": 4.9354201917653694e-05,
      "loss": 0.3221,
      "step": 230
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 1.4748750925064087,
      "learning_rate": 4.932600112803158e-05,
      "loss": 0.1699,
      "step": 240
    },
    {
      "epoch": 0.21150592216582065,
      "grad_norm": 28.762161254882812,
      "learning_rate": 4.929780033840948e-05,
      "loss": 0.1859,
      "step": 250
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 21.489336013793945,
      "learning_rate": 4.926959954878737e-05,
      "loss": 0.0832,
      "step": 260
    },
    {
      "epoch": 0.22842639593908629,
      "grad_norm": 1.1055177450180054,
      "learning_rate": 4.924139875916526e-05,
      "loss": 0.1289,
      "step": 270
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 22.156885147094727,
      "learning_rate": 4.921319796954315e-05,
      "loss": 0.1383,
      "step": 280
    },
    {
      "epoch": 0.24534686971235195,
      "grad_norm": 13.688899040222168,
      "learning_rate": 4.9184997179921036e-05,
      "loss": 0.1253,
      "step": 290
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 2.1891090869903564,
      "learning_rate": 4.915679639029893e-05,
      "loss": 0.1817,
      "step": 300
    },
    {
      "epoch": 0.2622673434856176,
      "grad_norm": 29.75678253173828,
      "learning_rate": 4.912859560067682e-05,
      "loss": 0.1101,
      "step": 310
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 19.95785140991211,
      "learning_rate": 4.910039481105471e-05,
      "loss": 0.1785,
      "step": 320
    },
    {
      "epoch": 0.27918781725888325,
      "grad_norm": 4.945294380187988,
      "learning_rate": 4.907219402143261e-05,
      "loss": 0.2358,
      "step": 330
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 26.60957145690918,
      "learning_rate": 4.904399323181049e-05,
      "loss": 0.1177,
      "step": 340
    },
    {
      "epoch": 0.2961082910321489,
      "grad_norm": 44.35723876953125,
      "learning_rate": 4.9015792442188384e-05,
      "loss": 0.1052,
      "step": 350
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.2594661712646484,
      "learning_rate": 4.898759165256627e-05,
      "loss": 0.1825,
      "step": 360
    },
    {
      "epoch": 0.3130287648054145,
      "grad_norm": 1.4883270263671875,
      "learning_rate": 4.8959390862944167e-05,
      "loss": 0.1231,
      "step": 370
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 17.421049118041992,
      "learning_rate": 4.8931190073322055e-05,
      "loss": 0.1644,
      "step": 380
    },
    {
      "epoch": 0.3299492385786802,
      "grad_norm": 16.858835220336914,
      "learning_rate": 4.890298928369995e-05,
      "loss": 0.1424,
      "step": 390
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 14.830533027648926,
      "learning_rate": 4.887478849407784e-05,
      "loss": 0.1687,
      "step": 400
    },
    {
      "epoch": 0.34686971235194586,
      "grad_norm": 2.4005239009857178,
      "learning_rate": 4.8846587704455725e-05,
      "loss": 0.1471,
      "step": 410
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.5430868268013,
      "learning_rate": 4.881838691483362e-05,
      "loss": 0.1136,
      "step": 420
    },
    {
      "epoch": 0.3637901861252115,
      "grad_norm": 0.6713274717330933,
      "learning_rate": 4.879018612521151e-05,
      "loss": 0.3007,
      "step": 430
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.46859073638916,
      "learning_rate": 4.87619853355894e-05,
      "loss": 0.0564,
      "step": 440
    },
    {
      "epoch": 0.38071065989847713,
      "grad_norm": 0.944525957107544,
      "learning_rate": 4.8733784545967284e-05,
      "loss": 0.1091,
      "step": 450
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.24216057360172272,
      "learning_rate": 4.870558375634518e-05,
      "loss": 0.0261,
      "step": 460
    },
    {
      "epoch": 0.3976311336717428,
      "grad_norm": 17.511394500732422,
      "learning_rate": 4.867738296672307e-05,
      "loss": 0.1677,
      "step": 470
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 13.479783058166504,
      "learning_rate": 4.864918217710096e-05,
      "loss": 0.2508,
      "step": 480
    },
    {
      "epoch": 0.41455160744500846,
      "grad_norm": 19.93234634399414,
      "learning_rate": 4.8620981387478856e-05,
      "loss": 0.0422,
      "step": 490
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 4.957183837890625,
      "learning_rate": 4.8592780597856744e-05,
      "loss": 0.0953,
      "step": 500
    },
    {
      "epoch": 0.43147208121827413,
      "grad_norm": 2.8080811500549316,
      "learning_rate": 4.856457980823463e-05,
      "loss": 0.0667,
      "step": 510
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 26.37185287475586,
      "learning_rate": 4.853637901861252e-05,
      "loss": 0.2009,
      "step": 520
    },
    {
      "epoch": 0.44839255499153974,
      "grad_norm": 1.484768033027649,
      "learning_rate": 4.8508178228990415e-05,
      "loss": 0.038,
      "step": 530
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 20.85687255859375,
      "learning_rate": 4.847997743936831e-05,
      "loss": 0.1368,
      "step": 540
    },
    {
      "epoch": 0.4653130287648054,
      "grad_norm": 2.726987361907959,
      "learning_rate": 4.84517766497462e-05,
      "loss": 0.1399,
      "step": 550
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 15.755430221557617,
      "learning_rate": 4.8423575860124085e-05,
      "loss": 0.0465,
      "step": 560
    },
    {
      "epoch": 0.48223350253807107,
      "grad_norm": 28.094520568847656,
      "learning_rate": 4.839537507050197e-05,
      "loss": 0.199,
      "step": 570
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 0.03665974736213684,
      "learning_rate": 4.836717428087987e-05,
      "loss": 0.1026,
      "step": 580
    },
    {
      "epoch": 0.49915397631133673,
      "grad_norm": 0.3312017023563385,
      "learning_rate": 4.8338973491257756e-05,
      "loss": 0.204,
      "step": 590
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 0.2591623365879059,
      "learning_rate": 4.831077270163565e-05,
      "loss": 0.1357,
      "step": 600
    },
    {
      "epoch": 0.5160744500846024,
      "grad_norm": 23.12666130065918,
      "learning_rate": 4.828257191201354e-05,
      "loss": 0.114,
      "step": 610
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.457749366760254,
      "learning_rate": 4.825437112239143e-05,
      "loss": 0.0955,
      "step": 620
    },
    {
      "epoch": 0.5329949238578681,
      "grad_norm": 19.274295806884766,
      "learning_rate": 4.822617033276932e-05,
      "loss": 0.318,
      "step": 630
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 22.72943115234375,
      "learning_rate": 4.819796954314721e-05,
      "loss": 0.146,
      "step": 640
    },
    {
      "epoch": 0.5499153976311336,
      "grad_norm": 6.262524604797363,
      "learning_rate": 4.8169768753525104e-05,
      "loss": 0.1691,
      "step": 650
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 20.436107635498047,
      "learning_rate": 4.814156796390299e-05,
      "loss": 0.1831,
      "step": 660
    },
    {
      "epoch": 0.5668358714043993,
      "grad_norm": 13.359298706054688,
      "learning_rate": 4.811336717428088e-05,
      "loss": 0.0537,
      "step": 670
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 7.079187393188477,
      "learning_rate": 4.8085166384658775e-05,
      "loss": 0.0709,
      "step": 680
    },
    {
      "epoch": 0.583756345177665,
      "grad_norm": 0.7319515347480774,
      "learning_rate": 4.805696559503666e-05,
      "loss": 0.1109,
      "step": 690
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 23.68626594543457,
      "learning_rate": 4.802876480541456e-05,
      "loss": 0.0784,
      "step": 700
    },
    {
      "epoch": 0.6006768189509306,
      "grad_norm": 0.6795468926429749,
      "learning_rate": 4.8000564015792445e-05,
      "loss": 0.1495,
      "step": 710
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 0.15101884305477142,
      "learning_rate": 4.7972363226170333e-05,
      "loss": 0.1307,
      "step": 720
    },
    {
      "epoch": 0.6175972927241963,
      "grad_norm": 10.494664192199707,
      "learning_rate": 4.794416243654822e-05,
      "loss": 0.1626,
      "step": 730
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 18.630586624145508,
      "learning_rate": 4.7915961646926116e-05,
      "loss": 0.1586,
      "step": 740
    },
    {
      "epoch": 0.6345177664974619,
      "grad_norm": 0.2620302140712738,
      "learning_rate": 4.788776085730401e-05,
      "loss": 0.0755,
      "step": 750
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 0.09258006513118744,
      "learning_rate": 4.78595600676819e-05,
      "loss": 0.1077,
      "step": 760
    },
    {
      "epoch": 0.6514382402707276,
      "grad_norm": 0.4374638497829437,
      "learning_rate": 4.783135927805979e-05,
      "loss": 0.1392,
      "step": 770
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.67353755235672,
      "learning_rate": 4.7803158488437675e-05,
      "loss": 0.0857,
      "step": 780
    },
    {
      "epoch": 0.6683587140439933,
      "grad_norm": 19.41292381286621,
      "learning_rate": 4.777495769881557e-05,
      "loss": 0.1199,
      "step": 790
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.23480162024497986,
      "learning_rate": 4.774675690919346e-05,
      "loss": 0.0371,
      "step": 800
    },
    {
      "epoch": 0.6852791878172588,
      "grad_norm": 0.12986932694911957,
      "learning_rate": 4.771855611957135e-05,
      "loss": 0.2893,
      "step": 810
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 1.1319631338119507,
      "learning_rate": 4.769035532994924e-05,
      "loss": 0.0735,
      "step": 820
    },
    {
      "epoch": 0.7021996615905245,
      "grad_norm": 9.579446792602539,
      "learning_rate": 4.766215454032713e-05,
      "loss": 0.1398,
      "step": 830
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 33.17691421508789,
      "learning_rate": 4.763395375070502e-05,
      "loss": 0.1564,
      "step": 840
    },
    {
      "epoch": 0.7191201353637902,
      "grad_norm": 7.179660797119141,
      "learning_rate": 4.760575296108291e-05,
      "loss": 0.1506,
      "step": 850
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 4.116767883300781,
      "learning_rate": 4.7577552171460806e-05,
      "loss": 0.0688,
      "step": 860
    },
    {
      "epoch": 0.7360406091370558,
      "grad_norm": 14.570455551147461,
      "learning_rate": 4.7549351381838694e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 0.619854748249054,
      "learning_rate": 4.752115059221658e-05,
      "loss": 0.1513,
      "step": 880
    },
    {
      "epoch": 0.7529610829103215,
      "grad_norm": 5.441271781921387,
      "learning_rate": 4.7492949802594476e-05,
      "loss": 0.261,
      "step": 890
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 2.6095757484436035,
      "learning_rate": 4.7464749012972364e-05,
      "loss": 0.0479,
      "step": 900
    },
    {
      "epoch": 0.7698815566835872,
      "grad_norm": 18.807838439941406,
      "learning_rate": 4.743654822335026e-05,
      "loss": 0.0865,
      "step": 910
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 19.832582473754883,
      "learning_rate": 4.740834743372815e-05,
      "loss": 0.2682,
      "step": 920
    },
    {
      "epoch": 0.7868020304568528,
      "grad_norm": 23.313390731811523,
      "learning_rate": 4.7380146644106035e-05,
      "loss": 0.1621,
      "step": 930
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 2.7553422451019287,
      "learning_rate": 4.735194585448392e-05,
      "loss": 0.1222,
      "step": 940
    },
    {
      "epoch": 0.8037225042301185,
      "grad_norm": 0.5432969331741333,
      "learning_rate": 4.732374506486182e-05,
      "loss": 0.083,
      "step": 950
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 11.276805877685547,
      "learning_rate": 4.729554427523971e-05,
      "loss": 0.0629,
      "step": 960
    },
    {
      "epoch": 0.8206429780033841,
      "grad_norm": 5.896979331970215,
      "learning_rate": 4.72673434856176e-05,
      "loss": 0.1201,
      "step": 970
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 16.9703426361084,
      "learning_rate": 4.7239142695995495e-05,
      "loss": 0.121,
      "step": 980
    },
    {
      "epoch": 0.8375634517766497,
      "grad_norm": 0.12442143261432648,
      "learning_rate": 4.7210941906373376e-05,
      "loss": 0.1755,
      "step": 990
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 0.058043692260980606,
      "learning_rate": 4.718274111675127e-05,
      "loss": 0.1251,
      "step": 1000
    },
    {
      "epoch": 0.8544839255499154,
      "grad_norm": 42.14734649658203,
      "learning_rate": 4.715454032712916e-05,
      "loss": 0.1367,
      "step": 1010
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 26.698923110961914,
      "learning_rate": 4.7126339537507054e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.871404399323181,
      "grad_norm": 3.701037645339966,
      "learning_rate": 4.709813874788495e-05,
      "loss": 0.2048,
      "step": 1030
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 12.624013900756836,
      "learning_rate": 4.706993795826283e-05,
      "loss": 0.1073,
      "step": 1040
    },
    {
      "epoch": 0.8883248730964467,
      "grad_norm": 30.081945419311523,
      "learning_rate": 4.7041737168640724e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 24.828798294067383,
      "learning_rate": 4.701353637901861e-05,
      "loss": 0.087,
      "step": 1060
    },
    {
      "epoch": 0.9052453468697124,
      "grad_norm": 27.589454650878906,
      "learning_rate": 4.698533558939651e-05,
      "loss": 0.0654,
      "step": 1070
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.207147598266602,
      "learning_rate": 4.6957134799774395e-05,
      "loss": 0.0868,
      "step": 1080
    },
    {
      "epoch": 0.922165820642978,
      "grad_norm": 1.1621407270431519,
      "learning_rate": 4.692893401015229e-05,
      "loss": 0.0359,
      "step": 1090
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 42.396610260009766,
      "learning_rate": 4.690073322053018e-05,
      "loss": 0.1143,
      "step": 1100
    },
    {
      "epoch": 0.9390862944162437,
      "grad_norm": 21.23570442199707,
      "learning_rate": 4.6872532430908066e-05,
      "loss": 0.1539,
      "step": 1110
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.07133467495441437,
      "learning_rate": 4.684433164128596e-05,
      "loss": 0.0776,
      "step": 1120
    },
    {
      "epoch": 0.9560067681895094,
      "grad_norm": 1.5074037313461304,
      "learning_rate": 4.681613085166385e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 18.812101364135742,
      "learning_rate": 4.678793006204174e-05,
      "loss": 0.0749,
      "step": 1140
    },
    {
      "epoch": 0.9729272419627749,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.675972927241963e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.9813874788494078,
      "grad_norm": 2.271929979324341,
      "learning_rate": 4.673152848279752e-05,
      "loss": 0.1919,
      "step": 1160
    },
    {
      "epoch": 0.9898477157360406,
      "grad_norm": 5.057013034820557,
      "learning_rate": 4.6703327693175414e-05,
      "loss": 0.0771,
      "step": 1170
    },
    {
      "epoch": 0.9983079526226735,
      "grad_norm": 10.19404411315918,
      "learning_rate": 4.66751269035533e-05,
      "loss": 0.0594,
      "step": 1180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9690740740740741,
      "eval_loss": 0.11386065185070038,
      "eval_runtime": 246.4452,
      "eval_samples_per_second": 21.912,
      "eval_steps_per_second": 2.739,
      "step": 1182
    }
  ],
  "logging_steps": 10,
  "max_steps": 17730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.43340365320192e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
