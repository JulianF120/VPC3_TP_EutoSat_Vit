{
  "best_global_step": 10638,
  "best_metric": 0.9840740740740741,
  "best_model_checkpoint": "VPC3_TP_EutoSat_Vit/models/tiny/checkpoint-10638",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 11820,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008460236886632826,
      "grad_norm": 14.466089248657227,
      "learning_rate": 4.9974619289340105e-05,
      "loss": 1.9739,
      "step": 10
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 20.900371551513672,
      "learning_rate": 4.994641849971799e-05,
      "loss": 1.1346,
      "step": 20
    },
    {
      "epoch": 0.025380710659898477,
      "grad_norm": 14.140461921691895,
      "learning_rate": 4.991821771009588e-05,
      "loss": 0.6714,
      "step": 30
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 14.910873413085938,
      "learning_rate": 4.9890016920473776e-05,
      "loss": 0.4596,
      "step": 40
    },
    {
      "epoch": 0.04230118443316413,
      "grad_norm": 35.95499801635742,
      "learning_rate": 4.986181613085167e-05,
      "loss": 0.4352,
      "step": 50
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 10.581116676330566,
      "learning_rate": 4.983361534122956e-05,
      "loss": 0.319,
      "step": 60
    },
    {
      "epoch": 0.05922165820642978,
      "grad_norm": 11.34449291229248,
      "learning_rate": 4.9805414551607446e-05,
      "loss": 0.2842,
      "step": 70
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 7.4420576095581055,
      "learning_rate": 4.9777213761985334e-05,
      "loss": 0.2789,
      "step": 80
    },
    {
      "epoch": 0.07614213197969544,
      "grad_norm": 21.182126998901367,
      "learning_rate": 4.974901297236323e-05,
      "loss": 0.2123,
      "step": 90
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 11.74959659576416,
      "learning_rate": 4.972081218274112e-05,
      "loss": 0.2109,
      "step": 100
    },
    {
      "epoch": 0.09306260575296109,
      "grad_norm": 24.90926170349121,
      "learning_rate": 4.969261139311901e-05,
      "loss": 0.1604,
      "step": 110
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.184607982635498,
      "learning_rate": 4.96644106034969e-05,
      "loss": 0.3748,
      "step": 120
    },
    {
      "epoch": 0.10998307952622674,
      "grad_norm": 12.008848190307617,
      "learning_rate": 4.963620981387479e-05,
      "loss": 0.1721,
      "step": 130
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 10.822035789489746,
      "learning_rate": 4.960800902425268e-05,
      "loss": 0.1741,
      "step": 140
    },
    {
      "epoch": 0.12690355329949238,
      "grad_norm": 3.1626784801483154,
      "learning_rate": 4.957980823463057e-05,
      "loss": 0.1298,
      "step": 150
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 6.791316032409668,
      "learning_rate": 4.9551607445008465e-05,
      "loss": 0.1967,
      "step": 160
    },
    {
      "epoch": 0.14382402707275804,
      "grad_norm": 4.2050347328186035,
      "learning_rate": 4.952340665538635e-05,
      "loss": 0.1122,
      "step": 170
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 11.0927095413208,
      "learning_rate": 4.949520586576424e-05,
      "loss": 0.1621,
      "step": 180
    },
    {
      "epoch": 0.16074450084602368,
      "grad_norm": 25.3814697265625,
      "learning_rate": 4.9467005076142136e-05,
      "loss": 0.374,
      "step": 190
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 2.0944905281066895,
      "learning_rate": 4.9438804286520024e-05,
      "loss": 0.1641,
      "step": 200
    },
    {
      "epoch": 0.17766497461928935,
      "grad_norm": 14.078400611877441,
      "learning_rate": 4.941060349689792e-05,
      "loss": 0.2302,
      "step": 210
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 13.332756996154785,
      "learning_rate": 4.9382402707275806e-05,
      "loss": 0.2209,
      "step": 220
    },
    {
      "epoch": 0.19458544839255498,
      "grad_norm": 1.499985694885254,
      "learning_rate": 4.9354201917653694e-05,
      "loss": 0.3221,
      "step": 230
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 1.4748750925064087,
      "learning_rate": 4.932600112803158e-05,
      "loss": 0.1699,
      "step": 240
    },
    {
      "epoch": 0.21150592216582065,
      "grad_norm": 28.762161254882812,
      "learning_rate": 4.929780033840948e-05,
      "loss": 0.1859,
      "step": 250
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 21.489336013793945,
      "learning_rate": 4.926959954878737e-05,
      "loss": 0.0832,
      "step": 260
    },
    {
      "epoch": 0.22842639593908629,
      "grad_norm": 1.1055177450180054,
      "learning_rate": 4.924139875916526e-05,
      "loss": 0.1289,
      "step": 270
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 22.156885147094727,
      "learning_rate": 4.921319796954315e-05,
      "loss": 0.1383,
      "step": 280
    },
    {
      "epoch": 0.24534686971235195,
      "grad_norm": 13.688899040222168,
      "learning_rate": 4.9184997179921036e-05,
      "loss": 0.1253,
      "step": 290
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 2.1891090869903564,
      "learning_rate": 4.915679639029893e-05,
      "loss": 0.1817,
      "step": 300
    },
    {
      "epoch": 0.2622673434856176,
      "grad_norm": 29.75678253173828,
      "learning_rate": 4.912859560067682e-05,
      "loss": 0.1101,
      "step": 310
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 19.95785140991211,
      "learning_rate": 4.910039481105471e-05,
      "loss": 0.1785,
      "step": 320
    },
    {
      "epoch": 0.27918781725888325,
      "grad_norm": 4.945294380187988,
      "learning_rate": 4.907219402143261e-05,
      "loss": 0.2358,
      "step": 330
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 26.60957145690918,
      "learning_rate": 4.904399323181049e-05,
      "loss": 0.1177,
      "step": 340
    },
    {
      "epoch": 0.2961082910321489,
      "grad_norm": 44.35723876953125,
      "learning_rate": 4.9015792442188384e-05,
      "loss": 0.1052,
      "step": 350
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.2594661712646484,
      "learning_rate": 4.898759165256627e-05,
      "loss": 0.1825,
      "step": 360
    },
    {
      "epoch": 0.3130287648054145,
      "grad_norm": 1.4883270263671875,
      "learning_rate": 4.8959390862944167e-05,
      "loss": 0.1231,
      "step": 370
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 17.421049118041992,
      "learning_rate": 4.8931190073322055e-05,
      "loss": 0.1644,
      "step": 380
    },
    {
      "epoch": 0.3299492385786802,
      "grad_norm": 16.858835220336914,
      "learning_rate": 4.890298928369995e-05,
      "loss": 0.1424,
      "step": 390
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 14.830533027648926,
      "learning_rate": 4.887478849407784e-05,
      "loss": 0.1687,
      "step": 400
    },
    {
      "epoch": 0.34686971235194586,
      "grad_norm": 2.4005239009857178,
      "learning_rate": 4.8846587704455725e-05,
      "loss": 0.1471,
      "step": 410
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.5430868268013,
      "learning_rate": 4.881838691483362e-05,
      "loss": 0.1136,
      "step": 420
    },
    {
      "epoch": 0.3637901861252115,
      "grad_norm": 0.6713274717330933,
      "learning_rate": 4.879018612521151e-05,
      "loss": 0.3007,
      "step": 430
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.46859073638916,
      "learning_rate": 4.87619853355894e-05,
      "loss": 0.0564,
      "step": 440
    },
    {
      "epoch": 0.38071065989847713,
      "grad_norm": 0.944525957107544,
      "learning_rate": 4.8733784545967284e-05,
      "loss": 0.1091,
      "step": 450
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.24216057360172272,
      "learning_rate": 4.870558375634518e-05,
      "loss": 0.0261,
      "step": 460
    },
    {
      "epoch": 0.3976311336717428,
      "grad_norm": 17.511394500732422,
      "learning_rate": 4.867738296672307e-05,
      "loss": 0.1677,
      "step": 470
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 13.479783058166504,
      "learning_rate": 4.864918217710096e-05,
      "loss": 0.2508,
      "step": 480
    },
    {
      "epoch": 0.41455160744500846,
      "grad_norm": 19.93234634399414,
      "learning_rate": 4.8620981387478856e-05,
      "loss": 0.0422,
      "step": 490
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 4.957183837890625,
      "learning_rate": 4.8592780597856744e-05,
      "loss": 0.0953,
      "step": 500
    },
    {
      "epoch": 0.43147208121827413,
      "grad_norm": 2.8080811500549316,
      "learning_rate": 4.856457980823463e-05,
      "loss": 0.0667,
      "step": 510
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 26.37185287475586,
      "learning_rate": 4.853637901861252e-05,
      "loss": 0.2009,
      "step": 520
    },
    {
      "epoch": 0.44839255499153974,
      "grad_norm": 1.484768033027649,
      "learning_rate": 4.8508178228990415e-05,
      "loss": 0.038,
      "step": 530
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 20.85687255859375,
      "learning_rate": 4.847997743936831e-05,
      "loss": 0.1368,
      "step": 540
    },
    {
      "epoch": 0.4653130287648054,
      "grad_norm": 2.726987361907959,
      "learning_rate": 4.84517766497462e-05,
      "loss": 0.1399,
      "step": 550
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 15.755430221557617,
      "learning_rate": 4.8423575860124085e-05,
      "loss": 0.0465,
      "step": 560
    },
    {
      "epoch": 0.48223350253807107,
      "grad_norm": 28.094520568847656,
      "learning_rate": 4.839537507050197e-05,
      "loss": 0.199,
      "step": 570
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 0.03665974736213684,
      "learning_rate": 4.836717428087987e-05,
      "loss": 0.1026,
      "step": 580
    },
    {
      "epoch": 0.49915397631133673,
      "grad_norm": 0.3312017023563385,
      "learning_rate": 4.8338973491257756e-05,
      "loss": 0.204,
      "step": 590
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 0.2591623365879059,
      "learning_rate": 4.831077270163565e-05,
      "loss": 0.1357,
      "step": 600
    },
    {
      "epoch": 0.5160744500846024,
      "grad_norm": 23.12666130065918,
      "learning_rate": 4.828257191201354e-05,
      "loss": 0.114,
      "step": 610
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.457749366760254,
      "learning_rate": 4.825437112239143e-05,
      "loss": 0.0955,
      "step": 620
    },
    {
      "epoch": 0.5329949238578681,
      "grad_norm": 19.274295806884766,
      "learning_rate": 4.822617033276932e-05,
      "loss": 0.318,
      "step": 630
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 22.72943115234375,
      "learning_rate": 4.819796954314721e-05,
      "loss": 0.146,
      "step": 640
    },
    {
      "epoch": 0.5499153976311336,
      "grad_norm": 6.262524604797363,
      "learning_rate": 4.8169768753525104e-05,
      "loss": 0.1691,
      "step": 650
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 20.436107635498047,
      "learning_rate": 4.814156796390299e-05,
      "loss": 0.1831,
      "step": 660
    },
    {
      "epoch": 0.5668358714043993,
      "grad_norm": 13.359298706054688,
      "learning_rate": 4.811336717428088e-05,
      "loss": 0.0537,
      "step": 670
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 7.079187393188477,
      "learning_rate": 4.8085166384658775e-05,
      "loss": 0.0709,
      "step": 680
    },
    {
      "epoch": 0.583756345177665,
      "grad_norm": 0.7319515347480774,
      "learning_rate": 4.805696559503666e-05,
      "loss": 0.1109,
      "step": 690
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 23.68626594543457,
      "learning_rate": 4.802876480541456e-05,
      "loss": 0.0784,
      "step": 700
    },
    {
      "epoch": 0.6006768189509306,
      "grad_norm": 0.6795468926429749,
      "learning_rate": 4.8000564015792445e-05,
      "loss": 0.1495,
      "step": 710
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 0.15101884305477142,
      "learning_rate": 4.7972363226170333e-05,
      "loss": 0.1307,
      "step": 720
    },
    {
      "epoch": 0.6175972927241963,
      "grad_norm": 10.494664192199707,
      "learning_rate": 4.794416243654822e-05,
      "loss": 0.1626,
      "step": 730
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 18.630586624145508,
      "learning_rate": 4.7915961646926116e-05,
      "loss": 0.1586,
      "step": 740
    },
    {
      "epoch": 0.6345177664974619,
      "grad_norm": 0.2620302140712738,
      "learning_rate": 4.788776085730401e-05,
      "loss": 0.0755,
      "step": 750
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 0.09258006513118744,
      "learning_rate": 4.78595600676819e-05,
      "loss": 0.1077,
      "step": 760
    },
    {
      "epoch": 0.6514382402707276,
      "grad_norm": 0.4374638497829437,
      "learning_rate": 4.783135927805979e-05,
      "loss": 0.1392,
      "step": 770
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.67353755235672,
      "learning_rate": 4.7803158488437675e-05,
      "loss": 0.0857,
      "step": 780
    },
    {
      "epoch": 0.6683587140439933,
      "grad_norm": 19.41292381286621,
      "learning_rate": 4.777495769881557e-05,
      "loss": 0.1199,
      "step": 790
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.23480162024497986,
      "learning_rate": 4.774675690919346e-05,
      "loss": 0.0371,
      "step": 800
    },
    {
      "epoch": 0.6852791878172588,
      "grad_norm": 0.12986932694911957,
      "learning_rate": 4.771855611957135e-05,
      "loss": 0.2893,
      "step": 810
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 1.1319631338119507,
      "learning_rate": 4.769035532994924e-05,
      "loss": 0.0735,
      "step": 820
    },
    {
      "epoch": 0.7021996615905245,
      "grad_norm": 9.579446792602539,
      "learning_rate": 4.766215454032713e-05,
      "loss": 0.1398,
      "step": 830
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 33.17691421508789,
      "learning_rate": 4.763395375070502e-05,
      "loss": 0.1564,
      "step": 840
    },
    {
      "epoch": 0.7191201353637902,
      "grad_norm": 7.179660797119141,
      "learning_rate": 4.760575296108291e-05,
      "loss": 0.1506,
      "step": 850
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 4.116767883300781,
      "learning_rate": 4.7577552171460806e-05,
      "loss": 0.0688,
      "step": 860
    },
    {
      "epoch": 0.7360406091370558,
      "grad_norm": 14.570455551147461,
      "learning_rate": 4.7549351381838694e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 0.619854748249054,
      "learning_rate": 4.752115059221658e-05,
      "loss": 0.1513,
      "step": 880
    },
    {
      "epoch": 0.7529610829103215,
      "grad_norm": 5.441271781921387,
      "learning_rate": 4.7492949802594476e-05,
      "loss": 0.261,
      "step": 890
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 2.6095757484436035,
      "learning_rate": 4.7464749012972364e-05,
      "loss": 0.0479,
      "step": 900
    },
    {
      "epoch": 0.7698815566835872,
      "grad_norm": 18.807838439941406,
      "learning_rate": 4.743654822335026e-05,
      "loss": 0.0865,
      "step": 910
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 19.832582473754883,
      "learning_rate": 4.740834743372815e-05,
      "loss": 0.2682,
      "step": 920
    },
    {
      "epoch": 0.7868020304568528,
      "grad_norm": 23.313390731811523,
      "learning_rate": 4.7380146644106035e-05,
      "loss": 0.1621,
      "step": 930
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 2.7553422451019287,
      "learning_rate": 4.735194585448392e-05,
      "loss": 0.1222,
      "step": 940
    },
    {
      "epoch": 0.8037225042301185,
      "grad_norm": 0.5432969331741333,
      "learning_rate": 4.732374506486182e-05,
      "loss": 0.083,
      "step": 950
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 11.276805877685547,
      "learning_rate": 4.729554427523971e-05,
      "loss": 0.0629,
      "step": 960
    },
    {
      "epoch": 0.8206429780033841,
      "grad_norm": 5.896979331970215,
      "learning_rate": 4.72673434856176e-05,
      "loss": 0.1201,
      "step": 970
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 16.9703426361084,
      "learning_rate": 4.7239142695995495e-05,
      "loss": 0.121,
      "step": 980
    },
    {
      "epoch": 0.8375634517766497,
      "grad_norm": 0.12442143261432648,
      "learning_rate": 4.7210941906373376e-05,
      "loss": 0.1755,
      "step": 990
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 0.058043692260980606,
      "learning_rate": 4.718274111675127e-05,
      "loss": 0.1251,
      "step": 1000
    },
    {
      "epoch": 0.8544839255499154,
      "grad_norm": 42.14734649658203,
      "learning_rate": 4.715454032712916e-05,
      "loss": 0.1367,
      "step": 1010
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 26.698923110961914,
      "learning_rate": 4.7126339537507054e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.871404399323181,
      "grad_norm": 3.701037645339966,
      "learning_rate": 4.709813874788495e-05,
      "loss": 0.2048,
      "step": 1030
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 12.624013900756836,
      "learning_rate": 4.706993795826283e-05,
      "loss": 0.1073,
      "step": 1040
    },
    {
      "epoch": 0.8883248730964467,
      "grad_norm": 30.081945419311523,
      "learning_rate": 4.7041737168640724e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 24.828798294067383,
      "learning_rate": 4.701353637901861e-05,
      "loss": 0.087,
      "step": 1060
    },
    {
      "epoch": 0.9052453468697124,
      "grad_norm": 27.589454650878906,
      "learning_rate": 4.698533558939651e-05,
      "loss": 0.0654,
      "step": 1070
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.207147598266602,
      "learning_rate": 4.6957134799774395e-05,
      "loss": 0.0868,
      "step": 1080
    },
    {
      "epoch": 0.922165820642978,
      "grad_norm": 1.1621407270431519,
      "learning_rate": 4.692893401015229e-05,
      "loss": 0.0359,
      "step": 1090
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 42.396610260009766,
      "learning_rate": 4.690073322053018e-05,
      "loss": 0.1143,
      "step": 1100
    },
    {
      "epoch": 0.9390862944162437,
      "grad_norm": 21.23570442199707,
      "learning_rate": 4.6872532430908066e-05,
      "loss": 0.1539,
      "step": 1110
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.07133467495441437,
      "learning_rate": 4.684433164128596e-05,
      "loss": 0.0776,
      "step": 1120
    },
    {
      "epoch": 0.9560067681895094,
      "grad_norm": 1.5074037313461304,
      "learning_rate": 4.681613085166385e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 18.812101364135742,
      "learning_rate": 4.678793006204174e-05,
      "loss": 0.0749,
      "step": 1140
    },
    {
      "epoch": 0.9729272419627749,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.675972927241963e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.9813874788494078,
      "grad_norm": 2.271929979324341,
      "learning_rate": 4.673152848279752e-05,
      "loss": 0.1919,
      "step": 1160
    },
    {
      "epoch": 0.9898477157360406,
      "grad_norm": 5.057013034820557,
      "learning_rate": 4.6703327693175414e-05,
      "loss": 0.0771,
      "step": 1170
    },
    {
      "epoch": 0.9983079526226735,
      "grad_norm": 10.19404411315918,
      "learning_rate": 4.66751269035533e-05,
      "loss": 0.0594,
      "step": 1180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9690740740740741,
      "eval_loss": 0.11386065185070038,
      "eval_runtime": 246.4452,
      "eval_samples_per_second": 21.912,
      "eval_steps_per_second": 2.739,
      "step": 1182
    },
    {
      "epoch": 1.0067681895093064,
      "grad_norm": 0.0524885393679142,
      "learning_rate": 4.6646926113931197e-05,
      "loss": 0.1154,
      "step": 1190
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 0.2056097388267517,
      "learning_rate": 4.6618725324309085e-05,
      "loss": 0.0667,
      "step": 1200
    },
    {
      "epoch": 1.023688663282572,
      "grad_norm": 0.31934717297554016,
      "learning_rate": 4.659052453468697e-05,
      "loss": 0.0517,
      "step": 1210
    },
    {
      "epoch": 1.0321489001692048,
      "grad_norm": 0.44508466124534607,
      "learning_rate": 4.656232374506486e-05,
      "loss": 0.0806,
      "step": 1220
    },
    {
      "epoch": 1.0406091370558375,
      "grad_norm": 17.873205184936523,
      "learning_rate": 4.6534122955442755e-05,
      "loss": 0.1168,
      "step": 1230
    },
    {
      "epoch": 1.0490693739424704,
      "grad_norm": 0.1031579002737999,
      "learning_rate": 4.650592216582065e-05,
      "loss": 0.0885,
      "step": 1240
    },
    {
      "epoch": 1.0575296108291032,
      "grad_norm": 1.859145998954773,
      "learning_rate": 4.647772137619854e-05,
      "loss": 0.0546,
      "step": 1250
    },
    {
      "epoch": 1.0659898477157361,
      "grad_norm": 2.6971371173858643,
      "learning_rate": 4.6449520586576426e-05,
      "loss": 0.0586,
      "step": 1260
    },
    {
      "epoch": 1.0744500846023688,
      "grad_norm": 3.4226748943328857,
      "learning_rate": 4.6421319796954314e-05,
      "loss": 0.1291,
      "step": 1270
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.06498179584741592,
      "learning_rate": 4.639311900733221e-05,
      "loss": 0.0912,
      "step": 1280
    },
    {
      "epoch": 1.0913705583756346,
      "grad_norm": 2.8320469856262207,
      "learning_rate": 4.6364918217710097e-05,
      "loss": 0.0783,
      "step": 1290
    },
    {
      "epoch": 1.0998307952622675,
      "grad_norm": 0.09660017490386963,
      "learning_rate": 4.633671742808799e-05,
      "loss": 0.0907,
      "step": 1300
    },
    {
      "epoch": 1.1082910321489001,
      "grad_norm": 0.13180534541606903,
      "learning_rate": 4.630851663846588e-05,
      "loss": 0.0413,
      "step": 1310
    },
    {
      "epoch": 1.116751269035533,
      "grad_norm": 0.16015172004699707,
      "learning_rate": 4.628031584884377e-05,
      "loss": 0.0407,
      "step": 1320
    },
    {
      "epoch": 1.125211505922166,
      "grad_norm": 9.34089469909668,
      "learning_rate": 4.625211505922166e-05,
      "loss": 0.1045,
      "step": 1330
    },
    {
      "epoch": 1.1336717428087986,
      "grad_norm": 24.051116943359375,
      "learning_rate": 4.622391426959955e-05,
      "loss": 0.0467,
      "step": 1340
    },
    {
      "epoch": 1.1421319796954315,
      "grad_norm": 9.480792045593262,
      "learning_rate": 4.6195713479977445e-05,
      "loss": 0.1429,
      "step": 1350
    },
    {
      "epoch": 1.1505922165820643,
      "grad_norm": 0.2971787750720978,
      "learning_rate": 4.616751269035533e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 1.1590524534686972,
      "grad_norm": 1.4138188362121582,
      "learning_rate": 4.613931190073322e-05,
      "loss": 0.0279,
      "step": 1370
    },
    {
      "epoch": 1.16751269035533,
      "grad_norm": 26.05870246887207,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0514,
      "step": 1380
    },
    {
      "epoch": 1.1759729272419628,
      "grad_norm": 0.014784063212573528,
      "learning_rate": 4.6082910321489e-05,
      "loss": 0.0145,
      "step": 1390
    },
    {
      "epoch": 1.1844331641285957,
      "grad_norm": 3.2919983863830566,
      "learning_rate": 4.60547095318669e-05,
      "loss": 0.0022,
      "step": 1400
    },
    {
      "epoch": 1.1928934010152283,
      "grad_norm": 20.8558349609375,
      "learning_rate": 4.6026508742244786e-05,
      "loss": 0.1509,
      "step": 1410
    },
    {
      "epoch": 1.2013536379018612,
      "grad_norm": 1.2578448057174683,
      "learning_rate": 4.5998307952622674e-05,
      "loss": 0.0209,
      "step": 1420
    },
    {
      "epoch": 1.2098138747884941,
      "grad_norm": 20.923458099365234,
      "learning_rate": 4.597010716300056e-05,
      "loss": 0.0547,
      "step": 1430
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 0.0193844735622406,
      "learning_rate": 4.594190637337846e-05,
      "loss": 0.178,
      "step": 1440
    },
    {
      "epoch": 1.2267343485617597,
      "grad_norm": 0.34279999136924744,
      "learning_rate": 4.591370558375635e-05,
      "loss": 0.0055,
      "step": 1450
    },
    {
      "epoch": 1.2351945854483926,
      "grad_norm": 0.713297963142395,
      "learning_rate": 4.588550479413424e-05,
      "loss": 0.0185,
      "step": 1460
    },
    {
      "epoch": 1.2436548223350254,
      "grad_norm": 0.06155781447887421,
      "learning_rate": 4.585730400451213e-05,
      "loss": 0.0267,
      "step": 1470
    },
    {
      "epoch": 1.252115059221658,
      "grad_norm": 15.050272941589355,
      "learning_rate": 4.5829103214890015e-05,
      "loss": 0.1215,
      "step": 1480
    },
    {
      "epoch": 1.260575296108291,
      "grad_norm": 2.018648386001587,
      "learning_rate": 4.580090242526791e-05,
      "loss": 0.0928,
      "step": 1490
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 26.905744552612305,
      "learning_rate": 4.57727016356458e-05,
      "loss": 0.0494,
      "step": 1500
    },
    {
      "epoch": 1.2774957698815568,
      "grad_norm": 0.08350187540054321,
      "learning_rate": 4.574450084602369e-05,
      "loss": 0.0409,
      "step": 1510
    },
    {
      "epoch": 1.2859560067681894,
      "grad_norm": 0.1177479475736618,
      "learning_rate": 4.571630005640159e-05,
      "loss": 0.1218,
      "step": 1520
    },
    {
      "epoch": 1.2944162436548223,
      "grad_norm": 14.32288932800293,
      "learning_rate": 4.568809926677947e-05,
      "loss": 0.1414,
      "step": 1530
    },
    {
      "epoch": 1.3028764805414552,
      "grad_norm": 0.8191991448402405,
      "learning_rate": 4.5659898477157363e-05,
      "loss": 0.0487,
      "step": 1540
    },
    {
      "epoch": 1.3113367174280879,
      "grad_norm": 1.2151057720184326,
      "learning_rate": 4.563169768753525e-05,
      "loss": 0.0101,
      "step": 1550
    },
    {
      "epoch": 1.3197969543147208,
      "grad_norm": 22.795188903808594,
      "learning_rate": 4.5603496897913146e-05,
      "loss": 0.056,
      "step": 1560
    },
    {
      "epoch": 1.3282571912013537,
      "grad_norm": 24.174396514892578,
      "learning_rate": 4.5575296108291034e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 1.3367174280879865,
      "grad_norm": 20.76497459411621,
      "learning_rate": 4.554709531866892e-05,
      "loss": 0.2546,
      "step": 1580
    },
    {
      "epoch": 1.3451776649746192,
      "grad_norm": 44.310550689697266,
      "learning_rate": 4.551889452904681e-05,
      "loss": 0.1427,
      "step": 1590
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 0.04374610632658005,
      "learning_rate": 4.5490693739424705e-05,
      "loss": 0.1959,
      "step": 1600
    },
    {
      "epoch": 1.362098138747885,
      "grad_norm": 6.750633716583252,
      "learning_rate": 4.54624929498026e-05,
      "loss": 0.0342,
      "step": 1610
    },
    {
      "epoch": 1.3705583756345177,
      "grad_norm": 0.28728750348091125,
      "learning_rate": 4.543429216018049e-05,
      "loss": 0.0333,
      "step": 1620
    },
    {
      "epoch": 1.3790186125211505,
      "grad_norm": 1.095624566078186,
      "learning_rate": 4.540609137055838e-05,
      "loss": 0.055,
      "step": 1630
    },
    {
      "epoch": 1.3874788494077834,
      "grad_norm": 0.1793481707572937,
      "learning_rate": 4.5377890580936263e-05,
      "loss": 0.0789,
      "step": 1640
    },
    {
      "epoch": 1.3959390862944163,
      "grad_norm": 0.10460668057203293,
      "learning_rate": 4.534968979131416e-05,
      "loss": 0.1204,
      "step": 1650
    },
    {
      "epoch": 1.404399323181049,
      "grad_norm": 0.17484290897846222,
      "learning_rate": 4.5321489001692046e-05,
      "loss": 0.0569,
      "step": 1660
    },
    {
      "epoch": 1.4128595600676819,
      "grad_norm": 2.5536487102508545,
      "learning_rate": 4.529328821206994e-05,
      "loss": 0.0966,
      "step": 1670
    },
    {
      "epoch": 1.4213197969543148,
      "grad_norm": 0.033308885991573334,
      "learning_rate": 4.5265087422447836e-05,
      "loss": 0.0455,
      "step": 1680
    },
    {
      "epoch": 1.4297800338409474,
      "grad_norm": 0.03772977367043495,
      "learning_rate": 4.523688663282572e-05,
      "loss": 0.1548,
      "step": 1690
    },
    {
      "epoch": 1.4382402707275803,
      "grad_norm": 0.09216587990522385,
      "learning_rate": 4.520868584320361e-05,
      "loss": 0.05,
      "step": 1700
    },
    {
      "epoch": 1.4467005076142132,
      "grad_norm": 0.03644145280122757,
      "learning_rate": 4.51804850535815e-05,
      "loss": 0.0294,
      "step": 1710
    },
    {
      "epoch": 1.455160744500846,
      "grad_norm": 0.005973259452730417,
      "learning_rate": 4.5152284263959394e-05,
      "loss": 0.0558,
      "step": 1720
    },
    {
      "epoch": 1.463620981387479,
      "grad_norm": 0.24085456132888794,
      "learning_rate": 4.512408347433728e-05,
      "loss": 0.055,
      "step": 1730
    },
    {
      "epoch": 1.4720812182741116,
      "grad_norm": 0.006745295133441687,
      "learning_rate": 4.509588268471518e-05,
      "loss": 0.0501,
      "step": 1740
    },
    {
      "epoch": 1.4805414551607445,
      "grad_norm": 0.49678128957748413,
      "learning_rate": 4.5067681895093065e-05,
      "loss": 0.0194,
      "step": 1750
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.2952556610107422,
      "learning_rate": 4.503948110547095e-05,
      "loss": 0.0893,
      "step": 1760
    },
    {
      "epoch": 1.49746192893401,
      "grad_norm": 1.9802641868591309,
      "learning_rate": 4.501128031584885e-05,
      "loss": 0.0114,
      "step": 1770
    },
    {
      "epoch": 1.505922165820643,
      "grad_norm": 0.016201358288526535,
      "learning_rate": 4.4983079526226736e-05,
      "loss": 0.1306,
      "step": 1780
    },
    {
      "epoch": 1.5143824027072759,
      "grad_norm": 0.2131015509366989,
      "learning_rate": 4.495487873660463e-05,
      "loss": 0.0282,
      "step": 1790
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 0.1275821179151535,
      "learning_rate": 4.492667794698252e-05,
      "loss": 0.0732,
      "step": 1800
    },
    {
      "epoch": 1.5313028764805414,
      "grad_norm": 32.563453674316406,
      "learning_rate": 4.4898477157360406e-05,
      "loss": 0.0461,
      "step": 1810
    },
    {
      "epoch": 1.5397631133671743,
      "grad_norm": 0.01262142974883318,
      "learning_rate": 4.48702763677383e-05,
      "loss": 0.0382,
      "step": 1820
    },
    {
      "epoch": 1.548223350253807,
      "grad_norm": 3.734633207321167,
      "learning_rate": 4.484207557811619e-05,
      "loss": 0.0036,
      "step": 1830
    },
    {
      "epoch": 1.5566835871404399,
      "grad_norm": 0.026379531249403954,
      "learning_rate": 4.4813874788494084e-05,
      "loss": 0.0045,
      "step": 1840
    },
    {
      "epoch": 1.5651438240270727,
      "grad_norm": 0.006282446440309286,
      "learning_rate": 4.478567399887197e-05,
      "loss": 0.0065,
      "step": 1850
    },
    {
      "epoch": 1.5736040609137056,
      "grad_norm": 0.3327971398830414,
      "learning_rate": 4.475747320924986e-05,
      "loss": 0.0198,
      "step": 1860
    },
    {
      "epoch": 1.5820642978003385,
      "grad_norm": 0.11799824237823486,
      "learning_rate": 4.472927241962775e-05,
      "loss": 0.1285,
      "step": 1870
    },
    {
      "epoch": 1.5905245346869712,
      "grad_norm": 0.005150949582457542,
      "learning_rate": 4.470107163000564e-05,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 1.598984771573604,
      "grad_norm": 20.945222854614258,
      "learning_rate": 4.467287084038354e-05,
      "loss": 0.0764,
      "step": 1890
    },
    {
      "epoch": 1.6074450084602367,
      "grad_norm": 14.346229553222656,
      "learning_rate": 4.4644670050761425e-05,
      "loss": 0.052,
      "step": 1900
    },
    {
      "epoch": 1.6159052453468696,
      "grad_norm": 0.4961164593696594,
      "learning_rate": 4.461646926113931e-05,
      "loss": 0.0594,
      "step": 1910
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 0.05455700308084488,
      "learning_rate": 4.45882684715172e-05,
      "loss": 0.1213,
      "step": 1920
    },
    {
      "epoch": 1.6328257191201354,
      "grad_norm": 35.61746597290039,
      "learning_rate": 4.4560067681895096e-05,
      "loss": 0.1965,
      "step": 1930
    },
    {
      "epoch": 1.6412859560067683,
      "grad_norm": 0.14853937923908234,
      "learning_rate": 4.4531866892272984e-05,
      "loss": 0.071,
      "step": 1940
    },
    {
      "epoch": 1.649746192893401,
      "grad_norm": 29.400121688842773,
      "learning_rate": 4.450366610265088e-05,
      "loss": 0.1181,
      "step": 1950
    },
    {
      "epoch": 1.6582064297800339,
      "grad_norm": 26.16289520263672,
      "learning_rate": 4.4475465313028766e-05,
      "loss": 0.0451,
      "step": 1960
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 16.397777557373047,
      "learning_rate": 4.4447264523406654e-05,
      "loss": 0.0818,
      "step": 1970
    },
    {
      "epoch": 1.6751269035532994,
      "grad_norm": 0.09849713742733002,
      "learning_rate": 4.441906373378455e-05,
      "loss": 0.0955,
      "step": 1980
    },
    {
      "epoch": 1.6835871404399323,
      "grad_norm": 7.682143211364746,
      "learning_rate": 4.439086294416244e-05,
      "loss": 0.1323,
      "step": 1990
    },
    {
      "epoch": 1.6920473773265652,
      "grad_norm": 0.6320121884346008,
      "learning_rate": 4.436266215454033e-05,
      "loss": 0.1091,
      "step": 2000
    },
    {
      "epoch": 1.700507614213198,
      "grad_norm": 0.12847696244716644,
      "learning_rate": 4.433446136491822e-05,
      "loss": 0.0281,
      "step": 2010
    },
    {
      "epoch": 1.708967851099831,
      "grad_norm": 15.028797149658203,
      "learning_rate": 4.430626057529611e-05,
      "loss": 0.0261,
      "step": 2020
    },
    {
      "epoch": 1.7174280879864636,
      "grad_norm": 0.01604713872075081,
      "learning_rate": 4.4278059785674e-05,
      "loss": 0.0013,
      "step": 2030
    },
    {
      "epoch": 1.7258883248730963,
      "grad_norm": 17.731983184814453,
      "learning_rate": 4.424985899605189e-05,
      "loss": 0.0434,
      "step": 2040
    },
    {
      "epoch": 1.7343485617597292,
      "grad_norm": 0.12152490019798279,
      "learning_rate": 4.4221658206429785e-05,
      "loss": 0.0606,
      "step": 2050
    },
    {
      "epoch": 1.742808798646362,
      "grad_norm": 0.003514975542202592,
      "learning_rate": 4.419345741680767e-05,
      "loss": 0.0556,
      "step": 2060
    },
    {
      "epoch": 1.751269035532995,
      "grad_norm": 2.6348941326141357,
      "learning_rate": 4.416525662718556e-05,
      "loss": 0.1486,
      "step": 2070
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 21.712257385253906,
      "learning_rate": 4.413705583756345e-05,
      "loss": 0.1412,
      "step": 2080
    },
    {
      "epoch": 1.7681895093062607,
      "grad_norm": 0.0020400604698807,
      "learning_rate": 4.4108855047941344e-05,
      "loss": 0.069,
      "step": 2090
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 13.40526294708252,
      "learning_rate": 4.408065425831924e-05,
      "loss": 0.0379,
      "step": 2100
    },
    {
      "epoch": 1.785109983079526,
      "grad_norm": 0.07841428369283676,
      "learning_rate": 4.4052453468697127e-05,
      "loss": 0.0338,
      "step": 2110
    },
    {
      "epoch": 1.793570219966159,
      "grad_norm": 21.989072799682617,
      "learning_rate": 4.4024252679075015e-05,
      "loss": 0.0383,
      "step": 2120
    },
    {
      "epoch": 1.8020304568527918,
      "grad_norm": 8.322708129882812,
      "learning_rate": 4.39960518894529e-05,
      "loss": 0.1942,
      "step": 2130
    },
    {
      "epoch": 1.8104906937394247,
      "grad_norm": 0.019643452018499374,
      "learning_rate": 4.39678510998308e-05,
      "loss": 0.0736,
      "step": 2140
    },
    {
      "epoch": 1.8189509306260576,
      "grad_norm": 37.64115524291992,
      "learning_rate": 4.3939650310208685e-05,
      "loss": 0.1089,
      "step": 2150
    },
    {
      "epoch": 1.8274111675126905,
      "grad_norm": 12.482965469360352,
      "learning_rate": 4.391144952058658e-05,
      "loss": 0.1011,
      "step": 2160
    },
    {
      "epoch": 1.8358714043993232,
      "grad_norm": 0.03910377621650696,
      "learning_rate": 4.3883248730964475e-05,
      "loss": 0.093,
      "step": 2170
    },
    {
      "epoch": 1.844331641285956,
      "grad_norm": 1.2610856294631958,
      "learning_rate": 4.3855047941342356e-05,
      "loss": 0.0736,
      "step": 2180
    },
    {
      "epoch": 1.8527918781725887,
      "grad_norm": 15.85295295715332,
      "learning_rate": 4.382684715172025e-05,
      "loss": 0.1832,
      "step": 2190
    },
    {
      "epoch": 1.8612521150592216,
      "grad_norm": 0.31547269225120544,
      "learning_rate": 4.379864636209814e-05,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 1.8697123519458545,
      "grad_norm": 0.3832317292690277,
      "learning_rate": 4.377044557247603e-05,
      "loss": 0.0473,
      "step": 2210
    },
    {
      "epoch": 1.8781725888324874,
      "grad_norm": 0.0396120585501194,
      "learning_rate": 4.374224478285392e-05,
      "loss": 0.0631,
      "step": 2220
    },
    {
      "epoch": 1.8866328257191203,
      "grad_norm": 0.14707453548908234,
      "learning_rate": 4.371404399323181e-05,
      "loss": 0.0929,
      "step": 2230
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 0.01668008789420128,
      "learning_rate": 4.3685843203609704e-05,
      "loss": 0.0821,
      "step": 2240
    },
    {
      "epoch": 1.9035532994923858,
      "grad_norm": 0.11122526228427887,
      "learning_rate": 4.365764241398759e-05,
      "loss": 0.1329,
      "step": 2250
    },
    {
      "epoch": 1.9120135363790185,
      "grad_norm": 35.64632797241211,
      "learning_rate": 4.362944162436549e-05,
      "loss": 0.0724,
      "step": 2260
    },
    {
      "epoch": 1.9204737732656514,
      "grad_norm": 0.12160845100879669,
      "learning_rate": 4.3601240834743375e-05,
      "loss": 0.0693,
      "step": 2270
    },
    {
      "epoch": 1.9289340101522843,
      "grad_norm": 0.010136724449694157,
      "learning_rate": 4.357304004512127e-05,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 1.9373942470389172,
      "grad_norm": 0.020088551566004753,
      "learning_rate": 4.354483925549915e-05,
      "loss": 0.0402,
      "step": 2290
    },
    {
      "epoch": 1.94585448392555,
      "grad_norm": 0.01234954409301281,
      "learning_rate": 4.3516638465877045e-05,
      "loss": 0.0293,
      "step": 2300
    },
    {
      "epoch": 1.9543147208121827,
      "grad_norm": 1.4190717935562134,
      "learning_rate": 4.348843767625494e-05,
      "loss": 0.1906,
      "step": 2310
    },
    {
      "epoch": 1.9627749576988156,
      "grad_norm": 0.010624142363667488,
      "learning_rate": 4.346023688663283e-05,
      "loss": 0.0392,
      "step": 2320
    },
    {
      "epoch": 1.9712351945854483,
      "grad_norm": 22.869890213012695,
      "learning_rate": 4.343203609701072e-05,
      "loss": 0.0536,
      "step": 2330
    },
    {
      "epoch": 1.9796954314720812,
      "grad_norm": 0.01851845346391201,
      "learning_rate": 4.3403835307388604e-05,
      "loss": 0.0733,
      "step": 2340
    },
    {
      "epoch": 1.988155668358714,
      "grad_norm": 25.321544647216797,
      "learning_rate": 4.33756345177665e-05,
      "loss": 0.0828,
      "step": 2350
    },
    {
      "epoch": 1.996615905245347,
      "grad_norm": 0.037506792694330215,
      "learning_rate": 4.334743372814439e-05,
      "loss": 0.046,
      "step": 2360
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9779629629629629,
      "eval_loss": 0.09348412603139877,
      "eval_runtime": 246.6577,
      "eval_samples_per_second": 21.893,
      "eval_steps_per_second": 2.737,
      "step": 2364
    },
    {
      "epoch": 2.00507614213198,
      "grad_norm": 0.7050085067749023,
      "learning_rate": 4.331923293852228e-05,
      "loss": 0.0019,
      "step": 2370
    },
    {
      "epoch": 2.0135363790186127,
      "grad_norm": 0.004118071403354406,
      "learning_rate": 4.3291032148900176e-05,
      "loss": 0.0297,
      "step": 2380
    },
    {
      "epoch": 2.021996615905245,
      "grad_norm": 36.45760726928711,
      "learning_rate": 4.3262831359278064e-05,
      "loss": 0.0852,
      "step": 2390
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 0.002832560334354639,
      "learning_rate": 4.323463056965595e-05,
      "loss": 0.0159,
      "step": 2400
    },
    {
      "epoch": 2.038917089678511,
      "grad_norm": 0.015435759909451008,
      "learning_rate": 4.320642978003384e-05,
      "loss": 0.0082,
      "step": 2410
    },
    {
      "epoch": 2.047377326565144,
      "grad_norm": 0.06332072615623474,
      "learning_rate": 4.3178228990411735e-05,
      "loss": 0.0096,
      "step": 2420
    },
    {
      "epoch": 2.0558375634517767,
      "grad_norm": 23.606990814208984,
      "learning_rate": 4.315002820078962e-05,
      "loss": 0.096,
      "step": 2430
    },
    {
      "epoch": 2.0642978003384096,
      "grad_norm": 16.45185089111328,
      "learning_rate": 4.312182741116752e-05,
      "loss": 0.0696,
      "step": 2440
    },
    {
      "epoch": 2.0727580372250425,
      "grad_norm": 23.556838989257812,
      "learning_rate": 4.3093626621545405e-05,
      "loss": 0.0283,
      "step": 2450
    },
    {
      "epoch": 2.081218274111675,
      "grad_norm": 0.35000672936439514,
      "learning_rate": 4.3065425831923293e-05,
      "loss": 0.0263,
      "step": 2460
    },
    {
      "epoch": 2.089678510998308,
      "grad_norm": 1.4101324081420898,
      "learning_rate": 4.303722504230119e-05,
      "loss": 0.0688,
      "step": 2470
    },
    {
      "epoch": 2.0981387478849407,
      "grad_norm": 17.108341217041016,
      "learning_rate": 4.3009024252679076e-05,
      "loss": 0.1071,
      "step": 2480
    },
    {
      "epoch": 2.1065989847715736,
      "grad_norm": 4.765998363494873,
      "learning_rate": 4.298082346305697e-05,
      "loss": 0.0024,
      "step": 2490
    },
    {
      "epoch": 2.1150592216582065,
      "grad_norm": 0.18713925778865814,
      "learning_rate": 4.295262267343486e-05,
      "loss": 0.0195,
      "step": 2500
    },
    {
      "epoch": 2.1235194585448394,
      "grad_norm": 1.4044023752212524,
      "learning_rate": 4.292442188381275e-05,
      "loss": 0.0151,
      "step": 2510
    },
    {
      "epoch": 2.1319796954314723,
      "grad_norm": 0.022990819066762924,
      "learning_rate": 4.289622109419064e-05,
      "loss": 0.0006,
      "step": 2520
    },
    {
      "epoch": 2.1404399323181047,
      "grad_norm": 0.4567020535469055,
      "learning_rate": 4.286802030456853e-05,
      "loss": 0.0272,
      "step": 2530
    },
    {
      "epoch": 2.1489001692047376,
      "grad_norm": 17.143157958984375,
      "learning_rate": 4.2839819514946424e-05,
      "loss": 0.0573,
      "step": 2540
    },
    {
      "epoch": 2.1573604060913705,
      "grad_norm": 0.5564812421798706,
      "learning_rate": 4.281161872532431e-05,
      "loss": 0.0137,
      "step": 2550
    },
    {
      "epoch": 2.1658206429780034,
      "grad_norm": 1.2734674215316772,
      "learning_rate": 4.27834179357022e-05,
      "loss": 0.0527,
      "step": 2560
    },
    {
      "epoch": 2.1742808798646363,
      "grad_norm": 0.05679820850491524,
      "learning_rate": 4.275521714608009e-05,
      "loss": 0.01,
      "step": 2570
    },
    {
      "epoch": 2.182741116751269,
      "grad_norm": 0.5252026915550232,
      "learning_rate": 4.272701635645798e-05,
      "loss": 0.0544,
      "step": 2580
    },
    {
      "epoch": 2.191201353637902,
      "grad_norm": 25.15257453918457,
      "learning_rate": 4.269881556683588e-05,
      "loss": 0.0168,
      "step": 2590
    },
    {
      "epoch": 2.199661590524535,
      "grad_norm": 20.0202579498291,
      "learning_rate": 4.2670614777213766e-05,
      "loss": 0.0555,
      "step": 2600
    },
    {
      "epoch": 2.2081218274111674,
      "grad_norm": 0.0031947263050824404,
      "learning_rate": 4.2642413987591654e-05,
      "loss": 0.005,
      "step": 2610
    },
    {
      "epoch": 2.2165820642978002,
      "grad_norm": 0.019850878044962883,
      "learning_rate": 4.261421319796954e-05,
      "loss": 0.0004,
      "step": 2620
    },
    {
      "epoch": 2.225042301184433,
      "grad_norm": 3.6412107944488525,
      "learning_rate": 4.2586012408347436e-05,
      "loss": 0.0964,
      "step": 2630
    },
    {
      "epoch": 2.233502538071066,
      "grad_norm": 1.5771880149841309,
      "learning_rate": 4.2557811618725324e-05,
      "loss": 0.0219,
      "step": 2640
    },
    {
      "epoch": 2.241962774957699,
      "grad_norm": 0.00178819231223315,
      "learning_rate": 4.252961082910322e-05,
      "loss": 0.058,
      "step": 2650
    },
    {
      "epoch": 2.250423011844332,
      "grad_norm": 17.10619354248047,
      "learning_rate": 4.250141003948111e-05,
      "loss": 0.114,
      "step": 2660
    },
    {
      "epoch": 2.2588832487309647,
      "grad_norm": 0.012720372527837753,
      "learning_rate": 4.2473209249858995e-05,
      "loss": 0.0003,
      "step": 2670
    },
    {
      "epoch": 2.267343485617597,
      "grad_norm": 0.007427964825183153,
      "learning_rate": 4.244500846023689e-05,
      "loss": 0.0313,
      "step": 2680
    },
    {
      "epoch": 2.27580372250423,
      "grad_norm": 0.01936277747154236,
      "learning_rate": 4.241680767061478e-05,
      "loss": 0.0297,
      "step": 2690
    },
    {
      "epoch": 2.284263959390863,
      "grad_norm": 9.420300483703613,
      "learning_rate": 4.238860688099267e-05,
      "loss": 0.0189,
      "step": 2700
    },
    {
      "epoch": 2.292724196277496,
      "grad_norm": 0.9173603653907776,
      "learning_rate": 4.236040609137056e-05,
      "loss": 0.0659,
      "step": 2710
    },
    {
      "epoch": 2.3011844331641287,
      "grad_norm": 0.0064922175370156765,
      "learning_rate": 4.233220530174845e-05,
      "loss": 0.0816,
      "step": 2720
    },
    {
      "epoch": 2.3096446700507616,
      "grad_norm": 2.5201611518859863,
      "learning_rate": 4.230400451212634e-05,
      "loss": 0.0159,
      "step": 2730
    },
    {
      "epoch": 2.3181049069373945,
      "grad_norm": 0.01033511571586132,
      "learning_rate": 4.227580372250423e-05,
      "loss": 0.0022,
      "step": 2740
    },
    {
      "epoch": 2.326565143824027,
      "grad_norm": 0.3796350657939911,
      "learning_rate": 4.2247602932882126e-05,
      "loss": 0.0836,
      "step": 2750
    },
    {
      "epoch": 2.33502538071066,
      "grad_norm": 12.385169982910156,
      "learning_rate": 4.2219402143260014e-05,
      "loss": 0.0703,
      "step": 2760
    },
    {
      "epoch": 2.3434856175972927,
      "grad_norm": 0.017592186108231544,
      "learning_rate": 4.21912013536379e-05,
      "loss": 0.1087,
      "step": 2770
    },
    {
      "epoch": 2.3519458544839256,
      "grad_norm": 2.3975565433502197,
      "learning_rate": 4.216300056401579e-05,
      "loss": 0.0045,
      "step": 2780
    },
    {
      "epoch": 2.3604060913705585,
      "grad_norm": 0.017607372254133224,
      "learning_rate": 4.2134799774393684e-05,
      "loss": 0.0671,
      "step": 2790
    },
    {
      "epoch": 2.3688663282571913,
      "grad_norm": 3.5394468307495117,
      "learning_rate": 4.210659898477158e-05,
      "loss": 0.0218,
      "step": 2800
    },
    {
      "epoch": 2.3773265651438242,
      "grad_norm": 0.16227824985980988,
      "learning_rate": 4.207839819514947e-05,
      "loss": 0.0023,
      "step": 2810
    },
    {
      "epoch": 2.3857868020304567,
      "grad_norm": 2.4429545402526855,
      "learning_rate": 4.2050197405527355e-05,
      "loss": 0.0355,
      "step": 2820
    },
    {
      "epoch": 2.3942470389170896,
      "grad_norm": 0.008337924256920815,
      "learning_rate": 4.202199661590524e-05,
      "loss": 0.1437,
      "step": 2830
    },
    {
      "epoch": 2.4027072758037225,
      "grad_norm": 24.83634376525879,
      "learning_rate": 4.199379582628314e-05,
      "loss": 0.0725,
      "step": 2840
    },
    {
      "epoch": 2.4111675126903553,
      "grad_norm": 0.06213049590587616,
      "learning_rate": 4.1965595036661026e-05,
      "loss": 0.0635,
      "step": 2850
    },
    {
      "epoch": 2.4196277495769882,
      "grad_norm": 0.005098477005958557,
      "learning_rate": 4.193739424703892e-05,
      "loss": 0.0236,
      "step": 2860
    },
    {
      "epoch": 2.428087986463621,
      "grad_norm": 0.012588235549628735,
      "learning_rate": 4.1909193457416815e-05,
      "loss": 0.0025,
      "step": 2870
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 17.291196823120117,
      "learning_rate": 4.1880992667794696e-05,
      "loss": 0.0647,
      "step": 2880
    },
    {
      "epoch": 2.4450084602368864,
      "grad_norm": 0.05634631961584091,
      "learning_rate": 4.185279187817259e-05,
      "loss": 0.0087,
      "step": 2890
    },
    {
      "epoch": 2.4534686971235193,
      "grad_norm": 0.00411198940128088,
      "learning_rate": 4.182459108855048e-05,
      "loss": 0.0491,
      "step": 2900
    },
    {
      "epoch": 2.4619289340101522,
      "grad_norm": 0.02043735422194004,
      "learning_rate": 4.1796390298928374e-05,
      "loss": 0.0304,
      "step": 2910
    },
    {
      "epoch": 2.470389170896785,
      "grad_norm": 0.20278824865818024,
      "learning_rate": 4.176818950930626e-05,
      "loss": 0.0616,
      "step": 2920
    },
    {
      "epoch": 2.478849407783418,
      "grad_norm": 0.005257409065961838,
      "learning_rate": 4.1739988719684157e-05,
      "loss": 0.074,
      "step": 2930
    },
    {
      "epoch": 2.487309644670051,
      "grad_norm": 0.013093408197164536,
      "learning_rate": 4.1711787930062045e-05,
      "loss": 0.0489,
      "step": 2940
    },
    {
      "epoch": 2.495769881556684,
      "grad_norm": 15.578856468200684,
      "learning_rate": 4.168358714043993e-05,
      "loss": 0.0064,
      "step": 2950
    },
    {
      "epoch": 2.504230118443316,
      "grad_norm": 0.6917970776557922,
      "learning_rate": 4.165538635081783e-05,
      "loss": 0.0027,
      "step": 2960
    },
    {
      "epoch": 2.512690355329949,
      "grad_norm": 3.800091028213501,
      "learning_rate": 4.1627185561195715e-05,
      "loss": 0.0687,
      "step": 2970
    },
    {
      "epoch": 2.521150592216582,
      "grad_norm": 14.703471183776855,
      "learning_rate": 4.159898477157361e-05,
      "loss": 0.0388,
      "step": 2980
    },
    {
      "epoch": 2.529610829103215,
      "grad_norm": 0.030179444700479507,
      "learning_rate": 4.157078398195149e-05,
      "loss": 0.0036,
      "step": 2990
    },
    {
      "epoch": 2.5380710659898478,
      "grad_norm": 0.00749274343252182,
      "learning_rate": 4.1542583192329386e-05,
      "loss": 0.0162,
      "step": 3000
    },
    {
      "epoch": 2.5465313028764807,
      "grad_norm": 5.890507698059082,
      "learning_rate": 4.151438240270728e-05,
      "loss": 0.0182,
      "step": 3010
    },
    {
      "epoch": 2.5549915397631136,
      "grad_norm": 1.79206120967865,
      "learning_rate": 4.148618161308517e-05,
      "loss": 0.0032,
      "step": 3020
    },
    {
      "epoch": 2.563451776649746,
      "grad_norm": 0.002368614310398698,
      "learning_rate": 4.145798082346306e-05,
      "loss": 0.051,
      "step": 3030
    },
    {
      "epoch": 2.571912013536379,
      "grad_norm": 0.387143075466156,
      "learning_rate": 4.142978003384095e-05,
      "loss": 0.086,
      "step": 3040
    },
    {
      "epoch": 2.5803722504230118,
      "grad_norm": 0.14291664958000183,
      "learning_rate": 4.140157924421884e-05,
      "loss": 0.0548,
      "step": 3050
    },
    {
      "epoch": 2.5888324873096447,
      "grad_norm": 0.004535431042313576,
      "learning_rate": 4.137337845459673e-05,
      "loss": 0.029,
      "step": 3060
    },
    {
      "epoch": 2.5972927241962775,
      "grad_norm": 0.10469698160886765,
      "learning_rate": 4.134517766497462e-05,
      "loss": 0.0057,
      "step": 3070
    },
    {
      "epoch": 2.6057529610829104,
      "grad_norm": 0.3293409049510956,
      "learning_rate": 4.131697687535252e-05,
      "loss": 0.0774,
      "step": 3080
    },
    {
      "epoch": 2.6142131979695433,
      "grad_norm": 32.15681076049805,
      "learning_rate": 4.1288776085730405e-05,
      "loss": 0.0603,
      "step": 3090
    },
    {
      "epoch": 2.6226734348561758,
      "grad_norm": 0.0024791238829493523,
      "learning_rate": 4.126057529610829e-05,
      "loss": 0.0064,
      "step": 3100
    },
    {
      "epoch": 2.6311336717428087,
      "grad_norm": 0.0034042412880808115,
      "learning_rate": 4.123237450648618e-05,
      "loss": 0.0128,
      "step": 3110
    },
    {
      "epoch": 2.6395939086294415,
      "grad_norm": 0.0038752921391278505,
      "learning_rate": 4.1204173716864075e-05,
      "loss": 0.0358,
      "step": 3120
    },
    {
      "epoch": 2.6480541455160744,
      "grad_norm": 0.008329003117978573,
      "learning_rate": 4.117597292724196e-05,
      "loss": 0.0334,
      "step": 3130
    },
    {
      "epoch": 2.6565143824027073,
      "grad_norm": 31.37432289123535,
      "learning_rate": 4.114777213761986e-05,
      "loss": 0.2025,
      "step": 3140
    },
    {
      "epoch": 2.66497461928934,
      "grad_norm": 0.0014850286534056067,
      "learning_rate": 4.1119571347997746e-05,
      "loss": 0.0929,
      "step": 3150
    },
    {
      "epoch": 2.673434856175973,
      "grad_norm": 4.7359771728515625,
      "learning_rate": 4.1091370558375634e-05,
      "loss": 0.0943,
      "step": 3160
    },
    {
      "epoch": 2.6818950930626055,
      "grad_norm": 0.014216204173862934,
      "learning_rate": 4.106316976875353e-05,
      "loss": 0.0145,
      "step": 3170
    },
    {
      "epoch": 2.6903553299492384,
      "grad_norm": 2.0783638954162598,
      "learning_rate": 4.103496897913142e-05,
      "loss": 0.0228,
      "step": 3180
    },
    {
      "epoch": 2.6988155668358713,
      "grad_norm": 3.2795324325561523,
      "learning_rate": 4.100676818950931e-05,
      "loss": 0.0169,
      "step": 3190
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 0.0433700792491436,
      "learning_rate": 4.09785673998872e-05,
      "loss": 0.0612,
      "step": 3200
    },
    {
      "epoch": 2.715736040609137,
      "grad_norm": 32.12123489379883,
      "learning_rate": 4.095036661026509e-05,
      "loss": 0.0217,
      "step": 3210
    },
    {
      "epoch": 2.72419627749577,
      "grad_norm": 0.8155362010002136,
      "learning_rate": 4.092216582064298e-05,
      "loss": 0.0118,
      "step": 3220
    },
    {
      "epoch": 2.732656514382403,
      "grad_norm": 0.2179349660873413,
      "learning_rate": 4.089396503102087e-05,
      "loss": 0.0145,
      "step": 3230
    },
    {
      "epoch": 2.7411167512690353,
      "grad_norm": 1.4932093620300293,
      "learning_rate": 4.0865764241398765e-05,
      "loss": 0.0233,
      "step": 3240
    },
    {
      "epoch": 2.749576988155668,
      "grad_norm": 0.00364291830919683,
      "learning_rate": 4.083756345177665e-05,
      "loss": 0.1643,
      "step": 3250
    },
    {
      "epoch": 2.758037225042301,
      "grad_norm": 0.09596369415521622,
      "learning_rate": 4.080936266215454e-05,
      "loss": 0.0446,
      "step": 3260
    },
    {
      "epoch": 2.766497461928934,
      "grad_norm": 0.9563506245613098,
      "learning_rate": 4.078116187253243e-05,
      "loss": 0.0277,
      "step": 3270
    },
    {
      "epoch": 2.774957698815567,
      "grad_norm": 1.0228968858718872,
      "learning_rate": 4.0752961082910323e-05,
      "loss": 0.0641,
      "step": 3280
    },
    {
      "epoch": 2.7834179357021998,
      "grad_norm": 0.7322272062301636,
      "learning_rate": 4.072476029328822e-05,
      "loss": 0.0704,
      "step": 3290
    },
    {
      "epoch": 2.7918781725888326,
      "grad_norm": 0.010357234627008438,
      "learning_rate": 4.0696559503666106e-05,
      "loss": 0.0566,
      "step": 3300
    },
    {
      "epoch": 2.800338409475465,
      "grad_norm": 2.28533935546875,
      "learning_rate": 4.0668358714043994e-05,
      "loss": 0.0015,
      "step": 3310
    },
    {
      "epoch": 2.808798646362098,
      "grad_norm": 71.36479187011719,
      "learning_rate": 4.064015792442188e-05,
      "loss": 0.0601,
      "step": 3320
    },
    {
      "epoch": 2.817258883248731,
      "grad_norm": 18.460063934326172,
      "learning_rate": 4.061195713479978e-05,
      "loss": 0.0596,
      "step": 3330
    },
    {
      "epoch": 2.8257191201353637,
      "grad_norm": 2.5516769886016846,
      "learning_rate": 4.0583756345177665e-05,
      "loss": 0.1339,
      "step": 3340
    },
    {
      "epoch": 2.8341793570219966,
      "grad_norm": 20.99701690673828,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0503,
      "step": 3350
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 0.01821170188486576,
      "learning_rate": 4.052735476593345e-05,
      "loss": 0.0102,
      "step": 3360
    },
    {
      "epoch": 2.8510998307952624,
      "grad_norm": 29.11432647705078,
      "learning_rate": 4.0499153976311335e-05,
      "loss": 0.1441,
      "step": 3370
    },
    {
      "epoch": 2.859560067681895,
      "grad_norm": 1.1221740245819092,
      "learning_rate": 4.047095318668923e-05,
      "loss": 0.022,
      "step": 3380
    },
    {
      "epoch": 2.868020304568528,
      "grad_norm": 0.015179646201431751,
      "learning_rate": 4.044275239706712e-05,
      "loss": 0.0715,
      "step": 3390
    },
    {
      "epoch": 2.8764805414551606,
      "grad_norm": 0.0020357100293040276,
      "learning_rate": 4.041455160744501e-05,
      "loss": 0.1299,
      "step": 3400
    },
    {
      "epoch": 2.8849407783417935,
      "grad_norm": 27.842060089111328,
      "learning_rate": 4.03863508178229e-05,
      "loss": 0.0664,
      "step": 3410
    },
    {
      "epoch": 2.8934010152284264,
      "grad_norm": 30.183269500732422,
      "learning_rate": 4.035815002820079e-05,
      "loss": 0.1413,
      "step": 3420
    },
    {
      "epoch": 2.9018612521150593,
      "grad_norm": 1.3792476654052734,
      "learning_rate": 4.0329949238578684e-05,
      "loss": 0.1381,
      "step": 3430
    },
    {
      "epoch": 2.910321489001692,
      "grad_norm": 0.004442022647708654,
      "learning_rate": 4.030174844895657e-05,
      "loss": 0.0171,
      "step": 3440
    },
    {
      "epoch": 2.9187817258883246,
      "grad_norm": 0.0026549394242465496,
      "learning_rate": 4.0273547659334466e-05,
      "loss": 0.0504,
      "step": 3450
    },
    {
      "epoch": 2.927241962774958,
      "grad_norm": 0.006903315894305706,
      "learning_rate": 4.0245346869712354e-05,
      "loss": 0.0293,
      "step": 3460
    },
    {
      "epoch": 2.9357021996615904,
      "grad_norm": 0.5951646566390991,
      "learning_rate": 4.021714608009024e-05,
      "loss": 0.0402,
      "step": 3470
    },
    {
      "epoch": 2.9441624365482233,
      "grad_norm": 0.0016850599786266685,
      "learning_rate": 4.018894529046813e-05,
      "loss": 0.0009,
      "step": 3480
    },
    {
      "epoch": 2.952622673434856,
      "grad_norm": 0.008935854770243168,
      "learning_rate": 4.0160744500846025e-05,
      "loss": 0.0011,
      "step": 3490
    },
    {
      "epoch": 2.961082910321489,
      "grad_norm": 0.0024079226423054934,
      "learning_rate": 4.013254371122392e-05,
      "loss": 0.0292,
      "step": 3500
    },
    {
      "epoch": 2.969543147208122,
      "grad_norm": 0.02782033011317253,
      "learning_rate": 4.010434292160181e-05,
      "loss": 0.1153,
      "step": 3510
    },
    {
      "epoch": 2.9780033840947544,
      "grad_norm": 0.02952849119901657,
      "learning_rate": 4.00761421319797e-05,
      "loss": 0.0547,
      "step": 3520
    },
    {
      "epoch": 2.9864636209813877,
      "grad_norm": 0.009455189108848572,
      "learning_rate": 4.0047941342357584e-05,
      "loss": 0.0483,
      "step": 3530
    },
    {
      "epoch": 2.99492385786802,
      "grad_norm": 10.323859214782715,
      "learning_rate": 4.001974055273548e-05,
      "loss": 0.0318,
      "step": 3540
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9790740740740741,
      "eval_loss": 0.10689126700162888,
      "eval_runtime": 244.4295,
      "eval_samples_per_second": 22.092,
      "eval_steps_per_second": 2.762,
      "step": 3546
    },
    {
      "epoch": 3.003384094754653,
      "grad_norm": 0.01834588684141636,
      "learning_rate": 3.9991539763113366e-05,
      "loss": 0.0424,
      "step": 3550
    },
    {
      "epoch": 3.011844331641286,
      "grad_norm": 0.010960851795971394,
      "learning_rate": 3.996333897349126e-05,
      "loss": 0.0003,
      "step": 3560
    },
    {
      "epoch": 3.020304568527919,
      "grad_norm": 0.24798567593097687,
      "learning_rate": 3.9935138183869156e-05,
      "loss": 0.0685,
      "step": 3570
    },
    {
      "epoch": 3.0287648054145517,
      "grad_norm": 0.0093618743121624,
      "learning_rate": 3.9906937394247044e-05,
      "loss": 0.0099,
      "step": 3580
    },
    {
      "epoch": 3.0372250423011846,
      "grad_norm": 9.537440299987793,
      "learning_rate": 3.987873660462493e-05,
      "loss": 0.069,
      "step": 3590
    },
    {
      "epoch": 3.045685279187817,
      "grad_norm": 5.259807109832764,
      "learning_rate": 3.985053581500282e-05,
      "loss": 0.0032,
      "step": 3600
    },
    {
      "epoch": 3.05414551607445,
      "grad_norm": 0.045542605221271515,
      "learning_rate": 3.9822335025380714e-05,
      "loss": 0.0332,
      "step": 3610
    },
    {
      "epoch": 3.062605752961083,
      "grad_norm": 31.600664138793945,
      "learning_rate": 3.97941342357586e-05,
      "loss": 0.1117,
      "step": 3620
    },
    {
      "epoch": 3.0710659898477157,
      "grad_norm": 0.3796718418598175,
      "learning_rate": 3.97659334461365e-05,
      "loss": 0.0045,
      "step": 3630
    },
    {
      "epoch": 3.0795262267343486,
      "grad_norm": 39.48462677001953,
      "learning_rate": 3.9737732656514385e-05,
      "loss": 0.0387,
      "step": 3640
    },
    {
      "epoch": 3.0879864636209815,
      "grad_norm": 0.02776162512600422,
      "learning_rate": 3.970953186689227e-05,
      "loss": 0.0462,
      "step": 3650
    },
    {
      "epoch": 3.0964467005076144,
      "grad_norm": 0.002200811170041561,
      "learning_rate": 3.968133107727017e-05,
      "loss": 0.0019,
      "step": 3660
    },
    {
      "epoch": 3.104906937394247,
      "grad_norm": 0.02475917525589466,
      "learning_rate": 3.9653130287648056e-05,
      "loss": 0.0297,
      "step": 3670
    },
    {
      "epoch": 3.1133671742808797,
      "grad_norm": 0.3228223919868469,
      "learning_rate": 3.962492949802595e-05,
      "loss": 0.0216,
      "step": 3680
    },
    {
      "epoch": 3.1218274111675126,
      "grad_norm": 0.007218979764729738,
      "learning_rate": 3.959672870840384e-05,
      "loss": 0.0551,
      "step": 3690
    },
    {
      "epoch": 3.1302876480541455,
      "grad_norm": 0.0344734825193882,
      "learning_rate": 3.9568527918781726e-05,
      "loss": 0.0286,
      "step": 3700
    },
    {
      "epoch": 3.1387478849407784,
      "grad_norm": 40.20549774169922,
      "learning_rate": 3.954032712915962e-05,
      "loss": 0.0426,
      "step": 3710
    },
    {
      "epoch": 3.1472081218274113,
      "grad_norm": 0.024796420708298683,
      "learning_rate": 3.951212633953751e-05,
      "loss": 0.0226,
      "step": 3720
    },
    {
      "epoch": 3.155668358714044,
      "grad_norm": 0.0016937133623287082,
      "learning_rate": 3.9483925549915404e-05,
      "loss": 0.0002,
      "step": 3730
    },
    {
      "epoch": 3.164128595600677,
      "grad_norm": 0.13282886147499084,
      "learning_rate": 3.945572476029329e-05,
      "loss": 0.0055,
      "step": 3740
    },
    {
      "epoch": 3.1725888324873095,
      "grad_norm": 0.001172096817754209,
      "learning_rate": 3.942752397067118e-05,
      "loss": 0.0923,
      "step": 3750
    },
    {
      "epoch": 3.1810490693739424,
      "grad_norm": 0.009804598987102509,
      "learning_rate": 3.939932318104907e-05,
      "loss": 0.0198,
      "step": 3760
    },
    {
      "epoch": 3.1895093062605753,
      "grad_norm": 0.028245095163583755,
      "learning_rate": 3.937112239142696e-05,
      "loss": 0.0061,
      "step": 3770
    },
    {
      "epoch": 3.197969543147208,
      "grad_norm": 0.06877922266721725,
      "learning_rate": 3.934292160180485e-05,
      "loss": 0.021,
      "step": 3780
    },
    {
      "epoch": 3.206429780033841,
      "grad_norm": 0.036648377776145935,
      "learning_rate": 3.9314720812182745e-05,
      "loss": 0.0543,
      "step": 3790
    },
    {
      "epoch": 3.214890016920474,
      "grad_norm": 5.26721715927124,
      "learning_rate": 3.928652002256063e-05,
      "loss": 0.0599,
      "step": 3800
    },
    {
      "epoch": 3.223350253807107,
      "grad_norm": 0.014083649031817913,
      "learning_rate": 3.925831923293852e-05,
      "loss": 0.0006,
      "step": 3810
    },
    {
      "epoch": 3.2318104906937393,
      "grad_norm": 0.0029833659064024687,
      "learning_rate": 3.9230118443316416e-05,
      "loss": 0.0447,
      "step": 3820
    },
    {
      "epoch": 3.240270727580372,
      "grad_norm": 0.026557322591543198,
      "learning_rate": 3.9201917653694304e-05,
      "loss": 0.0045,
      "step": 3830
    },
    {
      "epoch": 3.248730964467005,
      "grad_norm": 0.005659306421875954,
      "learning_rate": 3.91737168640722e-05,
      "loss": 0.001,
      "step": 3840
    },
    {
      "epoch": 3.257191201353638,
      "grad_norm": 0.03496940806508064,
      "learning_rate": 3.9145516074450087e-05,
      "loss": 0.0172,
      "step": 3850
    },
    {
      "epoch": 3.265651438240271,
      "grad_norm": 0.0023116273805499077,
      "learning_rate": 3.9117315284827975e-05,
      "loss": 0.0857,
      "step": 3860
    },
    {
      "epoch": 3.2741116751269037,
      "grad_norm": 0.37215325236320496,
      "learning_rate": 3.908911449520587e-05,
      "loss": 0.0286,
      "step": 3870
    },
    {
      "epoch": 3.2825719120135366,
      "grad_norm": 0.035301897674798965,
      "learning_rate": 3.906091370558376e-05,
      "loss": 0.0003,
      "step": 3880
    },
    {
      "epoch": 3.291032148900169,
      "grad_norm": 1.7044183015823364,
      "learning_rate": 3.903271291596165e-05,
      "loss": 0.0404,
      "step": 3890
    },
    {
      "epoch": 3.299492385786802,
      "grad_norm": 0.05944981426000595,
      "learning_rate": 3.900451212633954e-05,
      "loss": 0.0589,
      "step": 3900
    },
    {
      "epoch": 3.307952622673435,
      "grad_norm": 0.0019366999622434378,
      "learning_rate": 3.897631133671743e-05,
      "loss": 0.0014,
      "step": 3910
    },
    {
      "epoch": 3.3164128595600677,
      "grad_norm": 0.001430804724805057,
      "learning_rate": 3.8948110547095316e-05,
      "loss": 0.0209,
      "step": 3920
    },
    {
      "epoch": 3.3248730964467006,
      "grad_norm": 0.009113017469644547,
      "learning_rate": 3.891990975747321e-05,
      "loss": 0.0271,
      "step": 3930
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.013907868415117264,
      "learning_rate": 3.8891708967851105e-05,
      "loss": 0.0268,
      "step": 3940
    },
    {
      "epoch": 3.3417935702199664,
      "grad_norm": 0.12466797977685928,
      "learning_rate": 3.886350817822899e-05,
      "loss": 0.0002,
      "step": 3950
    },
    {
      "epoch": 3.350253807106599,
      "grad_norm": 0.2866568863391876,
      "learning_rate": 3.883530738860688e-05,
      "loss": 0.0004,
      "step": 3960
    },
    {
      "epoch": 3.3587140439932317,
      "grad_norm": 16.02290153503418,
      "learning_rate": 3.880710659898477e-05,
      "loss": 0.0038,
      "step": 3970
    },
    {
      "epoch": 3.3671742808798646,
      "grad_norm": 0.002139738295227289,
      "learning_rate": 3.8778905809362664e-05,
      "loss": 0.001,
      "step": 3980
    },
    {
      "epoch": 3.3756345177664975,
      "grad_norm": 0.0010046265088021755,
      "learning_rate": 3.875070501974055e-05,
      "loss": 0.0474,
      "step": 3990
    },
    {
      "epoch": 3.3840947546531304,
      "grad_norm": 0.008208019658923149,
      "learning_rate": 3.872250423011845e-05,
      "loss": 0.0046,
      "step": 4000
    },
    {
      "epoch": 3.3925549915397633,
      "grad_norm": 1.1522055864334106,
      "learning_rate": 3.8694303440496335e-05,
      "loss": 0.0077,
      "step": 4010
    },
    {
      "epoch": 3.401015228426396,
      "grad_norm": 0.01562747173011303,
      "learning_rate": 3.866610265087422e-05,
      "loss": 0.0063,
      "step": 4020
    },
    {
      "epoch": 3.4094754653130286,
      "grad_norm": 0.0014383612433448434,
      "learning_rate": 3.863790186125212e-05,
      "loss": 0.0529,
      "step": 4030
    },
    {
      "epoch": 3.4179357021996615,
      "grad_norm": 0.0016299285925924778,
      "learning_rate": 3.8609701071630005e-05,
      "loss": 0.0677,
      "step": 4040
    },
    {
      "epoch": 3.4263959390862944,
      "grad_norm": 13.122111320495605,
      "learning_rate": 3.85815002820079e-05,
      "loss": 0.0137,
      "step": 4050
    },
    {
      "epoch": 3.4348561759729273,
      "grad_norm": 0.004875198006629944,
      "learning_rate": 3.855329949238579e-05,
      "loss": 0.0128,
      "step": 4060
    },
    {
      "epoch": 3.44331641285956,
      "grad_norm": 0.02140418067574501,
      "learning_rate": 3.8525098702763676e-05,
      "loss": 0.026,
      "step": 4070
    },
    {
      "epoch": 3.451776649746193,
      "grad_norm": 0.006155872717499733,
      "learning_rate": 3.849689791314157e-05,
      "loss": 0.0184,
      "step": 4080
    },
    {
      "epoch": 3.460236886632826,
      "grad_norm": 0.2374344915151596,
      "learning_rate": 3.846869712351946e-05,
      "loss": 0.0513,
      "step": 4090
    },
    {
      "epoch": 3.4686971235194584,
      "grad_norm": 0.017507631331682205,
      "learning_rate": 3.8440496333897353e-05,
      "loss": 0.0103,
      "step": 4100
    },
    {
      "epoch": 3.4771573604060912,
      "grad_norm": 0.0015163926873356104,
      "learning_rate": 3.841229554427524e-05,
      "loss": 0.0014,
      "step": 4110
    },
    {
      "epoch": 3.485617597292724,
      "grad_norm": 22.77350616455078,
      "learning_rate": 3.838409475465313e-05,
      "loss": 0.0047,
      "step": 4120
    },
    {
      "epoch": 3.494077834179357,
      "grad_norm": 0.07426902651786804,
      "learning_rate": 3.835589396503102e-05,
      "loss": 0.0003,
      "step": 4130
    },
    {
      "epoch": 3.50253807106599,
      "grad_norm": 0.010615148581564426,
      "learning_rate": 3.832769317540891e-05,
      "loss": 0.0201,
      "step": 4140
    },
    {
      "epoch": 3.510998307952623,
      "grad_norm": 0.0011331115383654833,
      "learning_rate": 3.829949238578681e-05,
      "loss": 0.0007,
      "step": 4150
    },
    {
      "epoch": 3.5194585448392557,
      "grad_norm": 1.6333667039871216,
      "learning_rate": 3.8271291596164695e-05,
      "loss": 0.0392,
      "step": 4160
    },
    {
      "epoch": 3.527918781725888,
      "grad_norm": 0.26184895634651184,
      "learning_rate": 3.824309080654259e-05,
      "loss": 0.0205,
      "step": 4170
    },
    {
      "epoch": 3.536379018612521,
      "grad_norm": 0.006672317627817392,
      "learning_rate": 3.821489001692047e-05,
      "loss": 0.0006,
      "step": 4180
    },
    {
      "epoch": 3.544839255499154,
      "grad_norm": 0.004010564181953669,
      "learning_rate": 3.8186689227298365e-05,
      "loss": 0.0361,
      "step": 4190
    },
    {
      "epoch": 3.553299492385787,
      "grad_norm": 0.001074437634088099,
      "learning_rate": 3.8158488437676253e-05,
      "loss": 0.0033,
      "step": 4200
    },
    {
      "epoch": 3.5617597292724197,
      "grad_norm": 0.0021085531916469336,
      "learning_rate": 3.813028764805415e-05,
      "loss": 0.0007,
      "step": 4210
    },
    {
      "epoch": 3.5702199661590526,
      "grad_norm": 0.06242571026086807,
      "learning_rate": 3.810208685843204e-05,
      "loss": 0.0299,
      "step": 4220
    },
    {
      "epoch": 3.5786802030456855,
      "grad_norm": 0.02250576950609684,
      "learning_rate": 3.8073886068809924e-05,
      "loss": 0.107,
      "step": 4230
    },
    {
      "epoch": 3.587140439932318,
      "grad_norm": 0.0011083612916991115,
      "learning_rate": 3.804568527918782e-05,
      "loss": 0.0002,
      "step": 4240
    },
    {
      "epoch": 3.595600676818951,
      "grad_norm": 0.0011230985401198268,
      "learning_rate": 3.801748448956571e-05,
      "loss": 0.003,
      "step": 4250
    },
    {
      "epoch": 3.6040609137055837,
      "grad_norm": 0.009224538691341877,
      "learning_rate": 3.79892836999436e-05,
      "loss": 0.0005,
      "step": 4260
    },
    {
      "epoch": 3.6125211505922166,
      "grad_norm": 15.377131462097168,
      "learning_rate": 3.796108291032149e-05,
      "loss": 0.0193,
      "step": 4270
    },
    {
      "epoch": 3.6209813874788495,
      "grad_norm": 41.638832092285156,
      "learning_rate": 3.7932882120699384e-05,
      "loss": 0.0149,
      "step": 4280
    },
    {
      "epoch": 3.6294416243654823,
      "grad_norm": 0.004737805109471083,
      "learning_rate": 3.790468133107727e-05,
      "loss": 0.0193,
      "step": 4290
    },
    {
      "epoch": 3.6379018612521152,
      "grad_norm": 0.0011369517305865884,
      "learning_rate": 3.787648054145516e-05,
      "loss": 0.005,
      "step": 4300
    },
    {
      "epoch": 3.6463620981387477,
      "grad_norm": 0.09851745516061783,
      "learning_rate": 3.7848279751833055e-05,
      "loss": 0.0856,
      "step": 4310
    },
    {
      "epoch": 3.6548223350253806,
      "grad_norm": 0.10096631944179535,
      "learning_rate": 3.782007896221094e-05,
      "loss": 0.0082,
      "step": 4320
    },
    {
      "epoch": 3.6632825719120135,
      "grad_norm": 0.016250936314463615,
      "learning_rate": 3.779187817258884e-05,
      "loss": 0.0149,
      "step": 4330
    },
    {
      "epoch": 3.6717428087986463,
      "grad_norm": 0.010360185988247395,
      "learning_rate": 3.7763677382966726e-05,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 3.6802030456852792,
      "grad_norm": 6.11821174621582,
      "learning_rate": 3.7735476593344614e-05,
      "loss": 0.0029,
      "step": 4350
    },
    {
      "epoch": 3.688663282571912,
      "grad_norm": 0.33408334851264954,
      "learning_rate": 3.770727580372251e-05,
      "loss": 0.0364,
      "step": 4360
    },
    {
      "epoch": 3.697123519458545,
      "grad_norm": 0.10740282386541367,
      "learning_rate": 3.7679075014100396e-05,
      "loss": 0.0446,
      "step": 4370
    },
    {
      "epoch": 3.7055837563451774,
      "grad_norm": 0.10183051973581314,
      "learning_rate": 3.765087422447829e-05,
      "loss": 0.083,
      "step": 4380
    },
    {
      "epoch": 3.7140439932318103,
      "grad_norm": 41.86067199707031,
      "learning_rate": 3.762267343485618e-05,
      "loss": 0.0233,
      "step": 4390
    },
    {
      "epoch": 3.7225042301184432,
      "grad_norm": 0.002356411889195442,
      "learning_rate": 3.759447264523407e-05,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 3.730964467005076,
      "grad_norm": 38.21589660644531,
      "learning_rate": 3.7566271855611955e-05,
      "loss": 0.058,
      "step": 4410
    },
    {
      "epoch": 3.739424703891709,
      "grad_norm": 0.004705990664660931,
      "learning_rate": 3.753807106598985e-05,
      "loss": 0.0006,
      "step": 4420
    },
    {
      "epoch": 3.747884940778342,
      "grad_norm": 0.00811285711824894,
      "learning_rate": 3.7509870276367744e-05,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 3.7563451776649748,
      "grad_norm": 20.270261764526367,
      "learning_rate": 3.748166948674563e-05,
      "loss": 0.0111,
      "step": 4440
    },
    {
      "epoch": 3.764805414551607,
      "grad_norm": 2.5382938385009766,
      "learning_rate": 3.745346869712352e-05,
      "loss": 0.0652,
      "step": 4450
    },
    {
      "epoch": 3.77326565143824,
      "grad_norm": 0.007213369477540255,
      "learning_rate": 3.742526790750141e-05,
      "loss": 0.0015,
      "step": 4460
    },
    {
      "epoch": 3.781725888324873,
      "grad_norm": 0.5796733498573303,
      "learning_rate": 3.73970671178793e-05,
      "loss": 0.0982,
      "step": 4470
    },
    {
      "epoch": 3.790186125211506,
      "grad_norm": 0.007524318061769009,
      "learning_rate": 3.736886632825719e-05,
      "loss": 0.0006,
      "step": 4480
    },
    {
      "epoch": 3.7986463620981388,
      "grad_norm": 38.97788619995117,
      "learning_rate": 3.7340665538635086e-05,
      "loss": 0.0534,
      "step": 4490
    },
    {
      "epoch": 3.8071065989847717,
      "grad_norm": 0.0011714475695043802,
      "learning_rate": 3.7312464749012974e-05,
      "loss": 0.007,
      "step": 4500
    },
    {
      "epoch": 3.8155668358714045,
      "grad_norm": 0.0011707908706739545,
      "learning_rate": 3.728426395939086e-05,
      "loss": 0.0002,
      "step": 4510
    },
    {
      "epoch": 3.824027072758037,
      "grad_norm": 0.013039976358413696,
      "learning_rate": 3.7256063169768756e-05,
      "loss": 0.0423,
      "step": 4520
    },
    {
      "epoch": 3.8324873096446703,
      "grad_norm": 59.19457244873047,
      "learning_rate": 3.7227862380146644e-05,
      "loss": 0.0625,
      "step": 4530
    },
    {
      "epoch": 3.8409475465313028,
      "grad_norm": 40.03731155395508,
      "learning_rate": 3.719966159052454e-05,
      "loss": 0.0602,
      "step": 4540
    },
    {
      "epoch": 3.8494077834179357,
      "grad_norm": 0.04475225508213043,
      "learning_rate": 3.717146080090243e-05,
      "loss": 0.061,
      "step": 4550
    },
    {
      "epoch": 3.8578680203045685,
      "grad_norm": 27.82916831970215,
      "learning_rate": 3.7143260011280315e-05,
      "loss": 0.0252,
      "step": 4560
    },
    {
      "epoch": 3.8663282571912014,
      "grad_norm": 0.003097225446254015,
      "learning_rate": 3.711505922165821e-05,
      "loss": 0.0461,
      "step": 4570
    },
    {
      "epoch": 3.8747884940778343,
      "grad_norm": 0.018805798143148422,
      "learning_rate": 3.70868584320361e-05,
      "loss": 0.0006,
      "step": 4580
    },
    {
      "epoch": 3.8832487309644668,
      "grad_norm": 92.76812744140625,
      "learning_rate": 3.705865764241399e-05,
      "loss": 0.0996,
      "step": 4590
    },
    {
      "epoch": 3.8917089678511,
      "grad_norm": 0.027651218697428703,
      "learning_rate": 3.703045685279188e-05,
      "loss": 0.0005,
      "step": 4600
    },
    {
      "epoch": 3.9001692047377325,
      "grad_norm": 0.005020800977945328,
      "learning_rate": 3.700225606316977e-05,
      "loss": 0.0753,
      "step": 4610
    },
    {
      "epoch": 3.9086294416243654,
      "grad_norm": 12.201359748840332,
      "learning_rate": 3.6974055273547656e-05,
      "loss": 0.0055,
      "step": 4620
    },
    {
      "epoch": 3.9170896785109983,
      "grad_norm": 0.15659987926483154,
      "learning_rate": 3.694585448392555e-05,
      "loss": 0.0969,
      "step": 4630
    },
    {
      "epoch": 3.925549915397631,
      "grad_norm": 0.2831055819988251,
      "learning_rate": 3.6917653694303446e-05,
      "loss": 0.0543,
      "step": 4640
    },
    {
      "epoch": 3.934010152284264,
      "grad_norm": 0.0067841848358511925,
      "learning_rate": 3.6889452904681334e-05,
      "loss": 0.0524,
      "step": 4650
    },
    {
      "epoch": 3.9424703891708965,
      "grad_norm": 0.10396131128072739,
      "learning_rate": 3.686125211505922e-05,
      "loss": 0.029,
      "step": 4660
    },
    {
      "epoch": 3.95093062605753,
      "grad_norm": 0.001597329042851925,
      "learning_rate": 3.683305132543711e-05,
      "loss": 0.0005,
      "step": 4670
    },
    {
      "epoch": 3.9593908629441623,
      "grad_norm": 1.331456184387207,
      "learning_rate": 3.6804850535815005e-05,
      "loss": 0.0106,
      "step": 4680
    },
    {
      "epoch": 3.967851099830795,
      "grad_norm": 0.0009167367243207991,
      "learning_rate": 3.677664974619289e-05,
      "loss": 0.0306,
      "step": 4690
    },
    {
      "epoch": 3.976311336717428,
      "grad_norm": 0.001508068642579019,
      "learning_rate": 3.674844895657079e-05,
      "loss": 0.0086,
      "step": 4700
    },
    {
      "epoch": 3.984771573604061,
      "grad_norm": 0.03968614339828491,
      "learning_rate": 3.672024816694868e-05,
      "loss": 0.0104,
      "step": 4710
    },
    {
      "epoch": 3.993231810490694,
      "grad_norm": 0.0009144857176579535,
      "learning_rate": 3.669204737732656e-05,
      "loss": 0.0248,
      "step": 4720
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9811111111111112,
      "eval_loss": 0.0983881875872612,
      "eval_runtime": 244.1897,
      "eval_samples_per_second": 22.114,
      "eval_steps_per_second": 2.764,
      "step": 4728
    },
    {
      "epoch": 4.001692047377326,
      "grad_norm": 0.00838447269052267,
      "learning_rate": 3.666384658770446e-05,
      "loss": 0.0481,
      "step": 4730
    },
    {
      "epoch": 4.01015228426396,
      "grad_norm": 0.05189366266131401,
      "learning_rate": 3.6635645798082346e-05,
      "loss": 0.0002,
      "step": 4740
    },
    {
      "epoch": 4.018612521150592,
      "grad_norm": 0.006055421661585569,
      "learning_rate": 3.660744500846024e-05,
      "loss": 0.0999,
      "step": 4750
    },
    {
      "epoch": 4.027072758037225,
      "grad_norm": 0.17113140225410461,
      "learning_rate": 3.657924421883813e-05,
      "loss": 0.0001,
      "step": 4760
    },
    {
      "epoch": 4.035532994923858,
      "grad_norm": 0.0019412715919315815,
      "learning_rate": 3.6551043429216017e-05,
      "loss": 0.0001,
      "step": 4770
    },
    {
      "epoch": 4.04399323181049,
      "grad_norm": 0.13222156465053558,
      "learning_rate": 3.652284263959391e-05,
      "loss": 0.0591,
      "step": 4780
    },
    {
      "epoch": 4.052453468697124,
      "grad_norm": 20.808137893676758,
      "learning_rate": 3.64946418499718e-05,
      "loss": 0.0629,
      "step": 4790
    },
    {
      "epoch": 4.060913705583756,
      "grad_norm": 0.0011984440498054028,
      "learning_rate": 3.6466441060349694e-05,
      "loss": 0.0041,
      "step": 4800
    },
    {
      "epoch": 4.069373942470389,
      "grad_norm": 8.054487228393555,
      "learning_rate": 3.643824027072758e-05,
      "loss": 0.0021,
      "step": 4810
    },
    {
      "epoch": 4.077834179357022,
      "grad_norm": 10.821487426757812,
      "learning_rate": 3.641003948110548e-05,
      "loss": 0.0687,
      "step": 4820
    },
    {
      "epoch": 4.086294416243655,
      "grad_norm": 0.014579346403479576,
      "learning_rate": 3.638183869148336e-05,
      "loss": 0.0031,
      "step": 4830
    },
    {
      "epoch": 4.094754653130288,
      "grad_norm": 0.0013069623382762074,
      "learning_rate": 3.635363790186125e-05,
      "loss": 0.0278,
      "step": 4840
    },
    {
      "epoch": 4.10321489001692,
      "grad_norm": 0.004660760052502155,
      "learning_rate": 3.632543711223915e-05,
      "loss": 0.0039,
      "step": 4850
    },
    {
      "epoch": 4.111675126903553,
      "grad_norm": 44.9605598449707,
      "learning_rate": 3.6297236322617035e-05,
      "loss": 0.0522,
      "step": 4860
    },
    {
      "epoch": 4.120135363790186,
      "grad_norm": 0.03537004441022873,
      "learning_rate": 3.626903553299493e-05,
      "loss": 0.0001,
      "step": 4870
    },
    {
      "epoch": 4.128595600676819,
      "grad_norm": 0.0020748365204781294,
      "learning_rate": 3.624083474337281e-05,
      "loss": 0.0508,
      "step": 4880
    },
    {
      "epoch": 4.137055837563452,
      "grad_norm": 0.0059064943343400955,
      "learning_rate": 3.6212633953750706e-05,
      "loss": 0.0629,
      "step": 4890
    },
    {
      "epoch": 4.145516074450085,
      "grad_norm": 20.716463088989258,
      "learning_rate": 3.6184433164128594e-05,
      "loss": 0.0298,
      "step": 4900
    },
    {
      "epoch": 4.153976311336717,
      "grad_norm": 0.005600760690867901,
      "learning_rate": 3.615623237450649e-05,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 4.16243654822335,
      "grad_norm": 0.0005184190813452005,
      "learning_rate": 3.6128031584884383e-05,
      "loss": 0.0008,
      "step": 4920
    },
    {
      "epoch": 4.170896785109983,
      "grad_norm": 0.0026737540028989315,
      "learning_rate": 3.609983079526227e-05,
      "loss": 0.0003,
      "step": 4930
    },
    {
      "epoch": 4.179357021996616,
      "grad_norm": 0.018178755417466164,
      "learning_rate": 3.607163000564016e-05,
      "loss": 0.0001,
      "step": 4940
    },
    {
      "epoch": 4.187817258883249,
      "grad_norm": 0.0008468001033179462,
      "learning_rate": 3.604342921601805e-05,
      "loss": 0.0372,
      "step": 4950
    },
    {
      "epoch": 4.196277495769881,
      "grad_norm": 0.002735363319516182,
      "learning_rate": 3.601522842639594e-05,
      "loss": 0.0091,
      "step": 4960
    },
    {
      "epoch": 4.204737732656515,
      "grad_norm": 0.00459869671612978,
      "learning_rate": 3.598702763677383e-05,
      "loss": 0.0001,
      "step": 4970
    },
    {
      "epoch": 4.213197969543147,
      "grad_norm": 0.0016976207261905074,
      "learning_rate": 3.5958826847151725e-05,
      "loss": 0.0003,
      "step": 4980
    },
    {
      "epoch": 4.22165820642978,
      "grad_norm": 0.0009161622147075832,
      "learning_rate": 3.593062605752961e-05,
      "loss": 0.0002,
      "step": 4990
    },
    {
      "epoch": 4.230118443316413,
      "grad_norm": 0.0007522794185206294,
      "learning_rate": 3.59024252679075e-05,
      "loss": 0.0003,
      "step": 5000
    },
    {
      "epoch": 4.238578680203045,
      "grad_norm": 0.021669680252671242,
      "learning_rate": 3.5874224478285395e-05,
      "loss": 0.0003,
      "step": 5010
    },
    {
      "epoch": 4.247038917089679,
      "grad_norm": 0.001249210792593658,
      "learning_rate": 3.5846023688663283e-05,
      "loss": 0.0005,
      "step": 5020
    },
    {
      "epoch": 4.255499153976311,
      "grad_norm": 0.1633119136095047,
      "learning_rate": 3.581782289904118e-05,
      "loss": 0.0003,
      "step": 5030
    },
    {
      "epoch": 4.2639593908629445,
      "grad_norm": 7.556812286376953,
      "learning_rate": 3.5789622109419066e-05,
      "loss": 0.0081,
      "step": 5040
    },
    {
      "epoch": 4.272419627749577,
      "grad_norm": 0.000777612382080406,
      "learning_rate": 3.5761421319796954e-05,
      "loss": 0.0007,
      "step": 5050
    },
    {
      "epoch": 4.280879864636209,
      "grad_norm": 0.001112813246436417,
      "learning_rate": 3.573322053017485e-05,
      "loss": 0.0012,
      "step": 5060
    },
    {
      "epoch": 4.289340101522843,
      "grad_norm": 0.010047839023172855,
      "learning_rate": 3.570501974055274e-05,
      "loss": 0.0209,
      "step": 5070
    },
    {
      "epoch": 4.297800338409475,
      "grad_norm": 0.001340313465334475,
      "learning_rate": 3.567681895093063e-05,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 4.3062605752961085,
      "grad_norm": 44.0227165222168,
      "learning_rate": 3.564861816130852e-05,
      "loss": 0.0556,
      "step": 5090
    },
    {
      "epoch": 4.314720812182741,
      "grad_norm": 0.00042451993795111775,
      "learning_rate": 3.562041737168641e-05,
      "loss": 0.0702,
      "step": 5100
    },
    {
      "epoch": 4.323181049069374,
      "grad_norm": 0.01914479024708271,
      "learning_rate": 3.5592216582064295e-05,
      "loss": 0.0,
      "step": 5110
    },
    {
      "epoch": 4.331641285956007,
      "grad_norm": 0.0007154428749345243,
      "learning_rate": 3.556401579244219e-05,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 4.340101522842639,
      "grad_norm": 34.93402862548828,
      "learning_rate": 3.5535815002820085e-05,
      "loss": 0.0423,
      "step": 5130
    },
    {
      "epoch": 4.3485617597292725,
      "grad_norm": 0.0004523104871623218,
      "learning_rate": 3.550761421319797e-05,
      "loss": 0.0144,
      "step": 5140
    },
    {
      "epoch": 4.357021996615905,
      "grad_norm": 0.0022155223414301872,
      "learning_rate": 3.547941342357586e-05,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 4.365482233502538,
      "grad_norm": 0.0022550488356500864,
      "learning_rate": 3.545121263395375e-05,
      "loss": 0.0183,
      "step": 5160
    },
    {
      "epoch": 4.373942470389171,
      "grad_norm": 0.0008717403979972005,
      "learning_rate": 3.5423011844331644e-05,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 4.382402707275804,
      "grad_norm": 0.004135073162615299,
      "learning_rate": 3.539481105470953e-05,
      "loss": 0.0382,
      "step": 5180
    },
    {
      "epoch": 4.3908629441624365,
      "grad_norm": 0.0027376930229365826,
      "learning_rate": 3.5366610265087426e-05,
      "loss": 0.0115,
      "step": 5190
    },
    {
      "epoch": 4.39932318104907,
      "grad_norm": 0.0007371003157459199,
      "learning_rate": 3.5338409475465314e-05,
      "loss": 0.0002,
      "step": 5200
    },
    {
      "epoch": 4.407783417935702,
      "grad_norm": 0.035454634577035904,
      "learning_rate": 3.53102086858432e-05,
      "loss": 0.0002,
      "step": 5210
    },
    {
      "epoch": 4.416243654822335,
      "grad_norm": 0.003352323081344366,
      "learning_rate": 3.52820078962211e-05,
      "loss": 0.0207,
      "step": 5220
    },
    {
      "epoch": 4.424703891708968,
      "grad_norm": 7.48688268661499,
      "learning_rate": 3.5253807106598985e-05,
      "loss": 0.0611,
      "step": 5230
    },
    {
      "epoch": 4.4331641285956005,
      "grad_norm": 0.000511337595526129,
      "learning_rate": 3.522560631697688e-05,
      "loss": 0.0008,
      "step": 5240
    },
    {
      "epoch": 4.441624365482234,
      "grad_norm": 11.278562545776367,
      "learning_rate": 3.519740552735477e-05,
      "loss": 0.0593,
      "step": 5250
    },
    {
      "epoch": 4.450084602368866,
      "grad_norm": 2.48471999168396,
      "learning_rate": 3.5169204737732656e-05,
      "loss": 0.0177,
      "step": 5260
    },
    {
      "epoch": 4.458544839255499,
      "grad_norm": 0.05935634300112724,
      "learning_rate": 3.514100394811055e-05,
      "loss": 0.0104,
      "step": 5270
    },
    {
      "epoch": 4.467005076142132,
      "grad_norm": 7.332823276519775,
      "learning_rate": 3.511280315848844e-05,
      "loss": 0.0374,
      "step": 5280
    },
    {
      "epoch": 4.4754653130287645,
      "grad_norm": 0.002886174013838172,
      "learning_rate": 3.508460236886633e-05,
      "loss": 0.0003,
      "step": 5290
    },
    {
      "epoch": 4.483925549915398,
      "grad_norm": 0.0006390598136931658,
      "learning_rate": 3.505640157924422e-05,
      "loss": 0.0185,
      "step": 5300
    },
    {
      "epoch": 4.49238578680203,
      "grad_norm": 0.0010541939409449697,
      "learning_rate": 3.502820078962211e-05,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 4.500846023688664,
      "grad_norm": 0.0010183639824390411,
      "learning_rate": 3.5e-05,
      "loss": 0.016,
      "step": 5320
    },
    {
      "epoch": 4.509306260575296,
      "grad_norm": 0.003503310028463602,
      "learning_rate": 3.497179921037789e-05,
      "loss": 0.0505,
      "step": 5330
    },
    {
      "epoch": 4.517766497461929,
      "grad_norm": 0.011956801638007164,
      "learning_rate": 3.4943598420755786e-05,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 4.526226734348562,
      "grad_norm": 0.17480307817459106,
      "learning_rate": 3.4915397631133674e-05,
      "loss": 0.0645,
      "step": 5350
    },
    {
      "epoch": 4.534686971235194,
      "grad_norm": 13.193830490112305,
      "learning_rate": 3.488719684151157e-05,
      "loss": 0.0047,
      "step": 5360
    },
    {
      "epoch": 4.543147208121828,
      "grad_norm": 0.004032691475003958,
      "learning_rate": 3.485899605188945e-05,
      "loss": 0.0263,
      "step": 5370
    },
    {
      "epoch": 4.55160744500846,
      "grad_norm": 4.861699104309082,
      "learning_rate": 3.4830795262267345e-05,
      "loss": 0.0011,
      "step": 5380
    },
    {
      "epoch": 4.560067681895093,
      "grad_norm": 0.001978424144908786,
      "learning_rate": 3.480259447264523e-05,
      "loss": 0.049,
      "step": 5390
    },
    {
      "epoch": 4.568527918781726,
      "grad_norm": 0.006780265364795923,
      "learning_rate": 3.477439368302313e-05,
      "loss": 0.0642,
      "step": 5400
    },
    {
      "epoch": 4.576988155668358,
      "grad_norm": 0.0005791350267827511,
      "learning_rate": 3.474619289340102e-05,
      "loss": 0.0062,
      "step": 5410
    },
    {
      "epoch": 4.585448392554992,
      "grad_norm": 0.026468511670827866,
      "learning_rate": 3.4717992103778904e-05,
      "loss": 0.0514,
      "step": 5420
    },
    {
      "epoch": 4.593908629441624,
      "grad_norm": 0.0007777151768095791,
      "learning_rate": 3.46897913141568e-05,
      "loss": 0.0543,
      "step": 5430
    },
    {
      "epoch": 4.602368866328257,
      "grad_norm": 0.0011144551681354642,
      "learning_rate": 3.4661590524534686e-05,
      "loss": 0.0002,
      "step": 5440
    },
    {
      "epoch": 4.61082910321489,
      "grad_norm": 0.01665889099240303,
      "learning_rate": 3.463338973491258e-05,
      "loss": 0.0001,
      "step": 5450
    },
    {
      "epoch": 4.619289340101523,
      "grad_norm": 0.0004894139710813761,
      "learning_rate": 3.460518894529047e-05,
      "loss": 0.0001,
      "step": 5460
    },
    {
      "epoch": 4.627749576988156,
      "grad_norm": 0.0005975358071736991,
      "learning_rate": 3.4576988155668364e-05,
      "loss": 0.0618,
      "step": 5470
    },
    {
      "epoch": 4.636209813874789,
      "grad_norm": 0.0024628876708447933,
      "learning_rate": 3.454878736604625e-05,
      "loss": 0.0579,
      "step": 5480
    },
    {
      "epoch": 4.644670050761421,
      "grad_norm": 0.0017402000958099961,
      "learning_rate": 3.452058657642414e-05,
      "loss": 0.0063,
      "step": 5490
    },
    {
      "epoch": 4.653130287648054,
      "grad_norm": 0.13772323727607727,
      "learning_rate": 3.4492385786802035e-05,
      "loss": 0.001,
      "step": 5500
    },
    {
      "epoch": 4.661590524534687,
      "grad_norm": 0.0011101645650342107,
      "learning_rate": 3.446418499717992e-05,
      "loss": 0.0013,
      "step": 5510
    },
    {
      "epoch": 4.67005076142132,
      "grad_norm": 0.0012950075324624777,
      "learning_rate": 3.443598420755782e-05,
      "loss": 0.0054,
      "step": 5520
    },
    {
      "epoch": 4.678510998307953,
      "grad_norm": 0.012860757298767567,
      "learning_rate": 3.44077834179357e-05,
      "loss": 0.0018,
      "step": 5530
    },
    {
      "epoch": 4.686971235194585,
      "grad_norm": 0.10084102302789688,
      "learning_rate": 3.437958262831359e-05,
      "loss": 0.0044,
      "step": 5540
    },
    {
      "epoch": 4.695431472081218,
      "grad_norm": 0.0009529449162073433,
      "learning_rate": 3.435138183869149e-05,
      "loss": 0.0448,
      "step": 5550
    },
    {
      "epoch": 4.703891708967851,
      "grad_norm": 0.0016074383165687323,
      "learning_rate": 3.4323181049069376e-05,
      "loss": 0.0068,
      "step": 5560
    },
    {
      "epoch": 4.712351945854484,
      "grad_norm": 0.0028980509378015995,
      "learning_rate": 3.429498025944727e-05,
      "loss": 0.0327,
      "step": 5570
    },
    {
      "epoch": 4.720812182741117,
      "grad_norm": 0.0014102936256676912,
      "learning_rate": 3.426677946982516e-05,
      "loss": 0.0054,
      "step": 5580
    },
    {
      "epoch": 4.729272419627749,
      "grad_norm": 6.440666675567627,
      "learning_rate": 3.4238578680203047e-05,
      "loss": 0.0393,
      "step": 5590
    },
    {
      "epoch": 4.737732656514383,
      "grad_norm": 0.036787547171115875,
      "learning_rate": 3.4210377890580935e-05,
      "loss": 0.0029,
      "step": 5600
    },
    {
      "epoch": 4.746192893401015,
      "grad_norm": 0.0012621756177395582,
      "learning_rate": 3.418217710095883e-05,
      "loss": 0.0191,
      "step": 5610
    },
    {
      "epoch": 4.7546531302876485,
      "grad_norm": 0.010711428709328175,
      "learning_rate": 3.4153976311336724e-05,
      "loss": 0.0491,
      "step": 5620
    },
    {
      "epoch": 4.763113367174281,
      "grad_norm": 0.0010598469525575638,
      "learning_rate": 3.412577552171461e-05,
      "loss": 0.0005,
      "step": 5630
    },
    {
      "epoch": 4.771573604060913,
      "grad_norm": 0.053452666848897934,
      "learning_rate": 3.40975747320925e-05,
      "loss": 0.0001,
      "step": 5640
    },
    {
      "epoch": 4.780033840947547,
      "grad_norm": 0.32756224274635315,
      "learning_rate": 3.406937394247039e-05,
      "loss": 0.0095,
      "step": 5650
    },
    {
      "epoch": 4.788494077834179,
      "grad_norm": 0.02107892744243145,
      "learning_rate": 3.404117315284828e-05,
      "loss": 0.0125,
      "step": 5660
    },
    {
      "epoch": 4.7969543147208125,
      "grad_norm": 0.0007417812594212592,
      "learning_rate": 3.401297236322617e-05,
      "loss": 0.1002,
      "step": 5670
    },
    {
      "epoch": 4.805414551607445,
      "grad_norm": 0.0005917042144574225,
      "learning_rate": 3.3984771573604065e-05,
      "loss": 0.0092,
      "step": 5680
    },
    {
      "epoch": 4.813874788494077,
      "grad_norm": 0.014250446110963821,
      "learning_rate": 3.395657078398195e-05,
      "loss": 0.0488,
      "step": 5690
    },
    {
      "epoch": 4.822335025380711,
      "grad_norm": 0.007111320737749338,
      "learning_rate": 3.392836999435984e-05,
      "loss": 0.0635,
      "step": 5700
    },
    {
      "epoch": 4.830795262267343,
      "grad_norm": 0.0012872042134404182,
      "learning_rate": 3.3900169204737736e-05,
      "loss": 0.0113,
      "step": 5710
    },
    {
      "epoch": 4.8392554991539765,
      "grad_norm": 0.0013676137896254659,
      "learning_rate": 3.3871968415115624e-05,
      "loss": 0.0783,
      "step": 5720
    },
    {
      "epoch": 4.847715736040609,
      "grad_norm": 0.38881006836891174,
      "learning_rate": 3.384376762549352e-05,
      "loss": 0.0026,
      "step": 5730
    },
    {
      "epoch": 4.856175972927242,
      "grad_norm": 0.33584064245224,
      "learning_rate": 3.381556683587141e-05,
      "loss": 0.0004,
      "step": 5740
    },
    {
      "epoch": 4.864636209813875,
      "grad_norm": 0.3325847387313843,
      "learning_rate": 3.3787366046249295e-05,
      "loss": 0.0178,
      "step": 5750
    },
    {
      "epoch": 4.873096446700508,
      "grad_norm": 0.0362086147069931,
      "learning_rate": 3.375916525662719e-05,
      "loss": 0.0009,
      "step": 5760
    },
    {
      "epoch": 4.8815566835871405,
      "grad_norm": 0.002336557488888502,
      "learning_rate": 3.373096446700508e-05,
      "loss": 0.0365,
      "step": 5770
    },
    {
      "epoch": 4.890016920473773,
      "grad_norm": 0.0010363418841734529,
      "learning_rate": 3.370276367738297e-05,
      "loss": 0.0524,
      "step": 5780
    },
    {
      "epoch": 4.898477157360406,
      "grad_norm": 0.022306790575385094,
      "learning_rate": 3.367456288776086e-05,
      "loss": 0.0244,
      "step": 5790
    },
    {
      "epoch": 4.906937394247039,
      "grad_norm": 22.276203155517578,
      "learning_rate": 3.364636209813875e-05,
      "loss": 0.0373,
      "step": 5800
    },
    {
      "epoch": 4.915397631133672,
      "grad_norm": 0.03146412596106529,
      "learning_rate": 3.3618161308516636e-05,
      "loss": 0.0007,
      "step": 5810
    },
    {
      "epoch": 4.9238578680203045,
      "grad_norm": 0.0009572830749675632,
      "learning_rate": 3.358996051889453e-05,
      "loss": 0.0094,
      "step": 5820
    },
    {
      "epoch": 4.932318104906937,
      "grad_norm": 35.21375274658203,
      "learning_rate": 3.3561759729272425e-05,
      "loss": 0.1465,
      "step": 5830
    },
    {
      "epoch": 4.94077834179357,
      "grad_norm": 35.833221435546875,
      "learning_rate": 3.3533558939650313e-05,
      "loss": 0.0662,
      "step": 5840
    },
    {
      "epoch": 4.949238578680203,
      "grad_norm": 0.010310040786862373,
      "learning_rate": 3.35053581500282e-05,
      "loss": 0.1178,
      "step": 5850
    },
    {
      "epoch": 4.957698815566836,
      "grad_norm": 0.002540305256843567,
      "learning_rate": 3.347715736040609e-05,
      "loss": 0.0001,
      "step": 5860
    },
    {
      "epoch": 4.9661590524534684,
      "grad_norm": 0.07586555182933807,
      "learning_rate": 3.3448956570783984e-05,
      "loss": 0.0009,
      "step": 5870
    },
    {
      "epoch": 4.974619289340102,
      "grad_norm": 0.7592684626579285,
      "learning_rate": 3.342075578116187e-05,
      "loss": 0.0005,
      "step": 5880
    },
    {
      "epoch": 4.983079526226734,
      "grad_norm": 0.032136838883161545,
      "learning_rate": 3.339255499153977e-05,
      "loss": 0.0115,
      "step": 5890
    },
    {
      "epoch": 4.991539763113368,
      "grad_norm": 0.0005928167956881225,
      "learning_rate": 3.3364354201917655e-05,
      "loss": 0.0476,
      "step": 5900
    },
    {
      "epoch": 5.0,
      "grad_norm": 79.78588104248047,
      "learning_rate": 3.333615341229554e-05,
      "loss": 0.0601,
      "step": 5910
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9787037037037037,
      "eval_loss": 0.11622678488492966,
      "eval_runtime": 248.0008,
      "eval_samples_per_second": 21.774,
      "eval_steps_per_second": 2.722,
      "step": 5910
    },
    {
      "epoch": 5.008460236886632,
      "grad_norm": 0.08495175838470459,
      "learning_rate": 3.330795262267344e-05,
      "loss": 0.0001,
      "step": 5920
    },
    {
      "epoch": 5.016920473773266,
      "grad_norm": 0.0015004752203822136,
      "learning_rate": 3.3279751833051325e-05,
      "loss": 0.0386,
      "step": 5930
    },
    {
      "epoch": 5.025380710659898,
      "grad_norm": 0.005783995147794485,
      "learning_rate": 3.325155104342922e-05,
      "loss": 0.0003,
      "step": 5940
    },
    {
      "epoch": 5.0338409475465316,
      "grad_norm": 0.000916968856472522,
      "learning_rate": 3.322335025380711e-05,
      "loss": 0.0002,
      "step": 5950
    },
    {
      "epoch": 5.042301184433164,
      "grad_norm": 0.007372904568910599,
      "learning_rate": 3.3195149464184996e-05,
      "loss": 0.008,
      "step": 5960
    },
    {
      "epoch": 5.050761421319797,
      "grad_norm": 0.0011314525036141276,
      "learning_rate": 3.316694867456289e-05,
      "loss": 0.02,
      "step": 5970
    },
    {
      "epoch": 5.05922165820643,
      "grad_norm": 0.01762048900127411,
      "learning_rate": 3.313874788494078e-05,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 5.067681895093062,
      "grad_norm": 0.03547623008489609,
      "learning_rate": 3.3110547095318674e-05,
      "loss": 0.001,
      "step": 5990
    },
    {
      "epoch": 5.0761421319796955,
      "grad_norm": 0.0009837562683969736,
      "learning_rate": 3.308234630569656e-05,
      "loss": 0.0171,
      "step": 6000
    },
    {
      "epoch": 5.084602368866328,
      "grad_norm": 0.015334127470850945,
      "learning_rate": 3.305414551607445e-05,
      "loss": 0.0004,
      "step": 6010
    },
    {
      "epoch": 5.093062605752961,
      "grad_norm": 0.018826084211468697,
      "learning_rate": 3.302594472645234e-05,
      "loss": 0.0536,
      "step": 6020
    },
    {
      "epoch": 5.101522842639594,
      "grad_norm": 0.005876367446035147,
      "learning_rate": 3.299774393683023e-05,
      "loss": 0.0001,
      "step": 6030
    },
    {
      "epoch": 5.109983079526227,
      "grad_norm": 0.0012546040816232562,
      "learning_rate": 3.296954314720812e-05,
      "loss": 0.0494,
      "step": 6040
    },
    {
      "epoch": 5.1184433164128595,
      "grad_norm": 0.002867215545848012,
      "learning_rate": 3.2941342357586015e-05,
      "loss": 0.0475,
      "step": 6050
    },
    {
      "epoch": 5.126903553299492,
      "grad_norm": 0.003192116040736437,
      "learning_rate": 3.291314156796391e-05,
      "loss": 0.0001,
      "step": 6060
    },
    {
      "epoch": 5.135363790186125,
      "grad_norm": 25.30254554748535,
      "learning_rate": 3.288494077834179e-05,
      "loss": 0.0526,
      "step": 6070
    },
    {
      "epoch": 5.143824027072758,
      "grad_norm": 0.010442891158163548,
      "learning_rate": 3.2856739988719686e-05,
      "loss": 0.0038,
      "step": 6080
    },
    {
      "epoch": 5.152284263959391,
      "grad_norm": 0.002736078342422843,
      "learning_rate": 3.2828539199097574e-05,
      "loss": 0.0425,
      "step": 6090
    },
    {
      "epoch": 5.1607445008460235,
      "grad_norm": 0.004041831474751234,
      "learning_rate": 3.280033840947547e-05,
      "loss": 0.0681,
      "step": 6100
    },
    {
      "epoch": 5.169204737732657,
      "grad_norm": 0.0008186750928871334,
      "learning_rate": 3.2772137619853356e-05,
      "loss": 0.0016,
      "step": 6110
    },
    {
      "epoch": 5.177664974619289,
      "grad_norm": 0.0021178098395466805,
      "learning_rate": 3.274393683023125e-05,
      "loss": 0.0189,
      "step": 6120
    },
    {
      "epoch": 5.186125211505922,
      "grad_norm": 0.0012197758769616485,
      "learning_rate": 3.271573604060914e-05,
      "loss": 0.0005,
      "step": 6130
    },
    {
      "epoch": 5.194585448392555,
      "grad_norm": 28.292795181274414,
      "learning_rate": 3.268753525098703e-05,
      "loss": 0.0609,
      "step": 6140
    },
    {
      "epoch": 5.2030456852791875,
      "grad_norm": 0.0007349186344072223,
      "learning_rate": 3.265933446136492e-05,
      "loss": 0.0002,
      "step": 6150
    },
    {
      "epoch": 5.211505922165821,
      "grad_norm": 25.6258602142334,
      "learning_rate": 3.263113367174281e-05,
      "loss": 0.0287,
      "step": 6160
    },
    {
      "epoch": 5.219966159052453,
      "grad_norm": 0.005370883271098137,
      "learning_rate": 3.2602932882120704e-05,
      "loss": 0.0828,
      "step": 6170
    },
    {
      "epoch": 5.228426395939087,
      "grad_norm": 15.247941017150879,
      "learning_rate": 3.2574732092498586e-05,
      "loss": 0.0506,
      "step": 6180
    },
    {
      "epoch": 5.236886632825719,
      "grad_norm": 0.0015971384709700942,
      "learning_rate": 3.254653130287648e-05,
      "loss": 0.0001,
      "step": 6190
    },
    {
      "epoch": 5.2453468697123515,
      "grad_norm": 0.000837922387290746,
      "learning_rate": 3.2518330513254375e-05,
      "loss": 0.0004,
      "step": 6200
    },
    {
      "epoch": 5.253807106598985,
      "grad_norm": 0.0027105461340397596,
      "learning_rate": 3.249012972363226e-05,
      "loss": 0.0004,
      "step": 6210
    },
    {
      "epoch": 5.262267343485617,
      "grad_norm": 0.003533729584887624,
      "learning_rate": 3.246192893401016e-05,
      "loss": 0.0053,
      "step": 6220
    },
    {
      "epoch": 5.270727580372251,
      "grad_norm": 0.012713313102722168,
      "learning_rate": 3.2433728144388046e-05,
      "loss": 0.0001,
      "step": 6230
    },
    {
      "epoch": 5.279187817258883,
      "grad_norm": 0.00042596488492563367,
      "learning_rate": 3.2405527354765934e-05,
      "loss": 0.0378,
      "step": 6240
    },
    {
      "epoch": 5.287648054145516,
      "grad_norm": 0.011083374731242657,
      "learning_rate": 3.237732656514382e-05,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 5.296108291032149,
      "grad_norm": 0.00036169865052215755,
      "learning_rate": 3.2349125775521716e-05,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 5.304568527918782,
      "grad_norm": 0.002112647518515587,
      "learning_rate": 3.232092498589961e-05,
      "loss": 0.0,
      "step": 6270
    },
    {
      "epoch": 5.313028764805415,
      "grad_norm": 0.0004052052681799978,
      "learning_rate": 3.22927241962775e-05,
      "loss": 0.0001,
      "step": 6280
    },
    {
      "epoch": 5.321489001692047,
      "grad_norm": 0.005866990890353918,
      "learning_rate": 3.226452340665539e-05,
      "loss": 0.0021,
      "step": 6290
    },
    {
      "epoch": 5.32994923857868,
      "grad_norm": 0.00517220888286829,
      "learning_rate": 3.2236322617033275e-05,
      "loss": 0.0003,
      "step": 6300
    },
    {
      "epoch": 5.338409475465313,
      "grad_norm": 0.04557453468441963,
      "learning_rate": 3.220812182741117e-05,
      "loss": 0.003,
      "step": 6310
    },
    {
      "epoch": 5.346869712351946,
      "grad_norm": 0.0005734342848882079,
      "learning_rate": 3.217992103778906e-05,
      "loss": 0.0256,
      "step": 6320
    },
    {
      "epoch": 5.355329949238579,
      "grad_norm": 0.0027248302940279245,
      "learning_rate": 3.215172024816695e-05,
      "loss": 0.0211,
      "step": 6330
    },
    {
      "epoch": 5.363790186125211,
      "grad_norm": 2.960691452026367,
      "learning_rate": 3.212351945854484e-05,
      "loss": 0.0006,
      "step": 6340
    },
    {
      "epoch": 5.372250423011844,
      "grad_norm": 5.448554992675781,
      "learning_rate": 3.209531866892273e-05,
      "loss": 0.005,
      "step": 6350
    },
    {
      "epoch": 5.380710659898477,
      "grad_norm": 0.024258887395262718,
      "learning_rate": 3.206711787930062e-05,
      "loss": 0.0002,
      "step": 6360
    },
    {
      "epoch": 5.38917089678511,
      "grad_norm": 0.6432298421859741,
      "learning_rate": 3.203891708967851e-05,
      "loss": 0.0002,
      "step": 6370
    },
    {
      "epoch": 5.397631133671743,
      "grad_norm": 0.0006455639377236366,
      "learning_rate": 3.2010716300056406e-05,
      "loss": 0.0004,
      "step": 6380
    },
    {
      "epoch": 5.406091370558376,
      "grad_norm": 0.2651910185813904,
      "learning_rate": 3.1982515510434294e-05,
      "loss": 0.0001,
      "step": 6390
    },
    {
      "epoch": 5.414551607445008,
      "grad_norm": 0.19307082891464233,
      "learning_rate": 3.195431472081218e-05,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 5.423011844331642,
      "grad_norm": 0.0007573951734229922,
      "learning_rate": 3.1926113931190077e-05,
      "loss": 0.0003,
      "step": 6410
    },
    {
      "epoch": 5.431472081218274,
      "grad_norm": 26.83254051208496,
      "learning_rate": 3.1897913141567965e-05,
      "loss": 0.0498,
      "step": 6420
    },
    {
      "epoch": 5.439932318104907,
      "grad_norm": 0.0006683140527456999,
      "learning_rate": 3.186971235194586e-05,
      "loss": 0.0057,
      "step": 6430
    },
    {
      "epoch": 5.44839255499154,
      "grad_norm": 0.018950549885630608,
      "learning_rate": 3.184151156232375e-05,
      "loss": 0.0001,
      "step": 6440
    },
    {
      "epoch": 5.456852791878172,
      "grad_norm": 0.023443851619958878,
      "learning_rate": 3.1813310772701635e-05,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 5.465313028764806,
      "grad_norm": 0.0004122857644688338,
      "learning_rate": 3.178510998307952e-05,
      "loss": 0.0953,
      "step": 6460
    },
    {
      "epoch": 5.473773265651438,
      "grad_norm": 0.0008734120056033134,
      "learning_rate": 3.175690919345742e-05,
      "loss": 0.0004,
      "step": 6470
    },
    {
      "epoch": 5.482233502538071,
      "grad_norm": 1.0449550151824951,
      "learning_rate": 3.172870840383531e-05,
      "loss": 0.0003,
      "step": 6480
    },
    {
      "epoch": 5.490693739424704,
      "grad_norm": 0.007900227792561054,
      "learning_rate": 3.17005076142132e-05,
      "loss": 0.0006,
      "step": 6490
    },
    {
      "epoch": 5.499153976311336,
      "grad_norm": 0.0005304730148054659,
      "learning_rate": 3.167230682459109e-05,
      "loss": 0.0005,
      "step": 6500
    },
    {
      "epoch": 5.50761421319797,
      "grad_norm": 8.895605087280273,
      "learning_rate": 3.1644106034968977e-05,
      "loss": 0.06,
      "step": 6510
    },
    {
      "epoch": 5.516074450084602,
      "grad_norm": 2.346642255783081,
      "learning_rate": 3.161590524534687e-05,
      "loss": 0.0517,
      "step": 6520
    },
    {
      "epoch": 5.5245346869712355,
      "grad_norm": 0.12202025204896927,
      "learning_rate": 3.158770445572476e-05,
      "loss": 0.0003,
      "step": 6530
    },
    {
      "epoch": 5.532994923857868,
      "grad_norm": 2.0430760383605957,
      "learning_rate": 3.1559503666102654e-05,
      "loss": 0.0018,
      "step": 6540
    },
    {
      "epoch": 5.541455160744501,
      "grad_norm": 0.35401085019111633,
      "learning_rate": 3.153130287648054e-05,
      "loss": 0.0003,
      "step": 6550
    },
    {
      "epoch": 5.549915397631134,
      "grad_norm": 0.0007037241593934596,
      "learning_rate": 3.150310208685843e-05,
      "loss": 0.0014,
      "step": 6560
    },
    {
      "epoch": 5.558375634517766,
      "grad_norm": 0.006385166198015213,
      "learning_rate": 3.1474901297236325e-05,
      "loss": 0.0005,
      "step": 6570
    },
    {
      "epoch": 5.5668358714043995,
      "grad_norm": 33.14509963989258,
      "learning_rate": 3.144670050761421e-05,
      "loss": 0.0414,
      "step": 6580
    },
    {
      "epoch": 5.575296108291032,
      "grad_norm": 0.00223042001016438,
      "learning_rate": 3.141849971799211e-05,
      "loss": 0.0007,
      "step": 6590
    },
    {
      "epoch": 5.583756345177665,
      "grad_norm": 36.303218841552734,
      "learning_rate": 3.1390298928369995e-05,
      "loss": 0.0077,
      "step": 6600
    },
    {
      "epoch": 5.592216582064298,
      "grad_norm": 0.00037199180223979056,
      "learning_rate": 3.136209813874788e-05,
      "loss": 0.006,
      "step": 6610
    },
    {
      "epoch": 5.60067681895093,
      "grad_norm": 0.04985667020082474,
      "learning_rate": 3.133389734912578e-05,
      "loss": 0.0005,
      "step": 6620
    },
    {
      "epoch": 5.6091370558375635,
      "grad_norm": 0.0007710065692663193,
      "learning_rate": 3.1305696559503666e-05,
      "loss": 0.0,
      "step": 6630
    },
    {
      "epoch": 5.617597292724196,
      "grad_norm": 48.421661376953125,
      "learning_rate": 3.127749576988156e-05,
      "loss": 0.016,
      "step": 6640
    },
    {
      "epoch": 5.626057529610829,
      "grad_norm": 0.003799519734457135,
      "learning_rate": 3.124929498025945e-05,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 5.634517766497462,
      "grad_norm": 0.05970016121864319,
      "learning_rate": 3.122109419063734e-05,
      "loss": 0.0131,
      "step": 6660
    },
    {
      "epoch": 5.642978003384095,
      "grad_norm": 0.0006615244783461094,
      "learning_rate": 3.1192893401015225e-05,
      "loss": 0.0014,
      "step": 6670
    },
    {
      "epoch": 5.6514382402707275,
      "grad_norm": 87.96739959716797,
      "learning_rate": 3.116469261139312e-05,
      "loss": 0.0127,
      "step": 6680
    },
    {
      "epoch": 5.659898477157361,
      "grad_norm": 33.777366638183594,
      "learning_rate": 3.1136491821771014e-05,
      "loss": 0.0232,
      "step": 6690
    },
    {
      "epoch": 5.668358714043993,
      "grad_norm": 0.0013313748640939593,
      "learning_rate": 3.11082910321489e-05,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 5.676818950930626,
      "grad_norm": 0.04303807392716408,
      "learning_rate": 3.10800902425268e-05,
      "loss": 0.0111,
      "step": 6710
    },
    {
      "epoch": 5.685279187817259,
      "grad_norm": 0.0009377577225677669,
      "learning_rate": 3.105188945290468e-05,
      "loss": 0.0016,
      "step": 6720
    },
    {
      "epoch": 5.6937394247038915,
      "grad_norm": 0.0021734172478318214,
      "learning_rate": 3.102368866328257e-05,
      "loss": 0.0222,
      "step": 6730
    },
    {
      "epoch": 5.702199661590525,
      "grad_norm": 0.0005417380016297102,
      "learning_rate": 3.099548787366046e-05,
      "loss": 0.0219,
      "step": 6740
    },
    {
      "epoch": 5.710659898477157,
      "grad_norm": 0.03769075870513916,
      "learning_rate": 3.0967287084038355e-05,
      "loss": 0.0006,
      "step": 6750
    },
    {
      "epoch": 5.71912013536379,
      "grad_norm": 0.0042506069876253605,
      "learning_rate": 3.093908629441625e-05,
      "loss": 0.0004,
      "step": 6760
    },
    {
      "epoch": 5.727580372250423,
      "grad_norm": 0.0004971229354850948,
      "learning_rate": 3.091088550479414e-05,
      "loss": 0.0004,
      "step": 6770
    },
    {
      "epoch": 5.7360406091370555,
      "grad_norm": 0.01640683226287365,
      "learning_rate": 3.0882684715172026e-05,
      "loss": 0.0007,
      "step": 6780
    },
    {
      "epoch": 5.744500846023689,
      "grad_norm": 0.0006340723484754562,
      "learning_rate": 3.0854483925549914e-05,
      "loss": 0.0,
      "step": 6790
    },
    {
      "epoch": 5.752961082910321,
      "grad_norm": 0.22736212611198425,
      "learning_rate": 3.082628313592781e-05,
      "loss": 0.0323,
      "step": 6800
    },
    {
      "epoch": 5.761421319796955,
      "grad_norm": 0.003824122017249465,
      "learning_rate": 3.07980823463057e-05,
      "loss": 0.0,
      "step": 6810
    },
    {
      "epoch": 5.769881556683587,
      "grad_norm": 0.022976025938987732,
      "learning_rate": 3.076988155668359e-05,
      "loss": 0.0001,
      "step": 6820
    },
    {
      "epoch": 5.77834179357022,
      "grad_norm": 0.0008392822928726673,
      "learning_rate": 3.074168076706148e-05,
      "loss": 0.035,
      "step": 6830
    },
    {
      "epoch": 5.786802030456853,
      "grad_norm": 0.0015063630416989326,
      "learning_rate": 3.071347997743937e-05,
      "loss": 0.0003,
      "step": 6840
    },
    {
      "epoch": 5.795262267343485,
      "grad_norm": 0.000911880808416754,
      "learning_rate": 3.068527918781726e-05,
      "loss": 0.0001,
      "step": 6850
    },
    {
      "epoch": 5.803722504230119,
      "grad_norm": 0.0008936713566072285,
      "learning_rate": 3.065707839819515e-05,
      "loss": 0.0035,
      "step": 6860
    },
    {
      "epoch": 5.812182741116751,
      "grad_norm": 0.002141870092600584,
      "learning_rate": 3.0628877608573045e-05,
      "loss": 0.0552,
      "step": 6870
    },
    {
      "epoch": 5.820642978003384,
      "grad_norm": 0.030858591198921204,
      "learning_rate": 3.060067681895093e-05,
      "loss": 0.0003,
      "step": 6880
    },
    {
      "epoch": 5.829103214890017,
      "grad_norm": 0.0005173183744773269,
      "learning_rate": 3.057247602932882e-05,
      "loss": 0.0,
      "step": 6890
    },
    {
      "epoch": 5.837563451776649,
      "grad_norm": 0.0010564984986558557,
      "learning_rate": 3.0544275239706716e-05,
      "loss": 0.0061,
      "step": 6900
    },
    {
      "epoch": 5.846023688663283,
      "grad_norm": 0.0009607492247596383,
      "learning_rate": 3.0516074450084604e-05,
      "loss": 0.0112,
      "step": 6910
    },
    {
      "epoch": 5.854483925549915,
      "grad_norm": 3.633603096008301,
      "learning_rate": 3.0487873660462495e-05,
      "loss": 0.0008,
      "step": 6920
    },
    {
      "epoch": 5.862944162436548,
      "grad_norm": 0.0016195817152038217,
      "learning_rate": 3.0459672870840383e-05,
      "loss": 0.0,
      "step": 6930
    },
    {
      "epoch": 5.871404399323181,
      "grad_norm": 0.0004758294962812215,
      "learning_rate": 3.0431472081218278e-05,
      "loss": 0.0295,
      "step": 6940
    },
    {
      "epoch": 5.879864636209814,
      "grad_norm": 0.0005642222240567207,
      "learning_rate": 3.0403271291596162e-05,
      "loss": 0.0004,
      "step": 6950
    },
    {
      "epoch": 5.888324873096447,
      "grad_norm": 0.023344742134213448,
      "learning_rate": 3.0375070501974057e-05,
      "loss": 0.01,
      "step": 6960
    },
    {
      "epoch": 5.89678510998308,
      "grad_norm": 0.0040983459912240505,
      "learning_rate": 3.0346869712351948e-05,
      "loss": 0.0001,
      "step": 6970
    },
    {
      "epoch": 5.905245346869712,
      "grad_norm": 0.0004066282417625189,
      "learning_rate": 3.0318668922729836e-05,
      "loss": 0.0,
      "step": 6980
    },
    {
      "epoch": 5.913705583756345,
      "grad_norm": 1.4917168617248535,
      "learning_rate": 3.029046813310773e-05,
      "loss": 0.015,
      "step": 6990
    },
    {
      "epoch": 5.922165820642978,
      "grad_norm": 0.0008524596341885626,
      "learning_rate": 3.026226734348562e-05,
      "loss": 0.0883,
      "step": 7000
    },
    {
      "epoch": 5.930626057529611,
      "grad_norm": 0.002848224714398384,
      "learning_rate": 3.023406655386351e-05,
      "loss": 0.0003,
      "step": 7010
    },
    {
      "epoch": 5.939086294416244,
      "grad_norm": 0.01002656389027834,
      "learning_rate": 3.0205865764241398e-05,
      "loss": 0.0001,
      "step": 7020
    },
    {
      "epoch": 5.947546531302876,
      "grad_norm": 0.008435835130512714,
      "learning_rate": 3.017766497461929e-05,
      "loss": 0.0002,
      "step": 7030
    },
    {
      "epoch": 5.95600676818951,
      "grad_norm": 0.007835909724235535,
      "learning_rate": 3.0149464184997184e-05,
      "loss": 0.0377,
      "step": 7040
    },
    {
      "epoch": 5.964467005076142,
      "grad_norm": 0.0030949332285672426,
      "learning_rate": 3.0121263395375072e-05,
      "loss": 0.0001,
      "step": 7050
    },
    {
      "epoch": 5.972927241962775,
      "grad_norm": 0.0005452055484056473,
      "learning_rate": 3.0093062605752964e-05,
      "loss": 0.0104,
      "step": 7060
    },
    {
      "epoch": 5.981387478849408,
      "grad_norm": 0.002691934583708644,
      "learning_rate": 3.006486181613085e-05,
      "loss": 0.0354,
      "step": 7070
    },
    {
      "epoch": 5.98984771573604,
      "grad_norm": 0.08875536173582077,
      "learning_rate": 3.0036661026508743e-05,
      "loss": 0.0002,
      "step": 7080
    },
    {
      "epoch": 5.998307952622674,
      "grad_norm": 0.00024556650896556675,
      "learning_rate": 3.000846023688663e-05,
      "loss": 0.0001,
      "step": 7090
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9831481481481481,
      "eval_loss": 0.10116706788539886,
      "eval_runtime": 248.1101,
      "eval_samples_per_second": 21.765,
      "eval_steps_per_second": 2.721,
      "step": 7092
    },
    {
      "epoch": 6.006768189509306,
      "grad_norm": 0.001750582130625844,
      "learning_rate": 2.9980259447264526e-05,
      "loss": 0.0001,
      "step": 7100
    },
    {
      "epoch": 6.0152284263959395,
      "grad_norm": 0.004709551110863686,
      "learning_rate": 2.9952058657642417e-05,
      "loss": 0.0561,
      "step": 7110
    },
    {
      "epoch": 6.023688663282572,
      "grad_norm": 0.0005288380780257285,
      "learning_rate": 2.9923857868020305e-05,
      "loss": 0.0,
      "step": 7120
    },
    {
      "epoch": 6.032148900169204,
      "grad_norm": 0.001504052197560668,
      "learning_rate": 2.98956570783982e-05,
      "loss": 0.0406,
      "step": 7130
    },
    {
      "epoch": 6.040609137055838,
      "grad_norm": 0.0004155637579970062,
      "learning_rate": 2.9867456288776084e-05,
      "loss": 0.0,
      "step": 7140
    },
    {
      "epoch": 6.04906937394247,
      "grad_norm": 0.001209916896186769,
      "learning_rate": 2.983925549915398e-05,
      "loss": 0.0043,
      "step": 7150
    },
    {
      "epoch": 6.0575296108291035,
      "grad_norm": 0.0019743279553949833,
      "learning_rate": 2.9811054709531867e-05,
      "loss": 0.0,
      "step": 7160
    },
    {
      "epoch": 6.065989847715736,
      "grad_norm": 0.0005867692525498569,
      "learning_rate": 2.978285391990976e-05,
      "loss": 0.0596,
      "step": 7170
    },
    {
      "epoch": 6.074450084602369,
      "grad_norm": 0.0006942094187252223,
      "learning_rate": 2.9754653130287653e-05,
      "loss": 0.0,
      "step": 7180
    },
    {
      "epoch": 6.082910321489002,
      "grad_norm": 0.0018677710322663188,
      "learning_rate": 2.9726452340665538e-05,
      "loss": 0.0428,
      "step": 7190
    },
    {
      "epoch": 6.091370558375634,
      "grad_norm": 0.00038502219831570983,
      "learning_rate": 2.9698251551043432e-05,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 6.0998307952622675,
      "grad_norm": 0.0003239148354623467,
      "learning_rate": 2.967005076142132e-05,
      "loss": 0.0,
      "step": 7210
    },
    {
      "epoch": 6.1082910321489,
      "grad_norm": 58.96702194213867,
      "learning_rate": 2.9641849971799212e-05,
      "loss": 0.0574,
      "step": 7220
    },
    {
      "epoch": 6.116751269035533,
      "grad_norm": 0.0004127335560042411,
      "learning_rate": 2.96136491821771e-05,
      "loss": 0.0002,
      "step": 7230
    },
    {
      "epoch": 6.125211505922166,
      "grad_norm": 0.021679222583770752,
      "learning_rate": 2.9585448392554995e-05,
      "loss": 0.0002,
      "step": 7240
    },
    {
      "epoch": 6.133671742808799,
      "grad_norm": 0.0002247494412586093,
      "learning_rate": 2.9557247602932886e-05,
      "loss": 0.0005,
      "step": 7250
    },
    {
      "epoch": 6.1421319796954315,
      "grad_norm": 50.51150894165039,
      "learning_rate": 2.9529046813310774e-05,
      "loss": 0.0643,
      "step": 7260
    },
    {
      "epoch": 6.150592216582064,
      "grad_norm": 0.0025869489181786776,
      "learning_rate": 2.9500846023688665e-05,
      "loss": 0.0013,
      "step": 7270
    },
    {
      "epoch": 6.159052453468697,
      "grad_norm": 0.175792396068573,
      "learning_rate": 2.9472645234066553e-05,
      "loss": 0.066,
      "step": 7280
    },
    {
      "epoch": 6.16751269035533,
      "grad_norm": 0.00038070796290412545,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0742,
      "step": 7290
    },
    {
      "epoch": 6.175972927241963,
      "grad_norm": 0.00038723289617337286,
      "learning_rate": 2.9416243654822332e-05,
      "loss": 0.075,
      "step": 7300
    },
    {
      "epoch": 6.1844331641285955,
      "grad_norm": 0.0017645959742367268,
      "learning_rate": 2.9388042865200227e-05,
      "loss": 0.0295,
      "step": 7310
    },
    {
      "epoch": 6.192893401015229,
      "grad_norm": 0.0023752269335091114,
      "learning_rate": 2.935984207557812e-05,
      "loss": 0.0496,
      "step": 7320
    },
    {
      "epoch": 6.201353637901861,
      "grad_norm": 0.03596610203385353,
      "learning_rate": 2.9331641285956007e-05,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 6.209813874788494,
      "grad_norm": 1.6637327671051025,
      "learning_rate": 2.93034404963339e-05,
      "loss": 0.0033,
      "step": 7340
    },
    {
      "epoch": 6.218274111675127,
      "grad_norm": 0.027758944779634476,
      "learning_rate": 2.927523970671179e-05,
      "loss": 0.0002,
      "step": 7350
    },
    {
      "epoch": 6.2267343485617594,
      "grad_norm": 0.0018780857790261507,
      "learning_rate": 2.924703891708968e-05,
      "loss": 0.0949,
      "step": 7360
    },
    {
      "epoch": 6.235194585448393,
      "grad_norm": 0.012435970827937126,
      "learning_rate": 2.921883812746757e-05,
      "loss": 0.0001,
      "step": 7370
    },
    {
      "epoch": 6.243654822335025,
      "grad_norm": 0.023554546758532524,
      "learning_rate": 2.919063733784546e-05,
      "loss": 0.0118,
      "step": 7380
    },
    {
      "epoch": 6.2521150592216586,
      "grad_norm": 0.0009328334708698094,
      "learning_rate": 2.9162436548223355e-05,
      "loss": 0.0006,
      "step": 7390
    },
    {
      "epoch": 6.260575296108291,
      "grad_norm": 0.0012919788714498281,
      "learning_rate": 2.9134235758601243e-05,
      "loss": 0.0665,
      "step": 7400
    },
    {
      "epoch": 6.269035532994923,
      "grad_norm": 12.773752212524414,
      "learning_rate": 2.9106034968979134e-05,
      "loss": 0.0013,
      "step": 7410
    },
    {
      "epoch": 6.277495769881557,
      "grad_norm": 0.001793396077118814,
      "learning_rate": 2.9077834179357022e-05,
      "loss": 0.0389,
      "step": 7420
    },
    {
      "epoch": 6.285956006768189,
      "grad_norm": 0.0005340121570043266,
      "learning_rate": 2.9049633389734913e-05,
      "loss": 0.0,
      "step": 7430
    },
    {
      "epoch": 6.2944162436548226,
      "grad_norm": 0.0009798122337087989,
      "learning_rate": 2.90214326001128e-05,
      "loss": 0.001,
      "step": 7440
    },
    {
      "epoch": 6.302876480541455,
      "grad_norm": 0.0005731796845793724,
      "learning_rate": 2.8993231810490696e-05,
      "loss": 0.0131,
      "step": 7450
    },
    {
      "epoch": 6.311336717428088,
      "grad_norm": 0.11826997995376587,
      "learning_rate": 2.8965031020868587e-05,
      "loss": 0.0001,
      "step": 7460
    },
    {
      "epoch": 6.319796954314721,
      "grad_norm": 0.0020495953503996134,
      "learning_rate": 2.8936830231246475e-05,
      "loss": 0.0283,
      "step": 7470
    },
    {
      "epoch": 6.328257191201354,
      "grad_norm": 0.019431916996836662,
      "learning_rate": 2.890862944162437e-05,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 6.3367174280879865,
      "grad_norm": 0.0017547764582559466,
      "learning_rate": 2.8880428652002255e-05,
      "loss": 0.0,
      "step": 7490
    },
    {
      "epoch": 6.345177664974619,
      "grad_norm": 0.0007229670882225037,
      "learning_rate": 2.885222786238015e-05,
      "loss": 0.0001,
      "step": 7500
    },
    {
      "epoch": 6.353637901861252,
      "grad_norm": 0.0009207396069541574,
      "learning_rate": 2.8824027072758037e-05,
      "loss": 0.0,
      "step": 7510
    },
    {
      "epoch": 6.362098138747885,
      "grad_norm": 0.0016133275348693132,
      "learning_rate": 2.879582628313593e-05,
      "loss": 0.0,
      "step": 7520
    },
    {
      "epoch": 6.370558375634518,
      "grad_norm": 0.2163955718278885,
      "learning_rate": 2.8767625493513823e-05,
      "loss": 0.0007,
      "step": 7530
    },
    {
      "epoch": 6.3790186125211505,
      "grad_norm": 0.008737131953239441,
      "learning_rate": 2.873942470389171e-05,
      "loss": 0.0,
      "step": 7540
    },
    {
      "epoch": 6.387478849407783,
      "grad_norm": 0.00042356428457424045,
      "learning_rate": 2.8711223914269603e-05,
      "loss": 0.0053,
      "step": 7550
    },
    {
      "epoch": 6.395939086294416,
      "grad_norm": 0.01112381462007761,
      "learning_rate": 2.868302312464749e-05,
      "loss": 0.0405,
      "step": 7560
    },
    {
      "epoch": 6.404399323181049,
      "grad_norm": 0.7466667890548706,
      "learning_rate": 2.8654822335025382e-05,
      "loss": 0.012,
      "step": 7570
    },
    {
      "epoch": 6.412859560067682,
      "grad_norm": 0.0011975442757830024,
      "learning_rate": 2.862662154540327e-05,
      "loss": 0.033,
      "step": 7580
    },
    {
      "epoch": 6.4213197969543145,
      "grad_norm": 0.004585925955325365,
      "learning_rate": 2.8598420755781165e-05,
      "loss": 0.0179,
      "step": 7590
    },
    {
      "epoch": 6.429780033840948,
      "grad_norm": 0.0006403092993423343,
      "learning_rate": 2.8570219966159056e-05,
      "loss": 0.0003,
      "step": 7600
    },
    {
      "epoch": 6.43824027072758,
      "grad_norm": 0.0010181210236623883,
      "learning_rate": 2.8542019176536944e-05,
      "loss": 0.0008,
      "step": 7610
    },
    {
      "epoch": 6.446700507614214,
      "grad_norm": 0.0006577486637979746,
      "learning_rate": 2.8513818386914835e-05,
      "loss": 0.0009,
      "step": 7620
    },
    {
      "epoch": 6.455160744500846,
      "grad_norm": 0.006843026261776686,
      "learning_rate": 2.8485617597292723e-05,
      "loss": 0.0006,
      "step": 7630
    },
    {
      "epoch": 6.4636209813874785,
      "grad_norm": 0.000459567760117352,
      "learning_rate": 2.8457416807670618e-05,
      "loss": 0.0004,
      "step": 7640
    },
    {
      "epoch": 6.472081218274112,
      "grad_norm": 0.0007854198338463902,
      "learning_rate": 2.8429216018048506e-05,
      "loss": 0.0006,
      "step": 7650
    },
    {
      "epoch": 6.480541455160744,
      "grad_norm": 0.00045840590610168874,
      "learning_rate": 2.8401015228426397e-05,
      "loss": 0.0,
      "step": 7660
    },
    {
      "epoch": 6.489001692047378,
      "grad_norm": 0.0042251888662576675,
      "learning_rate": 2.837281443880429e-05,
      "loss": 0.0396,
      "step": 7670
    },
    {
      "epoch": 6.49746192893401,
      "grad_norm": 0.0017824436072260141,
      "learning_rate": 2.8344613649182177e-05,
      "loss": 0.0,
      "step": 7680
    },
    {
      "epoch": 6.5059221658206425,
      "grad_norm": 0.001419363426975906,
      "learning_rate": 2.831641285956007e-05,
      "loss": 0.0004,
      "step": 7690
    },
    {
      "epoch": 6.514382402707276,
      "grad_norm": 0.00023823160154279321,
      "learning_rate": 2.828821206993796e-05,
      "loss": 0.0004,
      "step": 7700
    },
    {
      "epoch": 6.522842639593908,
      "grad_norm": 0.0006499981973320246,
      "learning_rate": 2.826001128031585e-05,
      "loss": 0.0419,
      "step": 7710
    },
    {
      "epoch": 6.531302876480542,
      "grad_norm": 0.0015448539052158594,
      "learning_rate": 2.823181049069374e-05,
      "loss": 0.001,
      "step": 7720
    },
    {
      "epoch": 6.539763113367174,
      "grad_norm": 0.5018176436424255,
      "learning_rate": 2.820360970107163e-05,
      "loss": 0.0807,
      "step": 7730
    },
    {
      "epoch": 6.548223350253807,
      "grad_norm": 0.0015597770689055324,
      "learning_rate": 2.8175408911449525e-05,
      "loss": 0.0214,
      "step": 7740
    },
    {
      "epoch": 6.55668358714044,
      "grad_norm": 72.75348663330078,
      "learning_rate": 2.8147208121827413e-05,
      "loss": 0.0235,
      "step": 7750
    },
    {
      "epoch": 6.565143824027073,
      "grad_norm": 0.5070732235908508,
      "learning_rate": 2.8119007332205304e-05,
      "loss": 0.0068,
      "step": 7760
    },
    {
      "epoch": 6.573604060913706,
      "grad_norm": 0.003215300850570202,
      "learning_rate": 2.8090806542583192e-05,
      "loss": 0.0007,
      "step": 7770
    },
    {
      "epoch": 6.582064297800338,
      "grad_norm": 0.0017314753495156765,
      "learning_rate": 2.8062605752961087e-05,
      "loss": 0.0001,
      "step": 7780
    },
    {
      "epoch": 6.590524534686971,
      "grad_norm": 0.002985464408993721,
      "learning_rate": 2.803440496333897e-05,
      "loss": 0.0455,
      "step": 7790
    },
    {
      "epoch": 6.598984771573604,
      "grad_norm": 0.0027501119766384363,
      "learning_rate": 2.8006204173716866e-05,
      "loss": 0.0011,
      "step": 7800
    },
    {
      "epoch": 6.607445008460237,
      "grad_norm": 0.0075990064069628716,
      "learning_rate": 2.7978003384094758e-05,
      "loss": 0.0002,
      "step": 7810
    },
    {
      "epoch": 6.61590524534687,
      "grad_norm": 0.002549176337197423,
      "learning_rate": 2.7949802594472646e-05,
      "loss": 0.0,
      "step": 7820
    },
    {
      "epoch": 6.624365482233502,
      "grad_norm": 0.0005004932172596455,
      "learning_rate": 2.792160180485054e-05,
      "loss": 0.0002,
      "step": 7830
    },
    {
      "epoch": 6.632825719120135,
      "grad_norm": 0.0013734594685956836,
      "learning_rate": 2.7893401015228425e-05,
      "loss": 0.0,
      "step": 7840
    },
    {
      "epoch": 6.641285956006768,
      "grad_norm": 0.001727665076032281,
      "learning_rate": 2.786520022560632e-05,
      "loss": 0.0,
      "step": 7850
    },
    {
      "epoch": 6.649746192893401,
      "grad_norm": 0.0007502950611524284,
      "learning_rate": 2.7836999435984208e-05,
      "loss": 0.0,
      "step": 7860
    },
    {
      "epoch": 6.658206429780034,
      "grad_norm": 0.0012970510870218277,
      "learning_rate": 2.78087986463621e-05,
      "loss": 0.0026,
      "step": 7870
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.0010487665422260761,
      "learning_rate": 2.7780597856739994e-05,
      "loss": 0.0011,
      "step": 7880
    },
    {
      "epoch": 6.675126903553299,
      "grad_norm": 0.01294900942593813,
      "learning_rate": 2.775239706711788e-05,
      "loss": 0.0,
      "step": 7890
    },
    {
      "epoch": 6.683587140439933,
      "grad_norm": 0.05023118853569031,
      "learning_rate": 2.7724196277495773e-05,
      "loss": 0.0001,
      "step": 7900
    },
    {
      "epoch": 6.692047377326565,
      "grad_norm": 0.0005081488052383065,
      "learning_rate": 2.769599548787366e-05,
      "loss": 0.0,
      "step": 7910
    },
    {
      "epoch": 6.700507614213198,
      "grad_norm": 1.9741630554199219,
      "learning_rate": 2.7667794698251552e-05,
      "loss": 0.0531,
      "step": 7920
    },
    {
      "epoch": 6.708967851099831,
      "grad_norm": 0.0005357271293178201,
      "learning_rate": 2.763959390862944e-05,
      "loss": 0.0002,
      "step": 7930
    },
    {
      "epoch": 6.717428087986463,
      "grad_norm": 0.006255467887967825,
      "learning_rate": 2.7611393119007335e-05,
      "loss": 0.001,
      "step": 7940
    },
    {
      "epoch": 6.725888324873097,
      "grad_norm": 0.0017415584297850728,
      "learning_rate": 2.7583192329385226e-05,
      "loss": 0.0944,
      "step": 7950
    },
    {
      "epoch": 6.734348561759729,
      "grad_norm": 0.0004496847395785153,
      "learning_rate": 2.7554991539763114e-05,
      "loss": 0.0015,
      "step": 7960
    },
    {
      "epoch": 6.742808798646362,
      "grad_norm": 0.00036373804323375225,
      "learning_rate": 2.7526790750141006e-05,
      "loss": 0.0,
      "step": 7970
    },
    {
      "epoch": 6.751269035532995,
      "grad_norm": 0.0007861431804485619,
      "learning_rate": 2.7498589960518894e-05,
      "loss": 0.0311,
      "step": 7980
    },
    {
      "epoch": 6.759729272419627,
      "grad_norm": 0.0029205346945673227,
      "learning_rate": 2.747038917089679e-05,
      "loss": 0.0101,
      "step": 7990
    },
    {
      "epoch": 6.768189509306261,
      "grad_norm": 0.0020245590712875128,
      "learning_rate": 2.7442188381274676e-05,
      "loss": 0.0001,
      "step": 8000
    },
    {
      "epoch": 6.776649746192893,
      "grad_norm": 0.0004121851525269449,
      "learning_rate": 2.7413987591652568e-05,
      "loss": 0.0001,
      "step": 8010
    },
    {
      "epoch": 6.7851099830795265,
      "grad_norm": 0.0004014628939330578,
      "learning_rate": 2.7385786802030462e-05,
      "loss": 0.0764,
      "step": 8020
    },
    {
      "epoch": 6.793570219966159,
      "grad_norm": 0.005122969392687082,
      "learning_rate": 2.7357586012408347e-05,
      "loss": 0.0128,
      "step": 8030
    },
    {
      "epoch": 6.802030456852792,
      "grad_norm": 0.0085369311273098,
      "learning_rate": 2.7329385222786242e-05,
      "loss": 0.0347,
      "step": 8040
    },
    {
      "epoch": 6.810490693739425,
      "grad_norm": 4.8010478019714355,
      "learning_rate": 2.730118443316413e-05,
      "loss": 0.0511,
      "step": 8050
    },
    {
      "epoch": 6.818950930626057,
      "grad_norm": 70.66097259521484,
      "learning_rate": 2.727298364354202e-05,
      "loss": 0.0606,
      "step": 8060
    },
    {
      "epoch": 6.8274111675126905,
      "grad_norm": 0.003385297954082489,
      "learning_rate": 2.724478285391991e-05,
      "loss": 0.0086,
      "step": 8070
    },
    {
      "epoch": 6.835871404399323,
      "grad_norm": 0.0010107946582138538,
      "learning_rate": 2.72165820642978e-05,
      "loss": 0.0804,
      "step": 8080
    },
    {
      "epoch": 6.844331641285956,
      "grad_norm": 0.05418635159730911,
      "learning_rate": 2.7188381274675695e-05,
      "loss": 0.0046,
      "step": 8090
    },
    {
      "epoch": 6.852791878172589,
      "grad_norm": 0.0018369925674051046,
      "learning_rate": 2.7160180485053583e-05,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 6.861252115059221,
      "grad_norm": 0.4337839186191559,
      "learning_rate": 2.7131979695431475e-05,
      "loss": 0.0225,
      "step": 8110
    },
    {
      "epoch": 6.8697123519458545,
      "grad_norm": 4.322873592376709,
      "learning_rate": 2.7103778905809362e-05,
      "loss": 0.0619,
      "step": 8120
    },
    {
      "epoch": 6.878172588832487,
      "grad_norm": 0.0004570123855955899,
      "learning_rate": 2.7075578116187257e-05,
      "loss": 0.0062,
      "step": 8130
    },
    {
      "epoch": 6.88663282571912,
      "grad_norm": 0.00990690290927887,
      "learning_rate": 2.7047377326565142e-05,
      "loss": 0.001,
      "step": 8140
    },
    {
      "epoch": 6.895093062605753,
      "grad_norm": 0.01537672895938158,
      "learning_rate": 2.7019176536943037e-05,
      "loss": 0.0519,
      "step": 8150
    },
    {
      "epoch": 6.903553299492386,
      "grad_norm": 0.0014003268443048,
      "learning_rate": 2.6990975747320928e-05,
      "loss": 0.0,
      "step": 8160
    },
    {
      "epoch": 6.9120135363790185,
      "grad_norm": 0.0004866714298259467,
      "learning_rate": 2.6962774957698816e-05,
      "loss": 0.0776,
      "step": 8170
    },
    {
      "epoch": 6.920473773265652,
      "grad_norm": 23.079984664916992,
      "learning_rate": 2.693457416807671e-05,
      "loss": 0.0054,
      "step": 8180
    },
    {
      "epoch": 6.928934010152284,
      "grad_norm": 0.006753965280950069,
      "learning_rate": 2.6906373378454595e-05,
      "loss": 0.0001,
      "step": 8190
    },
    {
      "epoch": 6.937394247038917,
      "grad_norm": 0.8095031380653381,
      "learning_rate": 2.687817258883249e-05,
      "loss": 0.0008,
      "step": 8200
    },
    {
      "epoch": 6.94585448392555,
      "grad_norm": 0.0016577603528276086,
      "learning_rate": 2.6849971799210378e-05,
      "loss": 0.0003,
      "step": 8210
    },
    {
      "epoch": 6.9543147208121825,
      "grad_norm": 0.0007078401395119727,
      "learning_rate": 2.682177100958827e-05,
      "loss": 0.0001,
      "step": 8220
    },
    {
      "epoch": 6.962774957698816,
      "grad_norm": 0.0003305015270598233,
      "learning_rate": 2.6793570219966157e-05,
      "loss": 0.004,
      "step": 8230
    },
    {
      "epoch": 6.971235194585448,
      "grad_norm": 3.134098768234253,
      "learning_rate": 2.6765369430344052e-05,
      "loss": 0.0007,
      "step": 8240
    },
    {
      "epoch": 6.979695431472082,
      "grad_norm": 30.96390151977539,
      "learning_rate": 2.6737168640721943e-05,
      "loss": 0.0096,
      "step": 8250
    },
    {
      "epoch": 6.988155668358714,
      "grad_norm": 0.014233553782105446,
      "learning_rate": 2.670896785109983e-05,
      "loss": 0.0002,
      "step": 8260
    },
    {
      "epoch": 6.9966159052453465,
      "grad_norm": 0.001011527027003467,
      "learning_rate": 2.6680767061477723e-05,
      "loss": 0.0,
      "step": 8270
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9783333333333334,
      "eval_loss": 0.13195747137069702,
      "eval_runtime": 248.584,
      "eval_samples_per_second": 21.723,
      "eval_steps_per_second": 2.715,
      "step": 8274
    },
    {
      "epoch": 7.00507614213198,
      "grad_norm": 0.04417493939399719,
      "learning_rate": 2.665256627185561e-05,
      "loss": 0.0,
      "step": 8280
    },
    {
      "epoch": 7.013536379018612,
      "grad_norm": 0.004311149939894676,
      "learning_rate": 2.6624365482233505e-05,
      "loss": 0.0,
      "step": 8290
    },
    {
      "epoch": 7.021996615905246,
      "grad_norm": 0.0009231153526343405,
      "learning_rate": 2.6596164692611393e-05,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 7.030456852791878,
      "grad_norm": 2.1970698833465576,
      "learning_rate": 2.6567963902989285e-05,
      "loss": 0.0004,
      "step": 8310
    },
    {
      "epoch": 7.038917089678511,
      "grad_norm": 0.0015641051577404141,
      "learning_rate": 2.6539763113367176e-05,
      "loss": 0.0,
      "step": 8320
    },
    {
      "epoch": 7.047377326565144,
      "grad_norm": 0.0022692736238241196,
      "learning_rate": 2.6511562323745064e-05,
      "loss": 0.0,
      "step": 8330
    },
    {
      "epoch": 7.055837563451776,
      "grad_norm": 0.0009962613694369793,
      "learning_rate": 2.648336153412296e-05,
      "loss": 0.0045,
      "step": 8340
    },
    {
      "epoch": 7.06429780033841,
      "grad_norm": 0.0008909639436751604,
      "learning_rate": 2.6455160744500847e-05,
      "loss": 0.0002,
      "step": 8350
    },
    {
      "epoch": 7.072758037225042,
      "grad_norm": 0.00047105655539780855,
      "learning_rate": 2.6426959954878738e-05,
      "loss": 0.0009,
      "step": 8360
    },
    {
      "epoch": 7.081218274111675,
      "grad_norm": 0.0006099925958551466,
      "learning_rate": 2.6398759165256626e-05,
      "loss": 0.001,
      "step": 8370
    },
    {
      "epoch": 7.089678510998308,
      "grad_norm": 0.014448132365942001,
      "learning_rate": 2.6370558375634517e-05,
      "loss": 0.0047,
      "step": 8380
    },
    {
      "epoch": 7.098138747884941,
      "grad_norm": 0.011289873160421848,
      "learning_rate": 2.6342357586012412e-05,
      "loss": 0.0,
      "step": 8390
    },
    {
      "epoch": 7.106598984771574,
      "grad_norm": 0.0006280772504396737,
      "learning_rate": 2.63141567963903e-05,
      "loss": 0.0026,
      "step": 8400
    },
    {
      "epoch": 7.115059221658206,
      "grad_norm": 0.000557292252779007,
      "learning_rate": 2.628595600676819e-05,
      "loss": 0.0001,
      "step": 8410
    },
    {
      "epoch": 7.123519458544839,
      "grad_norm": 56.67745590209961,
      "learning_rate": 2.625775521714608e-05,
      "loss": 0.0204,
      "step": 8420
    },
    {
      "epoch": 7.131979695431472,
      "grad_norm": 0.0002933672512881458,
      "learning_rate": 2.6229554427523974e-05,
      "loss": 0.0,
      "step": 8430
    },
    {
      "epoch": 7.140439932318105,
      "grad_norm": 0.0014420138904824853,
      "learning_rate": 2.620135363790186e-05,
      "loss": 0.0093,
      "step": 8440
    },
    {
      "epoch": 7.148900169204738,
      "grad_norm": 0.0948992669582367,
      "learning_rate": 2.6173152848279753e-05,
      "loss": 0.0001,
      "step": 8450
    },
    {
      "epoch": 7.157360406091371,
      "grad_norm": 0.0005032621556892991,
      "learning_rate": 2.6144952058657645e-05,
      "loss": 0.0444,
      "step": 8460
    },
    {
      "epoch": 7.165820642978003,
      "grad_norm": 0.0003914123517461121,
      "learning_rate": 2.6116751269035533e-05,
      "loss": 0.0002,
      "step": 8470
    },
    {
      "epoch": 7.174280879864636,
      "grad_norm": 0.0030163535848259926,
      "learning_rate": 2.6088550479413427e-05,
      "loss": 0.0001,
      "step": 8480
    },
    {
      "epoch": 7.182741116751269,
      "grad_norm": 0.00072705332422629,
      "learning_rate": 2.6060349689791312e-05,
      "loss": 0.0054,
      "step": 8490
    },
    {
      "epoch": 7.191201353637902,
      "grad_norm": 0.0005904209101572633,
      "learning_rate": 2.6032148900169207e-05,
      "loss": 0.0004,
      "step": 8500
    },
    {
      "epoch": 7.199661590524535,
      "grad_norm": 0.0007385284407064319,
      "learning_rate": 2.6003948110547095e-05,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 7.208121827411167,
      "grad_norm": 0.0008186242775991559,
      "learning_rate": 2.5975747320924986e-05,
      "loss": 0.0009,
      "step": 8520
    },
    {
      "epoch": 7.216582064297801,
      "grad_norm": 0.000592954340390861,
      "learning_rate": 2.594754653130288e-05,
      "loss": 0.0,
      "step": 8530
    },
    {
      "epoch": 7.225042301184433,
      "grad_norm": 0.0004609551397152245,
      "learning_rate": 2.591934574168077e-05,
      "loss": 0.0634,
      "step": 8540
    },
    {
      "epoch": 7.233502538071066,
      "grad_norm": 0.00023650319781154394,
      "learning_rate": 2.589114495205866e-05,
      "loss": 0.0,
      "step": 8550
    },
    {
      "epoch": 7.241962774957699,
      "grad_norm": 0.00022180331870913506,
      "learning_rate": 2.5862944162436548e-05,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 7.250423011844331,
      "grad_norm": 0.00042606916395016015,
      "learning_rate": 2.583474337281444e-05,
      "loss": 0.0122,
      "step": 8570
    },
    {
      "epoch": 7.258883248730965,
      "grad_norm": 0.004835863132029772,
      "learning_rate": 2.5806542583192327e-05,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 7.267343485617597,
      "grad_norm": 0.02337002195417881,
      "learning_rate": 2.5778341793570222e-05,
      "loss": 0.0001,
      "step": 8590
    },
    {
      "epoch": 7.2758037225042305,
      "grad_norm": 0.0007640512194484472,
      "learning_rate": 2.5750141003948114e-05,
      "loss": 0.0012,
      "step": 8600
    },
    {
      "epoch": 7.284263959390863,
      "grad_norm": 0.09290546923875809,
      "learning_rate": 2.5721940214326e-05,
      "loss": 0.0,
      "step": 8610
    },
    {
      "epoch": 7.292724196277495,
      "grad_norm": 0.0020191383082419634,
      "learning_rate": 2.5693739424703893e-05,
      "loss": 0.0,
      "step": 8620
    },
    {
      "epoch": 7.301184433164129,
      "grad_norm": 0.0002144567115465179,
      "learning_rate": 2.566553863508178e-05,
      "loss": 0.0,
      "step": 8630
    },
    {
      "epoch": 7.309644670050761,
      "grad_norm": 0.004900167230516672,
      "learning_rate": 2.5637337845459676e-05,
      "loss": 0.0429,
      "step": 8640
    },
    {
      "epoch": 7.3181049069373945,
      "grad_norm": 0.0008796135662123561,
      "learning_rate": 2.5609137055837564e-05,
      "loss": 0.0,
      "step": 8650
    },
    {
      "epoch": 7.326565143824027,
      "grad_norm": 0.0003961726324632764,
      "learning_rate": 2.5580936266215455e-05,
      "loss": 0.0,
      "step": 8660
    },
    {
      "epoch": 7.33502538071066,
      "grad_norm": 0.007298395968973637,
      "learning_rate": 2.555273547659335e-05,
      "loss": 0.0,
      "step": 8670
    },
    {
      "epoch": 7.343485617597293,
      "grad_norm": 0.027740634977817535,
      "learning_rate": 2.5524534686971234e-05,
      "loss": 0.0,
      "step": 8680
    },
    {
      "epoch": 7.351945854483926,
      "grad_norm": 0.01982933282852173,
      "learning_rate": 2.549633389734913e-05,
      "loss": 0.0,
      "step": 8690
    },
    {
      "epoch": 7.3604060913705585,
      "grad_norm": 0.000262660498265177,
      "learning_rate": 2.5468133107727017e-05,
      "loss": 0.0116,
      "step": 8700
    },
    {
      "epoch": 7.368866328257191,
      "grad_norm": 0.0005152460071258247,
      "learning_rate": 2.5439932318104908e-05,
      "loss": 0.0026,
      "step": 8710
    },
    {
      "epoch": 7.377326565143824,
      "grad_norm": 0.000578017090447247,
      "learning_rate": 2.5411731528482796e-05,
      "loss": 0.0001,
      "step": 8720
    },
    {
      "epoch": 7.385786802030457,
      "grad_norm": 0.0677829161286354,
      "learning_rate": 2.5383530738860688e-05,
      "loss": 0.0619,
      "step": 8730
    },
    {
      "epoch": 7.39424703891709,
      "grad_norm": 0.0003226820845156908,
      "learning_rate": 2.5355329949238582e-05,
      "loss": 0.0,
      "step": 8740
    },
    {
      "epoch": 7.4027072758037225,
      "grad_norm": 0.0009318586671724916,
      "learning_rate": 2.532712915961647e-05,
      "loss": 0.003,
      "step": 8750
    },
    {
      "epoch": 7.411167512690355,
      "grad_norm": 0.0004680722195189446,
      "learning_rate": 2.529892836999436e-05,
      "loss": 0.0,
      "step": 8760
    },
    {
      "epoch": 7.419627749576988,
      "grad_norm": 0.0007791185635142028,
      "learning_rate": 2.527072758037225e-05,
      "loss": 0.0,
      "step": 8770
    },
    {
      "epoch": 7.428087986463621,
      "grad_norm": 0.00044054060708731413,
      "learning_rate": 2.5242526790750144e-05,
      "loss": 0.0231,
      "step": 8780
    },
    {
      "epoch": 7.436548223350254,
      "grad_norm": 0.0005597808631137013,
      "learning_rate": 2.521432600112803e-05,
      "loss": 0.0,
      "step": 8790
    },
    {
      "epoch": 7.4450084602368864,
      "grad_norm": 0.014114903286099434,
      "learning_rate": 2.5186125211505924e-05,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 7.45346869712352,
      "grad_norm": 0.006000615656375885,
      "learning_rate": 2.5157924421883815e-05,
      "loss": 0.0031,
      "step": 8810
    },
    {
      "epoch": 7.461928934010152,
      "grad_norm": 0.0004874904698226601,
      "learning_rate": 2.5129723632261703e-05,
      "loss": 0.0,
      "step": 8820
    },
    {
      "epoch": 7.470389170896786,
      "grad_norm": 0.001959633780643344,
      "learning_rate": 2.5101522842639598e-05,
      "loss": 0.0,
      "step": 8830
    },
    {
      "epoch": 7.478849407783418,
      "grad_norm": 0.000528340635355562,
      "learning_rate": 2.5073322053017482e-05,
      "loss": 0.0001,
      "step": 8840
    },
    {
      "epoch": 7.4873096446700504,
      "grad_norm": 0.00026639559655450284,
      "learning_rate": 2.5045121263395377e-05,
      "loss": 0.0349,
      "step": 8850
    },
    {
      "epoch": 7.495769881556684,
      "grad_norm": 0.00032993938657455146,
      "learning_rate": 2.5016920473773265e-05,
      "loss": 0.0,
      "step": 8860
    },
    {
      "epoch": 7.504230118443316,
      "grad_norm": 0.00041854011942632496,
      "learning_rate": 2.4988719684151156e-05,
      "loss": 0.0,
      "step": 8870
    },
    {
      "epoch": 7.5126903553299496,
      "grad_norm": 0.0005558948614634573,
      "learning_rate": 2.4960518894529048e-05,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 7.521150592216582,
      "grad_norm": 0.00028763010050170124,
      "learning_rate": 2.493231810490694e-05,
      "loss": 0.0,
      "step": 8890
    },
    {
      "epoch": 7.529610829103214,
      "grad_norm": 0.004597924184054136,
      "learning_rate": 2.4904117315284827e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 7.538071065989848,
      "grad_norm": 0.0004905695095658302,
      "learning_rate": 2.4875916525662722e-05,
      "loss": 0.0,
      "step": 8910
    },
    {
      "epoch": 7.54653130287648,
      "grad_norm": 0.00033250724663957953,
      "learning_rate": 2.484771573604061e-05,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 7.5549915397631136,
      "grad_norm": 0.021187547594308853,
      "learning_rate": 2.48195149464185e-05,
      "loss": 0.0,
      "step": 8930
    },
    {
      "epoch": 7.563451776649746,
      "grad_norm": 0.0003025640035048127,
      "learning_rate": 2.4791314156796392e-05,
      "loss": 0.0,
      "step": 8940
    },
    {
      "epoch": 7.571912013536379,
      "grad_norm": 0.00019252994388807565,
      "learning_rate": 2.476311336717428e-05,
      "loss": 0.0,
      "step": 8950
    },
    {
      "epoch": 7.580372250423012,
      "grad_norm": 0.0003077980945818126,
      "learning_rate": 2.4734912577552172e-05,
      "loss": 0.0341,
      "step": 8960
    },
    {
      "epoch": 7.588832487309645,
      "grad_norm": 0.0007933809538371861,
      "learning_rate": 2.4706711787930063e-05,
      "loss": 0.0374,
      "step": 8970
    },
    {
      "epoch": 7.5972927241962775,
      "grad_norm": 0.0005731445271521807,
      "learning_rate": 2.4678510998307954e-05,
      "loss": 0.0,
      "step": 8980
    },
    {
      "epoch": 7.60575296108291,
      "grad_norm": 0.00037330263876356184,
      "learning_rate": 2.4650310208685846e-05,
      "loss": 0.0075,
      "step": 8990
    },
    {
      "epoch": 7.614213197969543,
      "grad_norm": 0.4792309105396271,
      "learning_rate": 2.4622109419063734e-05,
      "loss": 0.0678,
      "step": 9000
    },
    {
      "epoch": 7.622673434856176,
      "grad_norm": 0.0010386076755821705,
      "learning_rate": 2.4593908629441625e-05,
      "loss": 0.0,
      "step": 9010
    },
    {
      "epoch": 7.631133671742809,
      "grad_norm": 0.0003225019318051636,
      "learning_rate": 2.4565707839819517e-05,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 7.6395939086294415,
      "grad_norm": 0.010798987001180649,
      "learning_rate": 2.4537507050197404e-05,
      "loss": 0.0,
      "step": 9030
    },
    {
      "epoch": 7.648054145516074,
      "grad_norm": 0.00023477936338167638,
      "learning_rate": 2.4509306260575296e-05,
      "loss": 0.0109,
      "step": 9040
    },
    {
      "epoch": 7.656514382402707,
      "grad_norm": 41.383174896240234,
      "learning_rate": 2.448110547095319e-05,
      "loss": 0.0446,
      "step": 9050
    },
    {
      "epoch": 7.66497461928934,
      "grad_norm": 20.769775390625,
      "learning_rate": 2.445290468133108e-05,
      "loss": 0.0051,
      "step": 9060
    },
    {
      "epoch": 7.673434856175973,
      "grad_norm": 0.00040438707219436765,
      "learning_rate": 2.442470389170897e-05,
      "loss": 0.0006,
      "step": 9070
    },
    {
      "epoch": 7.6818950930626055,
      "grad_norm": 0.03379608318209648,
      "learning_rate": 2.4396503102086858e-05,
      "loss": 0.0139,
      "step": 9080
    },
    {
      "epoch": 7.690355329949239,
      "grad_norm": 0.00042095777462236583,
      "learning_rate": 2.436830231246475e-05,
      "loss": 0.001,
      "step": 9090
    },
    {
      "epoch": 7.698815566835871,
      "grad_norm": 0.0003579046460799873,
      "learning_rate": 2.434010152284264e-05,
      "loss": 0.0003,
      "step": 9100
    },
    {
      "epoch": 7.707275803722505,
      "grad_norm": 0.0002435656206216663,
      "learning_rate": 2.431190073322053e-05,
      "loss": 0.0371,
      "step": 9110
    },
    {
      "epoch": 7.715736040609137,
      "grad_norm": 0.0004285743343643844,
      "learning_rate": 2.4283699943598423e-05,
      "loss": 0.0004,
      "step": 9120
    },
    {
      "epoch": 7.7241962774957695,
      "grad_norm": 35.37118148803711,
      "learning_rate": 2.4255499153976315e-05,
      "loss": 0.0349,
      "step": 9130
    },
    {
      "epoch": 7.732656514382403,
      "grad_norm": 0.001822065096348524,
      "learning_rate": 2.4227298364354203e-05,
      "loss": 0.0,
      "step": 9140
    },
    {
      "epoch": 7.741116751269035,
      "grad_norm": 0.00045900052646175027,
      "learning_rate": 2.4199097574732094e-05,
      "loss": 0.0077,
      "step": 9150
    },
    {
      "epoch": 7.749576988155669,
      "grad_norm": 0.0661391019821167,
      "learning_rate": 2.4170896785109985e-05,
      "loss": 0.0003,
      "step": 9160
    },
    {
      "epoch": 7.758037225042301,
      "grad_norm": 0.0007200148538686335,
      "learning_rate": 2.4142695995487873e-05,
      "loss": 0.0,
      "step": 9170
    },
    {
      "epoch": 7.7664974619289335,
      "grad_norm": 0.0004172374901827425,
      "learning_rate": 2.4114495205865765e-05,
      "loss": 0.0,
      "step": 9180
    },
    {
      "epoch": 7.774957698815567,
      "grad_norm": 0.0002744777302723378,
      "learning_rate": 2.4086294416243656e-05,
      "loss": 0.0,
      "step": 9190
    },
    {
      "epoch": 7.783417935702199,
      "grad_norm": 0.014424902386963367,
      "learning_rate": 2.4058093626621547e-05,
      "loss": 0.0001,
      "step": 9200
    },
    {
      "epoch": 7.791878172588833,
      "grad_norm": 17.57308006286621,
      "learning_rate": 2.402989283699944e-05,
      "loss": 0.0024,
      "step": 9210
    },
    {
      "epoch": 7.800338409475465,
      "grad_norm": 0.0008011744357645512,
      "learning_rate": 2.4001692047377327e-05,
      "loss": 0.0,
      "step": 9220
    },
    {
      "epoch": 7.808798646362098,
      "grad_norm": 0.0006662519881501794,
      "learning_rate": 2.3973491257755218e-05,
      "loss": 0.0,
      "step": 9230
    },
    {
      "epoch": 7.817258883248731,
      "grad_norm": 0.00026312420959584415,
      "learning_rate": 2.394529046813311e-05,
      "loss": 0.0005,
      "step": 9240
    },
    {
      "epoch": 7.825719120135364,
      "grad_norm": 0.011150856502354145,
      "learning_rate": 2.3917089678510997e-05,
      "loss": 0.0,
      "step": 9250
    },
    {
      "epoch": 7.834179357021997,
      "grad_norm": 0.0004387092776596546,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.0002,
      "step": 9260
    },
    {
      "epoch": 7.842639593908629,
      "grad_norm": 0.2780689299106598,
      "learning_rate": 2.386068809926678e-05,
      "loss": 0.0606,
      "step": 9270
    },
    {
      "epoch": 7.851099830795262,
      "grad_norm": 0.0036916490644216537,
      "learning_rate": 2.383248730964467e-05,
      "loss": 0.0,
      "step": 9280
    },
    {
      "epoch": 7.859560067681895,
      "grad_norm": 0.0004022230568807572,
      "learning_rate": 2.3804286520022563e-05,
      "loss": 0.0011,
      "step": 9290
    },
    {
      "epoch": 7.868020304568528,
      "grad_norm": 0.0013881343184038997,
      "learning_rate": 2.377608573040045e-05,
      "loss": 0.0001,
      "step": 9300
    },
    {
      "epoch": 7.876480541455161,
      "grad_norm": 0.00020758257596753538,
      "learning_rate": 2.3747884940778342e-05,
      "loss": 0.0,
      "step": 9310
    },
    {
      "epoch": 7.884940778341793,
      "grad_norm": 0.0002912292839027941,
      "learning_rate": 2.3719684151156233e-05,
      "loss": 0.0003,
      "step": 9320
    },
    {
      "epoch": 7.893401015228426,
      "grad_norm": 0.00025648405426181853,
      "learning_rate": 2.3691483361534125e-05,
      "loss": 0.0,
      "step": 9330
    },
    {
      "epoch": 7.901861252115059,
      "grad_norm": 0.0002877891529351473,
      "learning_rate": 2.3663282571912016e-05,
      "loss": 0.0,
      "step": 9340
    },
    {
      "epoch": 7.910321489001692,
      "grad_norm": 0.0003156211460009217,
      "learning_rate": 2.3635081782289904e-05,
      "loss": 0.0002,
      "step": 9350
    },
    {
      "epoch": 7.918781725888325,
      "grad_norm": 0.0002979850978590548,
      "learning_rate": 2.3606880992667795e-05,
      "loss": 0.0036,
      "step": 9360
    },
    {
      "epoch": 7.927241962774958,
      "grad_norm": 0.00023434878676198423,
      "learning_rate": 2.3578680203045687e-05,
      "loss": 0.0,
      "step": 9370
    },
    {
      "epoch": 7.93570219966159,
      "grad_norm": 0.0006011166842654347,
      "learning_rate": 2.3550479413423575e-05,
      "loss": 0.072,
      "step": 9380
    },
    {
      "epoch": 7.944162436548224,
      "grad_norm": 1.2562932968139648,
      "learning_rate": 2.3522278623801466e-05,
      "loss": 0.0024,
      "step": 9390
    },
    {
      "epoch": 7.952622673434856,
      "grad_norm": 0.0004057602200191468,
      "learning_rate": 2.349407783417936e-05,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 7.961082910321489,
      "grad_norm": 0.00972333736717701,
      "learning_rate": 2.346587704455725e-05,
      "loss": 0.0,
      "step": 9410
    },
    {
      "epoch": 7.969543147208122,
      "grad_norm": 0.0003254947951063514,
      "learning_rate": 2.343767625493514e-05,
      "loss": 0.0,
      "step": 9420
    },
    {
      "epoch": 7.978003384094754,
      "grad_norm": 0.0006241763476282358,
      "learning_rate": 2.340947546531303e-05,
      "loss": 0.0,
      "step": 9430
    },
    {
      "epoch": 7.986463620981388,
      "grad_norm": 0.0003053112013731152,
      "learning_rate": 2.338127467569092e-05,
      "loss": 0.0,
      "step": 9440
    },
    {
      "epoch": 7.99492385786802,
      "grad_norm": 0.0019893923308700323,
      "learning_rate": 2.335307388606881e-05,
      "loss": 0.0,
      "step": 9450
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9777777777777777,
      "eval_loss": 0.14105992019176483,
      "eval_runtime": 246.8697,
      "eval_samples_per_second": 21.874,
      "eval_steps_per_second": 2.734,
      "step": 9456
    },
    {
      "epoch": 8.003384094754653,
      "grad_norm": 0.0002609639195725322,
      "learning_rate": 2.33248730964467e-05,
      "loss": 0.0098,
      "step": 9460
    },
    {
      "epoch": 8.011844331641287,
      "grad_norm": 0.00028957115137018263,
      "learning_rate": 2.3296672306824594e-05,
      "loss": 0.0,
      "step": 9470
    },
    {
      "epoch": 8.02030456852792,
      "grad_norm": 0.000590721087064594,
      "learning_rate": 2.3268471517202485e-05,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 8.028764805414552,
      "grad_norm": 0.0005317007307894528,
      "learning_rate": 2.3240270727580373e-05,
      "loss": 0.0331,
      "step": 9490
    },
    {
      "epoch": 8.037225042301184,
      "grad_norm": 0.0002540628192946315,
      "learning_rate": 2.3212069937958264e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 8.045685279187817,
      "grad_norm": 0.003167835995554924,
      "learning_rate": 2.3183869148336156e-05,
      "loss": 0.0,
      "step": 9510
    },
    {
      "epoch": 8.05414551607445,
      "grad_norm": 0.0014109063195064664,
      "learning_rate": 2.3155668358714044e-05,
      "loss": 0.0,
      "step": 9520
    },
    {
      "epoch": 8.062605752961083,
      "grad_norm": 0.0023475433699786663,
      "learning_rate": 2.3127467569091935e-05,
      "loss": 0.0258,
      "step": 9530
    },
    {
      "epoch": 8.071065989847716,
      "grad_norm": 0.00022713826911058277,
      "learning_rate": 2.3099266779469826e-05,
      "loss": 0.0347,
      "step": 9540
    },
    {
      "epoch": 8.079526226734348,
      "grad_norm": 0.01207967009395361,
      "learning_rate": 2.3071065989847718e-05,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 8.08798646362098,
      "grad_norm": 0.00018360908143222332,
      "learning_rate": 2.304286520022561e-05,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 8.096446700507615,
      "grad_norm": 0.0003522584156598896,
      "learning_rate": 2.3014664410603497e-05,
      "loss": 0.0,
      "step": 9570
    },
    {
      "epoch": 8.104906937394247,
      "grad_norm": 0.0012087960494682193,
      "learning_rate": 2.2986463620981388e-05,
      "loss": 0.0001,
      "step": 9580
    },
    {
      "epoch": 8.11336717428088,
      "grad_norm": 0.02450253814458847,
      "learning_rate": 2.295826283135928e-05,
      "loss": 0.0411,
      "step": 9590
    },
    {
      "epoch": 8.121827411167512,
      "grad_norm": 0.0012558778980746865,
      "learning_rate": 2.2930062041737168e-05,
      "loss": 0.0142,
      "step": 9600
    },
    {
      "epoch": 8.130287648054146,
      "grad_norm": 0.00017645191110204905,
      "learning_rate": 2.2901861252115062e-05,
      "loss": 0.0,
      "step": 9610
    },
    {
      "epoch": 8.138747884940779,
      "grad_norm": 0.0037180117797106504,
      "learning_rate": 2.287366046249295e-05,
      "loss": 0.0043,
      "step": 9620
    },
    {
      "epoch": 8.147208121827411,
      "grad_norm": 0.0003910218074452132,
      "learning_rate": 2.284545967287084e-05,
      "loss": 0.0001,
      "step": 9630
    },
    {
      "epoch": 8.155668358714044,
      "grad_norm": 0.0004491691943258047,
      "learning_rate": 2.2817258883248733e-05,
      "loss": 0.0,
      "step": 9640
    },
    {
      "epoch": 8.164128595600676,
      "grad_norm": 0.0002563384477980435,
      "learning_rate": 2.278905809362662e-05,
      "loss": 0.0,
      "step": 9650
    },
    {
      "epoch": 8.17258883248731,
      "grad_norm": 0.00023523981508333236,
      "learning_rate": 2.2760857304004512e-05,
      "loss": 0.0002,
      "step": 9660
    },
    {
      "epoch": 8.181049069373943,
      "grad_norm": 0.00026224524481222034,
      "learning_rate": 2.2732656514382404e-05,
      "loss": 0.0277,
      "step": 9670
    },
    {
      "epoch": 8.189509306260575,
      "grad_norm": 0.00022213462216313928,
      "learning_rate": 2.2704455724760295e-05,
      "loss": 0.0511,
      "step": 9680
    },
    {
      "epoch": 8.197969543147208,
      "grad_norm": 0.0003204367239959538,
      "learning_rate": 2.2676254935138186e-05,
      "loss": 0.0,
      "step": 9690
    },
    {
      "epoch": 8.20642978003384,
      "grad_norm": 0.010431020520627499,
      "learning_rate": 2.2648054145516078e-05,
      "loss": 0.0011,
      "step": 9700
    },
    {
      "epoch": 8.214890016920474,
      "grad_norm": 0.0002529295743443072,
      "learning_rate": 2.2619853355893966e-05,
      "loss": 0.0,
      "step": 9710
    },
    {
      "epoch": 8.223350253807107,
      "grad_norm": 0.0006073036347515881,
      "learning_rate": 2.2591652566271857e-05,
      "loss": 0.0001,
      "step": 9720
    },
    {
      "epoch": 8.23181049069374,
      "grad_norm": 0.00025792146334424615,
      "learning_rate": 2.2563451776649745e-05,
      "loss": 0.0,
      "step": 9730
    },
    {
      "epoch": 8.240270727580372,
      "grad_norm": 0.0038322091568261385,
      "learning_rate": 2.2535250987027636e-05,
      "loss": 0.0752,
      "step": 9740
    },
    {
      "epoch": 8.248730964467006,
      "grad_norm": 0.000400882912799716,
      "learning_rate": 2.250705019740553e-05,
      "loss": 0.0005,
      "step": 9750
    },
    {
      "epoch": 8.257191201353638,
      "grad_norm": 0.005917025730013847,
      "learning_rate": 2.247884940778342e-05,
      "loss": 0.0062,
      "step": 9760
    },
    {
      "epoch": 8.26565143824027,
      "grad_norm": 1.735076665878296,
      "learning_rate": 2.245064861816131e-05,
      "loss": 0.0003,
      "step": 9770
    },
    {
      "epoch": 8.274111675126903,
      "grad_norm": 0.0012299735099077225,
      "learning_rate": 2.2422447828539202e-05,
      "loss": 0.0002,
      "step": 9780
    },
    {
      "epoch": 8.282571912013536,
      "grad_norm": 0.00029872619779780507,
      "learning_rate": 2.239424703891709e-05,
      "loss": 0.0058,
      "step": 9790
    },
    {
      "epoch": 8.29103214890017,
      "grad_norm": 2.7030231952667236,
      "learning_rate": 2.236604624929498e-05,
      "loss": 0.0004,
      "step": 9800
    },
    {
      "epoch": 8.299492385786802,
      "grad_norm": 0.01142918225377798,
      "learning_rate": 2.2337845459672872e-05,
      "loss": 0.0,
      "step": 9810
    },
    {
      "epoch": 8.307952622673435,
      "grad_norm": 0.00032102211844176054,
      "learning_rate": 2.2309644670050764e-05,
      "loss": 0.051,
      "step": 9820
    },
    {
      "epoch": 8.316412859560067,
      "grad_norm": 0.0007466164533980191,
      "learning_rate": 2.2281443880428655e-05,
      "loss": 0.0,
      "step": 9830
    },
    {
      "epoch": 8.3248730964467,
      "grad_norm": 0.024288147687911987,
      "learning_rate": 2.2253243090806543e-05,
      "loss": 0.001,
      "step": 9840
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.00030534176039509475,
      "learning_rate": 2.2225042301184434e-05,
      "loss": 0.0563,
      "step": 9850
    },
    {
      "epoch": 8.341793570219966,
      "grad_norm": 0.00033466951572336257,
      "learning_rate": 2.2196841511562326e-05,
      "loss": 0.0,
      "step": 9860
    },
    {
      "epoch": 8.350253807106599,
      "grad_norm": 0.001037093810737133,
      "learning_rate": 2.2168640721940214e-05,
      "loss": 0.0,
      "step": 9870
    },
    {
      "epoch": 8.358714043993231,
      "grad_norm": 0.0006812553037889302,
      "learning_rate": 2.2140439932318105e-05,
      "loss": 0.0,
      "step": 9880
    },
    {
      "epoch": 8.367174280879865,
      "grad_norm": 0.0004699396376963705,
      "learning_rate": 2.2112239142695997e-05,
      "loss": 0.0,
      "step": 9890
    },
    {
      "epoch": 8.375634517766498,
      "grad_norm": 0.0006885165348649025,
      "learning_rate": 2.2084038353073888e-05,
      "loss": 0.0001,
      "step": 9900
    },
    {
      "epoch": 8.38409475465313,
      "grad_norm": 0.014322511851787567,
      "learning_rate": 2.205583756345178e-05,
      "loss": 0.0,
      "step": 9910
    },
    {
      "epoch": 8.392554991539763,
      "grad_norm": 0.07389923185110092,
      "learning_rate": 2.2027636773829667e-05,
      "loss": 0.0,
      "step": 9920
    },
    {
      "epoch": 8.401015228426395,
      "grad_norm": 9.86077880859375,
      "learning_rate": 2.199943598420756e-05,
      "loss": 0.0009,
      "step": 9930
    },
    {
      "epoch": 8.40947546531303,
      "grad_norm": 0.0002648482332006097,
      "learning_rate": 2.197123519458545e-05,
      "loss": 0.0215,
      "step": 9940
    },
    {
      "epoch": 8.417935702199662,
      "grad_norm": 0.00020755399600602686,
      "learning_rate": 2.1943034404963338e-05,
      "loss": 0.0008,
      "step": 9950
    },
    {
      "epoch": 8.426395939086294,
      "grad_norm": 0.00023127166787162423,
      "learning_rate": 2.191483361534123e-05,
      "loss": 0.0024,
      "step": 9960
    },
    {
      "epoch": 8.434856175972927,
      "grad_norm": 0.0007119415677152574,
      "learning_rate": 2.188663282571912e-05,
      "loss": 0.0,
      "step": 9970
    },
    {
      "epoch": 8.44331641285956,
      "grad_norm": 0.0014589587226510048,
      "learning_rate": 2.1858432036097012e-05,
      "loss": 0.048,
      "step": 9980
    },
    {
      "epoch": 8.451776649746193,
      "grad_norm": 0.00018006828031502664,
      "learning_rate": 2.1830231246474903e-05,
      "loss": 0.0001,
      "step": 9990
    },
    {
      "epoch": 8.460236886632826,
      "grad_norm": 0.01180814579129219,
      "learning_rate": 2.180203045685279e-05,
      "loss": 0.0045,
      "step": 10000
    },
    {
      "epoch": 8.468697123519458,
      "grad_norm": 0.0003135066363029182,
      "learning_rate": 2.1773829667230683e-05,
      "loss": 0.0133,
      "step": 10010
    },
    {
      "epoch": 8.47715736040609,
      "grad_norm": 0.0001978356740437448,
      "learning_rate": 2.1745628877608574e-05,
      "loss": 0.0,
      "step": 10020
    },
    {
      "epoch": 8.485617597292725,
      "grad_norm": 0.0002471207990311086,
      "learning_rate": 2.1717428087986462e-05,
      "loss": 0.0,
      "step": 10030
    },
    {
      "epoch": 8.494077834179357,
      "grad_norm": 0.0013372402172535658,
      "learning_rate": 2.1689227298364357e-05,
      "loss": 0.0005,
      "step": 10040
    },
    {
      "epoch": 8.50253807106599,
      "grad_norm": 0.0010720272548496723,
      "learning_rate": 2.1661026508742248e-05,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 8.510998307952622,
      "grad_norm": 0.0003527978842612356,
      "learning_rate": 2.1632825719120136e-05,
      "loss": 0.0,
      "step": 10060
    },
    {
      "epoch": 8.519458544839255,
      "grad_norm": 0.0005748957628384233,
      "learning_rate": 2.1604624929498027e-05,
      "loss": 0.0038,
      "step": 10070
    },
    {
      "epoch": 8.527918781725889,
      "grad_norm": 0.0002674429561011493,
      "learning_rate": 2.157642413987592e-05,
      "loss": 0.0208,
      "step": 10080
    },
    {
      "epoch": 8.536379018612521,
      "grad_norm": 0.0001878468319773674,
      "learning_rate": 2.1548223350253807e-05,
      "loss": 0.0001,
      "step": 10090
    },
    {
      "epoch": 8.544839255499154,
      "grad_norm": 0.00024025475431699306,
      "learning_rate": 2.1520022560631698e-05,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 8.553299492385786,
      "grad_norm": 0.0010116755729541183,
      "learning_rate": 2.149182177100959e-05,
      "loss": 0.0335,
      "step": 10110
    },
    {
      "epoch": 8.561759729272419,
      "grad_norm": 0.0002856069477275014,
      "learning_rate": 2.146362098138748e-05,
      "loss": 0.0002,
      "step": 10120
    },
    {
      "epoch": 8.570219966159053,
      "grad_norm": 0.004023126792162657,
      "learning_rate": 2.1435420191765372e-05,
      "loss": 0.0002,
      "step": 10130
    },
    {
      "epoch": 8.578680203045685,
      "grad_norm": 0.00019336314289830625,
      "learning_rate": 2.140721940214326e-05,
      "loss": 0.0,
      "step": 10140
    },
    {
      "epoch": 8.587140439932318,
      "grad_norm": 0.0002104449231410399,
      "learning_rate": 2.137901861252115e-05,
      "loss": 0.036,
      "step": 10150
    },
    {
      "epoch": 8.59560067681895,
      "grad_norm": 0.0003919856681022793,
      "learning_rate": 2.1350817822899043e-05,
      "loss": 0.0184,
      "step": 10160
    },
    {
      "epoch": 8.604060913705585,
      "grad_norm": 0.00033939105924218893,
      "learning_rate": 2.132261703327693e-05,
      "loss": 0.0,
      "step": 10170
    },
    {
      "epoch": 8.612521150592217,
      "grad_norm": 0.04514142498373985,
      "learning_rate": 2.1294416243654825e-05,
      "loss": 0.0258,
      "step": 10180
    },
    {
      "epoch": 8.62098138747885,
      "grad_norm": 0.0025866215582937002,
      "learning_rate": 2.1266215454032713e-05,
      "loss": 0.0002,
      "step": 10190
    },
    {
      "epoch": 8.629441624365482,
      "grad_norm": 0.00027398436213843524,
      "learning_rate": 2.1238014664410605e-05,
      "loss": 0.0203,
      "step": 10200
    },
    {
      "epoch": 8.637901861252114,
      "grad_norm": 96.47274017333984,
      "learning_rate": 2.1209813874788496e-05,
      "loss": 0.0136,
      "step": 10210
    },
    {
      "epoch": 8.646362098138749,
      "grad_norm": 54.7008171081543,
      "learning_rate": 2.1181613085166384e-05,
      "loss": 0.0055,
      "step": 10220
    },
    {
      "epoch": 8.654822335025381,
      "grad_norm": 0.0011123428121209145,
      "learning_rate": 2.1153412295544275e-05,
      "loss": 0.0583,
      "step": 10230
    },
    {
      "epoch": 8.663282571912013,
      "grad_norm": 0.00046651740558445454,
      "learning_rate": 2.1125211505922167e-05,
      "loss": 0.0,
      "step": 10240
    },
    {
      "epoch": 8.671742808798646,
      "grad_norm": 0.0031069808173924685,
      "learning_rate": 2.1097010716300058e-05,
      "loss": 0.0,
      "step": 10250
    },
    {
      "epoch": 8.680203045685278,
      "grad_norm": 0.0013529517455026507,
      "learning_rate": 2.106880992667795e-05,
      "loss": 0.0048,
      "step": 10260
    },
    {
      "epoch": 8.688663282571913,
      "grad_norm": 0.0004450712585821748,
      "learning_rate": 2.1040609137055837e-05,
      "loss": 0.0,
      "step": 10270
    },
    {
      "epoch": 8.697123519458545,
      "grad_norm": 0.00045942558790557086,
      "learning_rate": 2.101240834743373e-05,
      "loss": 0.0001,
      "step": 10280
    },
    {
      "epoch": 8.705583756345177,
      "grad_norm": 0.00018253826419822872,
      "learning_rate": 2.098420755781162e-05,
      "loss": 0.0,
      "step": 10290
    },
    {
      "epoch": 8.71404399323181,
      "grad_norm": 0.0034353728406131268,
      "learning_rate": 2.0956006768189508e-05,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 8.722504230118444,
      "grad_norm": 0.0007654917426407337,
      "learning_rate": 2.09278059785674e-05,
      "loss": 0.0,
      "step": 10310
    },
    {
      "epoch": 8.730964467005077,
      "grad_norm": 0.011771977879106998,
      "learning_rate": 2.0899605188945294e-05,
      "loss": 0.0,
      "step": 10320
    },
    {
      "epoch": 8.739424703891709,
      "grad_norm": 0.0003026071353815496,
      "learning_rate": 2.0871404399323182e-05,
      "loss": 0.0023,
      "step": 10330
    },
    {
      "epoch": 8.747884940778341,
      "grad_norm": 0.00025090930284932256,
      "learning_rate": 2.0843203609701074e-05,
      "loss": 0.0,
      "step": 10340
    },
    {
      "epoch": 8.756345177664974,
      "grad_norm": 0.0005474370555020869,
      "learning_rate": 2.081500282007896e-05,
      "loss": 0.0005,
      "step": 10350
    },
    {
      "epoch": 8.764805414551608,
      "grad_norm": 0.0005581955192610621,
      "learning_rate": 2.0786802030456853e-05,
      "loss": 0.0014,
      "step": 10360
    },
    {
      "epoch": 8.77326565143824,
      "grad_norm": 0.001120754168368876,
      "learning_rate": 2.0758601240834744e-05,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 8.781725888324873,
      "grad_norm": 0.0007149911834858358,
      "learning_rate": 2.0730400451212632e-05,
      "loss": 0.0,
      "step": 10380
    },
    {
      "epoch": 8.790186125211505,
      "grad_norm": 0.00037412732490338385,
      "learning_rate": 2.0702199661590527e-05,
      "loss": 0.0149,
      "step": 10390
    },
    {
      "epoch": 8.79864636209814,
      "grad_norm": 0.12698255479335785,
      "learning_rate": 2.0673998871968418e-05,
      "loss": 0.0029,
      "step": 10400
    },
    {
      "epoch": 8.807106598984772,
      "grad_norm": 0.00022641461691819131,
      "learning_rate": 2.0645798082346306e-05,
      "loss": 0.0001,
      "step": 10410
    },
    {
      "epoch": 8.815566835871405,
      "grad_norm": 0.0007273576338775456,
      "learning_rate": 2.0617597292724198e-05,
      "loss": 0.0004,
      "step": 10420
    },
    {
      "epoch": 8.824027072758037,
      "grad_norm": 0.00014248539810068905,
      "learning_rate": 2.058939650310209e-05,
      "loss": 0.0,
      "step": 10430
    },
    {
      "epoch": 8.83248730964467,
      "grad_norm": 0.006015836726874113,
      "learning_rate": 2.0561195713479977e-05,
      "loss": 0.0001,
      "step": 10440
    },
    {
      "epoch": 8.840947546531304,
      "grad_norm": 0.0002163637982448563,
      "learning_rate": 2.0532994923857868e-05,
      "loss": 0.0,
      "step": 10450
    },
    {
      "epoch": 8.849407783417936,
      "grad_norm": 0.0009288793662562966,
      "learning_rate": 2.050479413423576e-05,
      "loss": 0.0014,
      "step": 10460
    },
    {
      "epoch": 8.857868020304569,
      "grad_norm": 0.0003894503752235323,
      "learning_rate": 2.047659334461365e-05,
      "loss": 0.0004,
      "step": 10470
    },
    {
      "epoch": 8.866328257191201,
      "grad_norm": 0.10264934599399567,
      "learning_rate": 2.0448392554991542e-05,
      "loss": 0.0,
      "step": 10480
    },
    {
      "epoch": 8.874788494077833,
      "grad_norm": 0.00022065610392019153,
      "learning_rate": 2.042019176536943e-05,
      "loss": 0.0,
      "step": 10490
    },
    {
      "epoch": 8.883248730964468,
      "grad_norm": 0.00041902961675077677,
      "learning_rate": 2.039199097574732e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 8.8917089678511,
      "grad_norm": 0.00045713272993452847,
      "learning_rate": 2.0363790186125213e-05,
      "loss": 0.0002,
      "step": 10510
    },
    {
      "epoch": 8.900169204737733,
      "grad_norm": 0.00027450095512904227,
      "learning_rate": 2.03355893965031e-05,
      "loss": 0.0001,
      "step": 10520
    },
    {
      "epoch": 8.908629441624365,
      "grad_norm": 0.0005320860655046999,
      "learning_rate": 2.0307388606880996e-05,
      "loss": 0.0,
      "step": 10530
    },
    {
      "epoch": 8.917089678510997,
      "grad_norm": 0.012407355941832066,
      "learning_rate": 2.0279187817258884e-05,
      "loss": 0.0001,
      "step": 10540
    },
    {
      "epoch": 8.925549915397632,
      "grad_norm": 0.49415209889411926,
      "learning_rate": 2.0250987027636775e-05,
      "loss": 0.0001,
      "step": 10550
    },
    {
      "epoch": 8.934010152284264,
      "grad_norm": 0.00031936957384459674,
      "learning_rate": 2.0222786238014666e-05,
      "loss": 0.001,
      "step": 10560
    },
    {
      "epoch": 8.942470389170897,
      "grad_norm": 0.0009385569719597697,
      "learning_rate": 2.0194585448392554e-05,
      "loss": 0.0,
      "step": 10570
    },
    {
      "epoch": 8.950930626057529,
      "grad_norm": 0.0003156432940158993,
      "learning_rate": 2.0166384658770446e-05,
      "loss": 0.0,
      "step": 10580
    },
    {
      "epoch": 8.959390862944163,
      "grad_norm": 0.0002983284357469529,
      "learning_rate": 2.0138183869148337e-05,
      "loss": 0.0031,
      "step": 10590
    },
    {
      "epoch": 8.967851099830796,
      "grad_norm": 0.22897422313690186,
      "learning_rate": 2.010998307952623e-05,
      "loss": 0.0001,
      "step": 10600
    },
    {
      "epoch": 8.976311336717428,
      "grad_norm": 0.0032758298330008984,
      "learning_rate": 2.008178228990412e-05,
      "loss": 0.0,
      "step": 10610
    },
    {
      "epoch": 8.98477157360406,
      "grad_norm": 0.0001483204250689596,
      "learning_rate": 2.0053581500282008e-05,
      "loss": 0.0055,
      "step": 10620
    },
    {
      "epoch": 8.993231810490693,
      "grad_norm": 0.00037014426197856665,
      "learning_rate": 2.00253807106599e-05,
      "loss": 0.0,
      "step": 10630
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9840740740740741,
      "eval_loss": 0.11537259817123413,
      "eval_runtime": 246.7865,
      "eval_samples_per_second": 21.881,
      "eval_steps_per_second": 2.735,
      "step": 10638
    },
    {
      "epoch": 9.001692047377327,
      "grad_norm": 0.0040128640830516815,
      "learning_rate": 1.999717992103779e-05,
      "loss": 0.0002,
      "step": 10640
    },
    {
      "epoch": 9.01015228426396,
      "grad_norm": 0.0004217748937662691,
      "learning_rate": 1.996897913141568e-05,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 9.018612521150592,
      "grad_norm": 0.0028842317406088114,
      "learning_rate": 1.994077834179357e-05,
      "loss": 0.0,
      "step": 10660
    },
    {
      "epoch": 9.027072758037225,
      "grad_norm": 0.0004353970871306956,
      "learning_rate": 1.9912577552171464e-05,
      "loss": 0.0,
      "step": 10670
    },
    {
      "epoch": 9.035532994923859,
      "grad_norm": 0.0013540963409468532,
      "learning_rate": 1.9884376762549352e-05,
      "loss": 0.0,
      "step": 10680
    },
    {
      "epoch": 9.043993231810491,
      "grad_norm": 0.0005250783869996667,
      "learning_rate": 1.9856175972927244e-05,
      "loss": 0.0,
      "step": 10690
    },
    {
      "epoch": 9.052453468697124,
      "grad_norm": 0.00017382546502631158,
      "learning_rate": 1.9827975183305135e-05,
      "loss": 0.0069,
      "step": 10700
    },
    {
      "epoch": 9.060913705583756,
      "grad_norm": 0.00022375761182047427,
      "learning_rate": 1.9799774393683023e-05,
      "loss": 0.0,
      "step": 10710
    },
    {
      "epoch": 9.069373942470389,
      "grad_norm": 0.00019359106954652816,
      "learning_rate": 1.9771573604060914e-05,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 9.077834179357023,
      "grad_norm": 0.0002679462486412376,
      "learning_rate": 1.9743372814438806e-05,
      "loss": 0.0,
      "step": 10730
    },
    {
      "epoch": 9.086294416243655,
      "grad_norm": 0.00014291831757873297,
      "learning_rate": 1.9715172024816697e-05,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 9.094754653130288,
      "grad_norm": 0.00020074621716048568,
      "learning_rate": 1.968697123519459e-05,
      "loss": 0.0012,
      "step": 10750
    },
    {
      "epoch": 9.10321489001692,
      "grad_norm": 0.00015139742754399776,
      "learning_rate": 1.9658770445572477e-05,
      "loss": 0.0002,
      "step": 10760
    },
    {
      "epoch": 9.111675126903553,
      "grad_norm": 0.000183643598575145,
      "learning_rate": 1.9630569655950368e-05,
      "loss": 0.0,
      "step": 10770
    },
    {
      "epoch": 9.120135363790187,
      "grad_norm": 0.0001409329561283812,
      "learning_rate": 1.960236886632826e-05,
      "loss": 0.0,
      "step": 10780
    },
    {
      "epoch": 9.12859560067682,
      "grad_norm": 0.0009228894487023354,
      "learning_rate": 1.9574168076706147e-05,
      "loss": 0.0002,
      "step": 10790
    },
    {
      "epoch": 9.137055837563452,
      "grad_norm": 0.00025474262656643987,
      "learning_rate": 1.954596728708404e-05,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 9.145516074450084,
      "grad_norm": 0.006160377524793148,
      "learning_rate": 1.951776649746193e-05,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 9.153976311336718,
      "grad_norm": 0.0010396833531558514,
      "learning_rate": 1.948956570783982e-05,
      "loss": 0.0,
      "step": 10820
    },
    {
      "epoch": 9.16243654822335,
      "grad_norm": 0.00047232734505087137,
      "learning_rate": 1.9461364918217713e-05,
      "loss": 0.0,
      "step": 10830
    },
    {
      "epoch": 9.170896785109983,
      "grad_norm": 0.0001310841616941616,
      "learning_rate": 1.94331641285956e-05,
      "loss": 0.0,
      "step": 10840
    },
    {
      "epoch": 9.179357021996616,
      "grad_norm": 0.00013461048365570605,
      "learning_rate": 1.9404963338973492e-05,
      "loss": 0.0002,
      "step": 10850
    },
    {
      "epoch": 9.187817258883248,
      "grad_norm": 43.908477783203125,
      "learning_rate": 1.9376762549351383e-05,
      "loss": 0.0166,
      "step": 10860
    },
    {
      "epoch": 9.196277495769882,
      "grad_norm": 0.00018696558254305273,
      "learning_rate": 1.934856175972927e-05,
      "loss": 0.0,
      "step": 10870
    },
    {
      "epoch": 9.204737732656515,
      "grad_norm": 0.0009358488605357707,
      "learning_rate": 1.9320360970107166e-05,
      "loss": 0.0,
      "step": 10880
    },
    {
      "epoch": 9.213197969543147,
      "grad_norm": 0.00031305020092986524,
      "learning_rate": 1.9292160180485054e-05,
      "loss": 0.0,
      "step": 10890
    },
    {
      "epoch": 9.22165820642978,
      "grad_norm": 0.00018341466784477234,
      "learning_rate": 1.9263959390862945e-05,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 9.230118443316412,
      "grad_norm": 0.0035076900385320187,
      "learning_rate": 1.9235758601240837e-05,
      "loss": 0.0,
      "step": 10910
    },
    {
      "epoch": 9.238578680203046,
      "grad_norm": 0.0002566102484706789,
      "learning_rate": 1.9207557811618725e-05,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 9.247038917089679,
      "grad_norm": 0.00034264702117070556,
      "learning_rate": 1.9179357021996616e-05,
      "loss": 0.0,
      "step": 10930
    },
    {
      "epoch": 9.255499153976311,
      "grad_norm": 0.00013095718168187886,
      "learning_rate": 1.9151156232374507e-05,
      "loss": 0.0001,
      "step": 10940
    },
    {
      "epoch": 9.263959390862944,
      "grad_norm": 0.0010019867913797498,
      "learning_rate": 1.91229554427524e-05,
      "loss": 0.0363,
      "step": 10950
    },
    {
      "epoch": 9.272419627749578,
      "grad_norm": 0.0001287703198613599,
      "learning_rate": 1.909475465313029e-05,
      "loss": 0.0,
      "step": 10960
    },
    {
      "epoch": 9.28087986463621,
      "grad_norm": 0.0001800721511244774,
      "learning_rate": 1.906655386350818e-05,
      "loss": 0.0,
      "step": 10970
    },
    {
      "epoch": 9.289340101522843,
      "grad_norm": 0.0002580199216026813,
      "learning_rate": 1.903835307388607e-05,
      "loss": 0.0,
      "step": 10980
    },
    {
      "epoch": 9.297800338409475,
      "grad_norm": 0.0015286299167200923,
      "learning_rate": 1.901015228426396e-05,
      "loss": 0.0,
      "step": 10990
    },
    {
      "epoch": 9.306260575296108,
      "grad_norm": 0.0003345400036778301,
      "learning_rate": 1.898195149464185e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 9.314720812182742,
      "grad_norm": 0.002025580732151866,
      "learning_rate": 1.895375070501974e-05,
      "loss": 0.0,
      "step": 11010
    },
    {
      "epoch": 9.323181049069374,
      "grad_norm": 0.0002285733207827434,
      "learning_rate": 1.892554991539763e-05,
      "loss": 0.0,
      "step": 11020
    },
    {
      "epoch": 9.331641285956007,
      "grad_norm": 0.00022918934701010585,
      "learning_rate": 1.8897349125775523e-05,
      "loss": 0.0,
      "step": 11030
    },
    {
      "epoch": 9.34010152284264,
      "grad_norm": 0.0001245740131707862,
      "learning_rate": 1.8869148336153414e-05,
      "loss": 0.0003,
      "step": 11040
    },
    {
      "epoch": 9.348561759729272,
      "grad_norm": 0.00014723512867931277,
      "learning_rate": 1.8840947546531305e-05,
      "loss": 0.0013,
      "step": 11050
    },
    {
      "epoch": 9.357021996615906,
      "grad_norm": 0.00016450247494503856,
      "learning_rate": 1.8812746756909193e-05,
      "loss": 0.0428,
      "step": 11060
    },
    {
      "epoch": 9.365482233502538,
      "grad_norm": 0.00019194478227291256,
      "learning_rate": 1.8784545967287085e-05,
      "loss": 0.0267,
      "step": 11070
    },
    {
      "epoch": 9.37394247038917,
      "grad_norm": 0.0016545637045055628,
      "learning_rate": 1.8756345177664976e-05,
      "loss": 0.0,
      "step": 11080
    },
    {
      "epoch": 9.382402707275803,
      "grad_norm": 0.002562417881563306,
      "learning_rate": 1.8728144388042864e-05,
      "loss": 0.0002,
      "step": 11090
    },
    {
      "epoch": 9.390862944162437,
      "grad_norm": 0.0001972365571418777,
      "learning_rate": 1.869994359842076e-05,
      "loss": 0.0002,
      "step": 11100
    },
    {
      "epoch": 9.39932318104907,
      "grad_norm": 0.004486857447773218,
      "learning_rate": 1.8671742808798647e-05,
      "loss": 0.0,
      "step": 11110
    },
    {
      "epoch": 9.407783417935702,
      "grad_norm": 0.0009828874608501792,
      "learning_rate": 1.8643542019176538e-05,
      "loss": 0.0,
      "step": 11120
    },
    {
      "epoch": 9.416243654822335,
      "grad_norm": 0.02880033478140831,
      "learning_rate": 1.861534122955443e-05,
      "loss": 0.0597,
      "step": 11130
    },
    {
      "epoch": 9.424703891708967,
      "grad_norm": 0.00020604743622243404,
      "learning_rate": 1.8587140439932317e-05,
      "loss": 0.0008,
      "step": 11140
    },
    {
      "epoch": 9.433164128595601,
      "grad_norm": 0.00016063590010162443,
      "learning_rate": 1.855893965031021e-05,
      "loss": 0.0297,
      "step": 11150
    },
    {
      "epoch": 9.441624365482234,
      "grad_norm": 0.0001560311793582514,
      "learning_rate": 1.85307388606881e-05,
      "loss": 0.0,
      "step": 11160
    },
    {
      "epoch": 9.450084602368866,
      "grad_norm": 0.00016643093840684742,
      "learning_rate": 1.850253807106599e-05,
      "loss": 0.0745,
      "step": 11170
    },
    {
      "epoch": 9.458544839255499,
      "grad_norm": 0.00017934148490894586,
      "learning_rate": 1.8474337281443883e-05,
      "loss": 0.0001,
      "step": 11180
    },
    {
      "epoch": 9.467005076142131,
      "grad_norm": 0.00014118598483037204,
      "learning_rate": 1.844613649182177e-05,
      "loss": 0.0,
      "step": 11190
    },
    {
      "epoch": 9.475465313028765,
      "grad_norm": 0.001174816396087408,
      "learning_rate": 1.8417935702199662e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 9.483925549915398,
      "grad_norm": 0.00016233154747169465,
      "learning_rate": 1.8389734912577554e-05,
      "loss": 0.0,
      "step": 11210
    },
    {
      "epoch": 9.49238578680203,
      "grad_norm": 0.0003516540746204555,
      "learning_rate": 1.836153412295544e-05,
      "loss": 0.0001,
      "step": 11220
    },
    {
      "epoch": 9.500846023688663,
      "grad_norm": 0.00015520007582381368,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0,
      "step": 11230
    },
    {
      "epoch": 9.509306260575297,
      "grad_norm": 0.00031659507658332586,
      "learning_rate": 1.8305132543711224e-05,
      "loss": 0.0,
      "step": 11240
    },
    {
      "epoch": 9.51776649746193,
      "grad_norm": 43.0629997253418,
      "learning_rate": 1.8276931754089116e-05,
      "loss": 0.0349,
      "step": 11250
    },
    {
      "epoch": 9.526226734348562,
      "grad_norm": 0.0002005415881285444,
      "learning_rate": 1.8248730964467007e-05,
      "loss": 0.0,
      "step": 11260
    },
    {
      "epoch": 9.534686971235194,
      "grad_norm": 0.00040341768180951476,
      "learning_rate": 1.8220530174844895e-05,
      "loss": 0.0,
      "step": 11270
    },
    {
      "epoch": 9.543147208121827,
      "grad_norm": 0.00018536674906499684,
      "learning_rate": 1.8192329385222786e-05,
      "loss": 0.012,
      "step": 11280
    },
    {
      "epoch": 9.551607445008461,
      "grad_norm": 0.08572995662689209,
      "learning_rate": 1.8164128595600678e-05,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 9.560067681895093,
      "grad_norm": 0.010623477399349213,
      "learning_rate": 1.8135927805978566e-05,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 9.568527918781726,
      "grad_norm": 0.0003838366537820548,
      "learning_rate": 1.810772701635646e-05,
      "loss": 0.0,
      "step": 11310
    },
    {
      "epoch": 9.576988155668358,
      "grad_norm": 0.0004832665727008134,
      "learning_rate": 1.807952622673435e-05,
      "loss": 0.004,
      "step": 11320
    },
    {
      "epoch": 9.58544839255499,
      "grad_norm": 0.00019738917762879282,
      "learning_rate": 1.805132543711224e-05,
      "loss": 0.0,
      "step": 11330
    },
    {
      "epoch": 9.593908629441625,
      "grad_norm": 0.000212654413189739,
      "learning_rate": 1.802312464749013e-05,
      "loss": 0.0,
      "step": 11340
    },
    {
      "epoch": 9.602368866328257,
      "grad_norm": 0.0002118913980666548,
      "learning_rate": 1.7994923857868022e-05,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 9.61082910321489,
      "grad_norm": 0.00030388004961423576,
      "learning_rate": 1.796672306824591e-05,
      "loss": 0.003,
      "step": 11360
    },
    {
      "epoch": 9.619289340101522,
      "grad_norm": 0.00011928171443287283,
      "learning_rate": 1.79385222786238e-05,
      "loss": 0.0,
      "step": 11370
    },
    {
      "epoch": 9.627749576988156,
      "grad_norm": 0.0001555421040393412,
      "learning_rate": 1.7910321489001693e-05,
      "loss": 0.0,
      "step": 11380
    },
    {
      "epoch": 9.636209813874789,
      "grad_norm": 0.0009595968294888735,
      "learning_rate": 1.7882120699379584e-05,
      "loss": 0.0026,
      "step": 11390
    },
    {
      "epoch": 9.644670050761421,
      "grad_norm": 0.000822699919808656,
      "learning_rate": 1.7853919909757476e-05,
      "loss": 0.0,
      "step": 11400
    },
    {
      "epoch": 9.653130287648054,
      "grad_norm": 0.00020219053840264678,
      "learning_rate": 1.7825719120135364e-05,
      "loss": 0.0,
      "step": 11410
    },
    {
      "epoch": 9.661590524534686,
      "grad_norm": 0.00019550102297216654,
      "learning_rate": 1.7797518330513255e-05,
      "loss": 0.0,
      "step": 11420
    },
    {
      "epoch": 9.67005076142132,
      "grad_norm": 0.0003723730333149433,
      "learning_rate": 1.7769317540891146e-05,
      "loss": 0.0,
      "step": 11430
    },
    {
      "epoch": 9.678510998307953,
      "grad_norm": 0.0005258393357507885,
      "learning_rate": 1.7741116751269034e-05,
      "loss": 0.0,
      "step": 11440
    },
    {
      "epoch": 9.686971235194585,
      "grad_norm": 0.000243098838836886,
      "learning_rate": 1.771291596164693e-05,
      "loss": 0.0,
      "step": 11450
    },
    {
      "epoch": 9.695431472081218,
      "grad_norm": 0.000259396736510098,
      "learning_rate": 1.7684715172024817e-05,
      "loss": 0.0317,
      "step": 11460
    },
    {
      "epoch": 9.703891708967852,
      "grad_norm": 0.0035051775630563498,
      "learning_rate": 1.765651438240271e-05,
      "loss": 0.0,
      "step": 11470
    },
    {
      "epoch": 9.712351945854484,
      "grad_norm": 0.00013035441224928945,
      "learning_rate": 1.76283135927806e-05,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 9.720812182741117,
      "grad_norm": 63.64271926879883,
      "learning_rate": 1.7600112803158488e-05,
      "loss": 0.0282,
      "step": 11490
    },
    {
      "epoch": 9.72927241962775,
      "grad_norm": 0.00028787562041543424,
      "learning_rate": 1.757191201353638e-05,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 9.737732656514382,
      "grad_norm": 0.00013682078861165792,
      "learning_rate": 1.754371122391427e-05,
      "loss": 0.0,
      "step": 11510
    },
    {
      "epoch": 9.746192893401016,
      "grad_norm": 2.455310583114624,
      "learning_rate": 1.7515510434292162e-05,
      "loss": 0.0004,
      "step": 11520
    },
    {
      "epoch": 9.754653130287648,
      "grad_norm": 0.00012862235598731786,
      "learning_rate": 1.7487309644670053e-05,
      "loss": 0.0,
      "step": 11530
    },
    {
      "epoch": 9.763113367174281,
      "grad_norm": 0.00011651409295154735,
      "learning_rate": 1.745910885504794e-05,
      "loss": 0.0002,
      "step": 11540
    },
    {
      "epoch": 9.771573604060913,
      "grad_norm": 0.0002657091536093503,
      "learning_rate": 1.7430908065425832e-05,
      "loss": 0.0,
      "step": 11550
    },
    {
      "epoch": 9.780033840947546,
      "grad_norm": 51.371089935302734,
      "learning_rate": 1.7402707275803724e-05,
      "loss": 0.0077,
      "step": 11560
    },
    {
      "epoch": 9.78849407783418,
      "grad_norm": 0.0001347402430837974,
      "learning_rate": 1.7374506486181612e-05,
      "loss": 0.0,
      "step": 11570
    },
    {
      "epoch": 9.796954314720812,
      "grad_norm": 0.0002523253788240254,
      "learning_rate": 1.7346305696559503e-05,
      "loss": 0.0,
      "step": 11580
    },
    {
      "epoch": 9.805414551607445,
      "grad_norm": 0.0011399578070268035,
      "learning_rate": 1.7318104906937398e-05,
      "loss": 0.0017,
      "step": 11590
    },
    {
      "epoch": 9.813874788494077,
      "grad_norm": 0.00014902788097970188,
      "learning_rate": 1.7289904117315286e-05,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 9.82233502538071,
      "grad_norm": 0.0008156829862855375,
      "learning_rate": 1.7261703327693177e-05,
      "loss": 0.0,
      "step": 11610
    },
    {
      "epoch": 9.830795262267344,
      "grad_norm": 0.0008530242484994233,
      "learning_rate": 1.723350253807107e-05,
      "loss": 0.0,
      "step": 11620
    },
    {
      "epoch": 9.839255499153976,
      "grad_norm": 0.008163358084857464,
      "learning_rate": 1.7205301748448957e-05,
      "loss": 0.0,
      "step": 11630
    },
    {
      "epoch": 9.847715736040609,
      "grad_norm": 0.00015459312999155372,
      "learning_rate": 1.7177100958826848e-05,
      "loss": 0.0,
      "step": 11640
    },
    {
      "epoch": 9.856175972927241,
      "grad_norm": 0.0011013166513293982,
      "learning_rate": 1.7148900169204736e-05,
      "loss": 0.0001,
      "step": 11650
    },
    {
      "epoch": 9.864636209813876,
      "grad_norm": 9.61166006163694e-05,
      "learning_rate": 1.712069937958263e-05,
      "loss": 0.0,
      "step": 11660
    },
    {
      "epoch": 9.873096446700508,
      "grad_norm": 0.00022844283375889063,
      "learning_rate": 1.7092498589960522e-05,
      "loss": 0.0,
      "step": 11670
    },
    {
      "epoch": 9.88155668358714,
      "grad_norm": 0.0003787346067838371,
      "learning_rate": 1.706429780033841e-05,
      "loss": 0.0,
      "step": 11680
    },
    {
      "epoch": 9.890016920473773,
      "grad_norm": 0.00014689828094560653,
      "learning_rate": 1.70360970107163e-05,
      "loss": 0.0,
      "step": 11690
    },
    {
      "epoch": 9.898477157360405,
      "grad_norm": 0.00017153103544842452,
      "learning_rate": 1.7007896221094193e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 9.90693739424704,
      "grad_norm": 0.0002029402821790427,
      "learning_rate": 1.697969543147208e-05,
      "loss": 0.0,
      "step": 11710
    },
    {
      "epoch": 9.915397631133672,
      "grad_norm": 0.0003572004206944257,
      "learning_rate": 1.6951494641849972e-05,
      "loss": 0.0,
      "step": 11720
    },
    {
      "epoch": 9.923857868020304,
      "grad_norm": 0.00011087588063674048,
      "learning_rate": 1.6923293852227863e-05,
      "loss": 0.0,
      "step": 11730
    },
    {
      "epoch": 9.932318104906937,
      "grad_norm": 0.003487754613161087,
      "learning_rate": 1.6895093062605755e-05,
      "loss": 0.0427,
      "step": 11740
    },
    {
      "epoch": 9.940778341793571,
      "grad_norm": 0.0002074167859973386,
      "learning_rate": 1.6866892272983646e-05,
      "loss": 0.0,
      "step": 11750
    },
    {
      "epoch": 9.949238578680204,
      "grad_norm": 0.00012663280358538032,
      "learning_rate": 1.6838691483361534e-05,
      "loss": 0.0054,
      "step": 11760
    },
    {
      "epoch": 9.957698815566836,
      "grad_norm": 0.000861071574036032,
      "learning_rate": 1.6810490693739425e-05,
      "loss": 0.0,
      "step": 11770
    },
    {
      "epoch": 9.966159052453468,
      "grad_norm": 0.0002919440739788115,
      "learning_rate": 1.6782289904117317e-05,
      "loss": 0.0,
      "step": 11780
    },
    {
      "epoch": 9.974619289340101,
      "grad_norm": 0.0011941286502406001,
      "learning_rate": 1.6754089114495205e-05,
      "loss": 0.0001,
      "step": 11790
    },
    {
      "epoch": 9.983079526226735,
      "grad_norm": 0.00019279886328149587,
      "learning_rate": 1.67258883248731e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 9.991539763113368,
      "grad_norm": 0.0022659907117486,
      "learning_rate": 1.6697687535250987e-05,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.00015966413775458932,
      "learning_rate": 1.666948674562888e-05,
      "loss": 0.0,
      "step": 11820
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9807407407407407,
      "eval_loss": 0.12179934233427048,
      "eval_runtime": 248.9343,
      "eval_samples_per_second": 21.692,
      "eval_steps_per_second": 2.712,
      "step": 11820
    }
  ],
  "logging_steps": 10,
  "max_steps": 17730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.43340365320192e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
