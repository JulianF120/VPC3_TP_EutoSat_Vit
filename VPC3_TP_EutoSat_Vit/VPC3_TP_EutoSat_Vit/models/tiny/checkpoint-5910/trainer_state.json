{
  "best_global_step": 4728,
  "best_metric": 0.9811111111111112,
  "best_model_checkpoint": "VPC3_TP_EutoSat_Vit/models/tiny/checkpoint-4728",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5910,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008460236886632826,
      "grad_norm": 14.466089248657227,
      "learning_rate": 4.9974619289340105e-05,
      "loss": 1.9739,
      "step": 10
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 20.900371551513672,
      "learning_rate": 4.994641849971799e-05,
      "loss": 1.1346,
      "step": 20
    },
    {
      "epoch": 0.025380710659898477,
      "grad_norm": 14.140461921691895,
      "learning_rate": 4.991821771009588e-05,
      "loss": 0.6714,
      "step": 30
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 14.910873413085938,
      "learning_rate": 4.9890016920473776e-05,
      "loss": 0.4596,
      "step": 40
    },
    {
      "epoch": 0.04230118443316413,
      "grad_norm": 35.95499801635742,
      "learning_rate": 4.986181613085167e-05,
      "loss": 0.4352,
      "step": 50
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 10.581116676330566,
      "learning_rate": 4.983361534122956e-05,
      "loss": 0.319,
      "step": 60
    },
    {
      "epoch": 0.05922165820642978,
      "grad_norm": 11.34449291229248,
      "learning_rate": 4.9805414551607446e-05,
      "loss": 0.2842,
      "step": 70
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 7.4420576095581055,
      "learning_rate": 4.9777213761985334e-05,
      "loss": 0.2789,
      "step": 80
    },
    {
      "epoch": 0.07614213197969544,
      "grad_norm": 21.182126998901367,
      "learning_rate": 4.974901297236323e-05,
      "loss": 0.2123,
      "step": 90
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 11.74959659576416,
      "learning_rate": 4.972081218274112e-05,
      "loss": 0.2109,
      "step": 100
    },
    {
      "epoch": 0.09306260575296109,
      "grad_norm": 24.90926170349121,
      "learning_rate": 4.969261139311901e-05,
      "loss": 0.1604,
      "step": 110
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.184607982635498,
      "learning_rate": 4.96644106034969e-05,
      "loss": 0.3748,
      "step": 120
    },
    {
      "epoch": 0.10998307952622674,
      "grad_norm": 12.008848190307617,
      "learning_rate": 4.963620981387479e-05,
      "loss": 0.1721,
      "step": 130
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 10.822035789489746,
      "learning_rate": 4.960800902425268e-05,
      "loss": 0.1741,
      "step": 140
    },
    {
      "epoch": 0.12690355329949238,
      "grad_norm": 3.1626784801483154,
      "learning_rate": 4.957980823463057e-05,
      "loss": 0.1298,
      "step": 150
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 6.791316032409668,
      "learning_rate": 4.9551607445008465e-05,
      "loss": 0.1967,
      "step": 160
    },
    {
      "epoch": 0.14382402707275804,
      "grad_norm": 4.2050347328186035,
      "learning_rate": 4.952340665538635e-05,
      "loss": 0.1122,
      "step": 170
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 11.0927095413208,
      "learning_rate": 4.949520586576424e-05,
      "loss": 0.1621,
      "step": 180
    },
    {
      "epoch": 0.16074450084602368,
      "grad_norm": 25.3814697265625,
      "learning_rate": 4.9467005076142136e-05,
      "loss": 0.374,
      "step": 190
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 2.0944905281066895,
      "learning_rate": 4.9438804286520024e-05,
      "loss": 0.1641,
      "step": 200
    },
    {
      "epoch": 0.17766497461928935,
      "grad_norm": 14.078400611877441,
      "learning_rate": 4.941060349689792e-05,
      "loss": 0.2302,
      "step": 210
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 13.332756996154785,
      "learning_rate": 4.9382402707275806e-05,
      "loss": 0.2209,
      "step": 220
    },
    {
      "epoch": 0.19458544839255498,
      "grad_norm": 1.499985694885254,
      "learning_rate": 4.9354201917653694e-05,
      "loss": 0.3221,
      "step": 230
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 1.4748750925064087,
      "learning_rate": 4.932600112803158e-05,
      "loss": 0.1699,
      "step": 240
    },
    {
      "epoch": 0.21150592216582065,
      "grad_norm": 28.762161254882812,
      "learning_rate": 4.929780033840948e-05,
      "loss": 0.1859,
      "step": 250
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 21.489336013793945,
      "learning_rate": 4.926959954878737e-05,
      "loss": 0.0832,
      "step": 260
    },
    {
      "epoch": 0.22842639593908629,
      "grad_norm": 1.1055177450180054,
      "learning_rate": 4.924139875916526e-05,
      "loss": 0.1289,
      "step": 270
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 22.156885147094727,
      "learning_rate": 4.921319796954315e-05,
      "loss": 0.1383,
      "step": 280
    },
    {
      "epoch": 0.24534686971235195,
      "grad_norm": 13.688899040222168,
      "learning_rate": 4.9184997179921036e-05,
      "loss": 0.1253,
      "step": 290
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 2.1891090869903564,
      "learning_rate": 4.915679639029893e-05,
      "loss": 0.1817,
      "step": 300
    },
    {
      "epoch": 0.2622673434856176,
      "grad_norm": 29.75678253173828,
      "learning_rate": 4.912859560067682e-05,
      "loss": 0.1101,
      "step": 310
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 19.95785140991211,
      "learning_rate": 4.910039481105471e-05,
      "loss": 0.1785,
      "step": 320
    },
    {
      "epoch": 0.27918781725888325,
      "grad_norm": 4.945294380187988,
      "learning_rate": 4.907219402143261e-05,
      "loss": 0.2358,
      "step": 330
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 26.60957145690918,
      "learning_rate": 4.904399323181049e-05,
      "loss": 0.1177,
      "step": 340
    },
    {
      "epoch": 0.2961082910321489,
      "grad_norm": 44.35723876953125,
      "learning_rate": 4.9015792442188384e-05,
      "loss": 0.1052,
      "step": 350
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.2594661712646484,
      "learning_rate": 4.898759165256627e-05,
      "loss": 0.1825,
      "step": 360
    },
    {
      "epoch": 0.3130287648054145,
      "grad_norm": 1.4883270263671875,
      "learning_rate": 4.8959390862944167e-05,
      "loss": 0.1231,
      "step": 370
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 17.421049118041992,
      "learning_rate": 4.8931190073322055e-05,
      "loss": 0.1644,
      "step": 380
    },
    {
      "epoch": 0.3299492385786802,
      "grad_norm": 16.858835220336914,
      "learning_rate": 4.890298928369995e-05,
      "loss": 0.1424,
      "step": 390
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 14.830533027648926,
      "learning_rate": 4.887478849407784e-05,
      "loss": 0.1687,
      "step": 400
    },
    {
      "epoch": 0.34686971235194586,
      "grad_norm": 2.4005239009857178,
      "learning_rate": 4.8846587704455725e-05,
      "loss": 0.1471,
      "step": 410
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.5430868268013,
      "learning_rate": 4.881838691483362e-05,
      "loss": 0.1136,
      "step": 420
    },
    {
      "epoch": 0.3637901861252115,
      "grad_norm": 0.6713274717330933,
      "learning_rate": 4.879018612521151e-05,
      "loss": 0.3007,
      "step": 430
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.46859073638916,
      "learning_rate": 4.87619853355894e-05,
      "loss": 0.0564,
      "step": 440
    },
    {
      "epoch": 0.38071065989847713,
      "grad_norm": 0.944525957107544,
      "learning_rate": 4.8733784545967284e-05,
      "loss": 0.1091,
      "step": 450
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.24216057360172272,
      "learning_rate": 4.870558375634518e-05,
      "loss": 0.0261,
      "step": 460
    },
    {
      "epoch": 0.3976311336717428,
      "grad_norm": 17.511394500732422,
      "learning_rate": 4.867738296672307e-05,
      "loss": 0.1677,
      "step": 470
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 13.479783058166504,
      "learning_rate": 4.864918217710096e-05,
      "loss": 0.2508,
      "step": 480
    },
    {
      "epoch": 0.41455160744500846,
      "grad_norm": 19.93234634399414,
      "learning_rate": 4.8620981387478856e-05,
      "loss": 0.0422,
      "step": 490
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 4.957183837890625,
      "learning_rate": 4.8592780597856744e-05,
      "loss": 0.0953,
      "step": 500
    },
    {
      "epoch": 0.43147208121827413,
      "grad_norm": 2.8080811500549316,
      "learning_rate": 4.856457980823463e-05,
      "loss": 0.0667,
      "step": 510
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 26.37185287475586,
      "learning_rate": 4.853637901861252e-05,
      "loss": 0.2009,
      "step": 520
    },
    {
      "epoch": 0.44839255499153974,
      "grad_norm": 1.484768033027649,
      "learning_rate": 4.8508178228990415e-05,
      "loss": 0.038,
      "step": 530
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 20.85687255859375,
      "learning_rate": 4.847997743936831e-05,
      "loss": 0.1368,
      "step": 540
    },
    {
      "epoch": 0.4653130287648054,
      "grad_norm": 2.726987361907959,
      "learning_rate": 4.84517766497462e-05,
      "loss": 0.1399,
      "step": 550
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 15.755430221557617,
      "learning_rate": 4.8423575860124085e-05,
      "loss": 0.0465,
      "step": 560
    },
    {
      "epoch": 0.48223350253807107,
      "grad_norm": 28.094520568847656,
      "learning_rate": 4.839537507050197e-05,
      "loss": 0.199,
      "step": 570
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 0.03665974736213684,
      "learning_rate": 4.836717428087987e-05,
      "loss": 0.1026,
      "step": 580
    },
    {
      "epoch": 0.49915397631133673,
      "grad_norm": 0.3312017023563385,
      "learning_rate": 4.8338973491257756e-05,
      "loss": 0.204,
      "step": 590
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 0.2591623365879059,
      "learning_rate": 4.831077270163565e-05,
      "loss": 0.1357,
      "step": 600
    },
    {
      "epoch": 0.5160744500846024,
      "grad_norm": 23.12666130065918,
      "learning_rate": 4.828257191201354e-05,
      "loss": 0.114,
      "step": 610
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.457749366760254,
      "learning_rate": 4.825437112239143e-05,
      "loss": 0.0955,
      "step": 620
    },
    {
      "epoch": 0.5329949238578681,
      "grad_norm": 19.274295806884766,
      "learning_rate": 4.822617033276932e-05,
      "loss": 0.318,
      "step": 630
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 22.72943115234375,
      "learning_rate": 4.819796954314721e-05,
      "loss": 0.146,
      "step": 640
    },
    {
      "epoch": 0.5499153976311336,
      "grad_norm": 6.262524604797363,
      "learning_rate": 4.8169768753525104e-05,
      "loss": 0.1691,
      "step": 650
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 20.436107635498047,
      "learning_rate": 4.814156796390299e-05,
      "loss": 0.1831,
      "step": 660
    },
    {
      "epoch": 0.5668358714043993,
      "grad_norm": 13.359298706054688,
      "learning_rate": 4.811336717428088e-05,
      "loss": 0.0537,
      "step": 670
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 7.079187393188477,
      "learning_rate": 4.8085166384658775e-05,
      "loss": 0.0709,
      "step": 680
    },
    {
      "epoch": 0.583756345177665,
      "grad_norm": 0.7319515347480774,
      "learning_rate": 4.805696559503666e-05,
      "loss": 0.1109,
      "step": 690
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 23.68626594543457,
      "learning_rate": 4.802876480541456e-05,
      "loss": 0.0784,
      "step": 700
    },
    {
      "epoch": 0.6006768189509306,
      "grad_norm": 0.6795468926429749,
      "learning_rate": 4.8000564015792445e-05,
      "loss": 0.1495,
      "step": 710
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 0.15101884305477142,
      "learning_rate": 4.7972363226170333e-05,
      "loss": 0.1307,
      "step": 720
    },
    {
      "epoch": 0.6175972927241963,
      "grad_norm": 10.494664192199707,
      "learning_rate": 4.794416243654822e-05,
      "loss": 0.1626,
      "step": 730
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 18.630586624145508,
      "learning_rate": 4.7915961646926116e-05,
      "loss": 0.1586,
      "step": 740
    },
    {
      "epoch": 0.6345177664974619,
      "grad_norm": 0.2620302140712738,
      "learning_rate": 4.788776085730401e-05,
      "loss": 0.0755,
      "step": 750
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 0.09258006513118744,
      "learning_rate": 4.78595600676819e-05,
      "loss": 0.1077,
      "step": 760
    },
    {
      "epoch": 0.6514382402707276,
      "grad_norm": 0.4374638497829437,
      "learning_rate": 4.783135927805979e-05,
      "loss": 0.1392,
      "step": 770
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.67353755235672,
      "learning_rate": 4.7803158488437675e-05,
      "loss": 0.0857,
      "step": 780
    },
    {
      "epoch": 0.6683587140439933,
      "grad_norm": 19.41292381286621,
      "learning_rate": 4.777495769881557e-05,
      "loss": 0.1199,
      "step": 790
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.23480162024497986,
      "learning_rate": 4.774675690919346e-05,
      "loss": 0.0371,
      "step": 800
    },
    {
      "epoch": 0.6852791878172588,
      "grad_norm": 0.12986932694911957,
      "learning_rate": 4.771855611957135e-05,
      "loss": 0.2893,
      "step": 810
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 1.1319631338119507,
      "learning_rate": 4.769035532994924e-05,
      "loss": 0.0735,
      "step": 820
    },
    {
      "epoch": 0.7021996615905245,
      "grad_norm": 9.579446792602539,
      "learning_rate": 4.766215454032713e-05,
      "loss": 0.1398,
      "step": 830
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 33.17691421508789,
      "learning_rate": 4.763395375070502e-05,
      "loss": 0.1564,
      "step": 840
    },
    {
      "epoch": 0.7191201353637902,
      "grad_norm": 7.179660797119141,
      "learning_rate": 4.760575296108291e-05,
      "loss": 0.1506,
      "step": 850
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 4.116767883300781,
      "learning_rate": 4.7577552171460806e-05,
      "loss": 0.0688,
      "step": 860
    },
    {
      "epoch": 0.7360406091370558,
      "grad_norm": 14.570455551147461,
      "learning_rate": 4.7549351381838694e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 0.619854748249054,
      "learning_rate": 4.752115059221658e-05,
      "loss": 0.1513,
      "step": 880
    },
    {
      "epoch": 0.7529610829103215,
      "grad_norm": 5.441271781921387,
      "learning_rate": 4.7492949802594476e-05,
      "loss": 0.261,
      "step": 890
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 2.6095757484436035,
      "learning_rate": 4.7464749012972364e-05,
      "loss": 0.0479,
      "step": 900
    },
    {
      "epoch": 0.7698815566835872,
      "grad_norm": 18.807838439941406,
      "learning_rate": 4.743654822335026e-05,
      "loss": 0.0865,
      "step": 910
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 19.832582473754883,
      "learning_rate": 4.740834743372815e-05,
      "loss": 0.2682,
      "step": 920
    },
    {
      "epoch": 0.7868020304568528,
      "grad_norm": 23.313390731811523,
      "learning_rate": 4.7380146644106035e-05,
      "loss": 0.1621,
      "step": 930
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 2.7553422451019287,
      "learning_rate": 4.735194585448392e-05,
      "loss": 0.1222,
      "step": 940
    },
    {
      "epoch": 0.8037225042301185,
      "grad_norm": 0.5432969331741333,
      "learning_rate": 4.732374506486182e-05,
      "loss": 0.083,
      "step": 950
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 11.276805877685547,
      "learning_rate": 4.729554427523971e-05,
      "loss": 0.0629,
      "step": 960
    },
    {
      "epoch": 0.8206429780033841,
      "grad_norm": 5.896979331970215,
      "learning_rate": 4.72673434856176e-05,
      "loss": 0.1201,
      "step": 970
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 16.9703426361084,
      "learning_rate": 4.7239142695995495e-05,
      "loss": 0.121,
      "step": 980
    },
    {
      "epoch": 0.8375634517766497,
      "grad_norm": 0.12442143261432648,
      "learning_rate": 4.7210941906373376e-05,
      "loss": 0.1755,
      "step": 990
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 0.058043692260980606,
      "learning_rate": 4.718274111675127e-05,
      "loss": 0.1251,
      "step": 1000
    },
    {
      "epoch": 0.8544839255499154,
      "grad_norm": 42.14734649658203,
      "learning_rate": 4.715454032712916e-05,
      "loss": 0.1367,
      "step": 1010
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 26.698923110961914,
      "learning_rate": 4.7126339537507054e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.871404399323181,
      "grad_norm": 3.701037645339966,
      "learning_rate": 4.709813874788495e-05,
      "loss": 0.2048,
      "step": 1030
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 12.624013900756836,
      "learning_rate": 4.706993795826283e-05,
      "loss": 0.1073,
      "step": 1040
    },
    {
      "epoch": 0.8883248730964467,
      "grad_norm": 30.081945419311523,
      "learning_rate": 4.7041737168640724e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 24.828798294067383,
      "learning_rate": 4.701353637901861e-05,
      "loss": 0.087,
      "step": 1060
    },
    {
      "epoch": 0.9052453468697124,
      "grad_norm": 27.589454650878906,
      "learning_rate": 4.698533558939651e-05,
      "loss": 0.0654,
      "step": 1070
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.207147598266602,
      "learning_rate": 4.6957134799774395e-05,
      "loss": 0.0868,
      "step": 1080
    },
    {
      "epoch": 0.922165820642978,
      "grad_norm": 1.1621407270431519,
      "learning_rate": 4.692893401015229e-05,
      "loss": 0.0359,
      "step": 1090
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 42.396610260009766,
      "learning_rate": 4.690073322053018e-05,
      "loss": 0.1143,
      "step": 1100
    },
    {
      "epoch": 0.9390862944162437,
      "grad_norm": 21.23570442199707,
      "learning_rate": 4.6872532430908066e-05,
      "loss": 0.1539,
      "step": 1110
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.07133467495441437,
      "learning_rate": 4.684433164128596e-05,
      "loss": 0.0776,
      "step": 1120
    },
    {
      "epoch": 0.9560067681895094,
      "grad_norm": 1.5074037313461304,
      "learning_rate": 4.681613085166385e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 18.812101364135742,
      "learning_rate": 4.678793006204174e-05,
      "loss": 0.0749,
      "step": 1140
    },
    {
      "epoch": 0.9729272419627749,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.675972927241963e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.9813874788494078,
      "grad_norm": 2.271929979324341,
      "learning_rate": 4.673152848279752e-05,
      "loss": 0.1919,
      "step": 1160
    },
    {
      "epoch": 0.9898477157360406,
      "grad_norm": 5.057013034820557,
      "learning_rate": 4.6703327693175414e-05,
      "loss": 0.0771,
      "step": 1170
    },
    {
      "epoch": 0.9983079526226735,
      "grad_norm": 10.19404411315918,
      "learning_rate": 4.66751269035533e-05,
      "loss": 0.0594,
      "step": 1180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9690740740740741,
      "eval_loss": 0.11386065185070038,
      "eval_runtime": 246.4452,
      "eval_samples_per_second": 21.912,
      "eval_steps_per_second": 2.739,
      "step": 1182
    },
    {
      "epoch": 1.0067681895093064,
      "grad_norm": 0.0524885393679142,
      "learning_rate": 4.6646926113931197e-05,
      "loss": 0.1154,
      "step": 1190
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 0.2056097388267517,
      "learning_rate": 4.6618725324309085e-05,
      "loss": 0.0667,
      "step": 1200
    },
    {
      "epoch": 1.023688663282572,
      "grad_norm": 0.31934717297554016,
      "learning_rate": 4.659052453468697e-05,
      "loss": 0.0517,
      "step": 1210
    },
    {
      "epoch": 1.0321489001692048,
      "grad_norm": 0.44508466124534607,
      "learning_rate": 4.656232374506486e-05,
      "loss": 0.0806,
      "step": 1220
    },
    {
      "epoch": 1.0406091370558375,
      "grad_norm": 17.873205184936523,
      "learning_rate": 4.6534122955442755e-05,
      "loss": 0.1168,
      "step": 1230
    },
    {
      "epoch": 1.0490693739424704,
      "grad_norm": 0.1031579002737999,
      "learning_rate": 4.650592216582065e-05,
      "loss": 0.0885,
      "step": 1240
    },
    {
      "epoch": 1.0575296108291032,
      "grad_norm": 1.859145998954773,
      "learning_rate": 4.647772137619854e-05,
      "loss": 0.0546,
      "step": 1250
    },
    {
      "epoch": 1.0659898477157361,
      "grad_norm": 2.6971371173858643,
      "learning_rate": 4.6449520586576426e-05,
      "loss": 0.0586,
      "step": 1260
    },
    {
      "epoch": 1.0744500846023688,
      "grad_norm": 3.4226748943328857,
      "learning_rate": 4.6421319796954314e-05,
      "loss": 0.1291,
      "step": 1270
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.06498179584741592,
      "learning_rate": 4.639311900733221e-05,
      "loss": 0.0912,
      "step": 1280
    },
    {
      "epoch": 1.0913705583756346,
      "grad_norm": 2.8320469856262207,
      "learning_rate": 4.6364918217710097e-05,
      "loss": 0.0783,
      "step": 1290
    },
    {
      "epoch": 1.0998307952622675,
      "grad_norm": 0.09660017490386963,
      "learning_rate": 4.633671742808799e-05,
      "loss": 0.0907,
      "step": 1300
    },
    {
      "epoch": 1.1082910321489001,
      "grad_norm": 0.13180534541606903,
      "learning_rate": 4.630851663846588e-05,
      "loss": 0.0413,
      "step": 1310
    },
    {
      "epoch": 1.116751269035533,
      "grad_norm": 0.16015172004699707,
      "learning_rate": 4.628031584884377e-05,
      "loss": 0.0407,
      "step": 1320
    },
    {
      "epoch": 1.125211505922166,
      "grad_norm": 9.34089469909668,
      "learning_rate": 4.625211505922166e-05,
      "loss": 0.1045,
      "step": 1330
    },
    {
      "epoch": 1.1336717428087986,
      "grad_norm": 24.051116943359375,
      "learning_rate": 4.622391426959955e-05,
      "loss": 0.0467,
      "step": 1340
    },
    {
      "epoch": 1.1421319796954315,
      "grad_norm": 9.480792045593262,
      "learning_rate": 4.6195713479977445e-05,
      "loss": 0.1429,
      "step": 1350
    },
    {
      "epoch": 1.1505922165820643,
      "grad_norm": 0.2971787750720978,
      "learning_rate": 4.616751269035533e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 1.1590524534686972,
      "grad_norm": 1.4138188362121582,
      "learning_rate": 4.613931190073322e-05,
      "loss": 0.0279,
      "step": 1370
    },
    {
      "epoch": 1.16751269035533,
      "grad_norm": 26.05870246887207,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0514,
      "step": 1380
    },
    {
      "epoch": 1.1759729272419628,
      "grad_norm": 0.014784063212573528,
      "learning_rate": 4.6082910321489e-05,
      "loss": 0.0145,
      "step": 1390
    },
    {
      "epoch": 1.1844331641285957,
      "grad_norm": 3.2919983863830566,
      "learning_rate": 4.60547095318669e-05,
      "loss": 0.0022,
      "step": 1400
    },
    {
      "epoch": 1.1928934010152283,
      "grad_norm": 20.8558349609375,
      "learning_rate": 4.6026508742244786e-05,
      "loss": 0.1509,
      "step": 1410
    },
    {
      "epoch": 1.2013536379018612,
      "grad_norm": 1.2578448057174683,
      "learning_rate": 4.5998307952622674e-05,
      "loss": 0.0209,
      "step": 1420
    },
    {
      "epoch": 1.2098138747884941,
      "grad_norm": 20.923458099365234,
      "learning_rate": 4.597010716300056e-05,
      "loss": 0.0547,
      "step": 1430
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 0.0193844735622406,
      "learning_rate": 4.594190637337846e-05,
      "loss": 0.178,
      "step": 1440
    },
    {
      "epoch": 1.2267343485617597,
      "grad_norm": 0.34279999136924744,
      "learning_rate": 4.591370558375635e-05,
      "loss": 0.0055,
      "step": 1450
    },
    {
      "epoch": 1.2351945854483926,
      "grad_norm": 0.713297963142395,
      "learning_rate": 4.588550479413424e-05,
      "loss": 0.0185,
      "step": 1460
    },
    {
      "epoch": 1.2436548223350254,
      "grad_norm": 0.06155781447887421,
      "learning_rate": 4.585730400451213e-05,
      "loss": 0.0267,
      "step": 1470
    },
    {
      "epoch": 1.252115059221658,
      "grad_norm": 15.050272941589355,
      "learning_rate": 4.5829103214890015e-05,
      "loss": 0.1215,
      "step": 1480
    },
    {
      "epoch": 1.260575296108291,
      "grad_norm": 2.018648386001587,
      "learning_rate": 4.580090242526791e-05,
      "loss": 0.0928,
      "step": 1490
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 26.905744552612305,
      "learning_rate": 4.57727016356458e-05,
      "loss": 0.0494,
      "step": 1500
    },
    {
      "epoch": 1.2774957698815568,
      "grad_norm": 0.08350187540054321,
      "learning_rate": 4.574450084602369e-05,
      "loss": 0.0409,
      "step": 1510
    },
    {
      "epoch": 1.2859560067681894,
      "grad_norm": 0.1177479475736618,
      "learning_rate": 4.571630005640159e-05,
      "loss": 0.1218,
      "step": 1520
    },
    {
      "epoch": 1.2944162436548223,
      "grad_norm": 14.32288932800293,
      "learning_rate": 4.568809926677947e-05,
      "loss": 0.1414,
      "step": 1530
    },
    {
      "epoch": 1.3028764805414552,
      "grad_norm": 0.8191991448402405,
      "learning_rate": 4.5659898477157363e-05,
      "loss": 0.0487,
      "step": 1540
    },
    {
      "epoch": 1.3113367174280879,
      "grad_norm": 1.2151057720184326,
      "learning_rate": 4.563169768753525e-05,
      "loss": 0.0101,
      "step": 1550
    },
    {
      "epoch": 1.3197969543147208,
      "grad_norm": 22.795188903808594,
      "learning_rate": 4.5603496897913146e-05,
      "loss": 0.056,
      "step": 1560
    },
    {
      "epoch": 1.3282571912013537,
      "grad_norm": 24.174396514892578,
      "learning_rate": 4.5575296108291034e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 1.3367174280879865,
      "grad_norm": 20.76497459411621,
      "learning_rate": 4.554709531866892e-05,
      "loss": 0.2546,
      "step": 1580
    },
    {
      "epoch": 1.3451776649746192,
      "grad_norm": 44.310550689697266,
      "learning_rate": 4.551889452904681e-05,
      "loss": 0.1427,
      "step": 1590
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 0.04374610632658005,
      "learning_rate": 4.5490693739424705e-05,
      "loss": 0.1959,
      "step": 1600
    },
    {
      "epoch": 1.362098138747885,
      "grad_norm": 6.750633716583252,
      "learning_rate": 4.54624929498026e-05,
      "loss": 0.0342,
      "step": 1610
    },
    {
      "epoch": 1.3705583756345177,
      "grad_norm": 0.28728750348091125,
      "learning_rate": 4.543429216018049e-05,
      "loss": 0.0333,
      "step": 1620
    },
    {
      "epoch": 1.3790186125211505,
      "grad_norm": 1.095624566078186,
      "learning_rate": 4.540609137055838e-05,
      "loss": 0.055,
      "step": 1630
    },
    {
      "epoch": 1.3874788494077834,
      "grad_norm": 0.1793481707572937,
      "learning_rate": 4.5377890580936263e-05,
      "loss": 0.0789,
      "step": 1640
    },
    {
      "epoch": 1.3959390862944163,
      "grad_norm": 0.10460668057203293,
      "learning_rate": 4.534968979131416e-05,
      "loss": 0.1204,
      "step": 1650
    },
    {
      "epoch": 1.404399323181049,
      "grad_norm": 0.17484290897846222,
      "learning_rate": 4.5321489001692046e-05,
      "loss": 0.0569,
      "step": 1660
    },
    {
      "epoch": 1.4128595600676819,
      "grad_norm": 2.5536487102508545,
      "learning_rate": 4.529328821206994e-05,
      "loss": 0.0966,
      "step": 1670
    },
    {
      "epoch": 1.4213197969543148,
      "grad_norm": 0.033308885991573334,
      "learning_rate": 4.5265087422447836e-05,
      "loss": 0.0455,
      "step": 1680
    },
    {
      "epoch": 1.4297800338409474,
      "grad_norm": 0.03772977367043495,
      "learning_rate": 4.523688663282572e-05,
      "loss": 0.1548,
      "step": 1690
    },
    {
      "epoch": 1.4382402707275803,
      "grad_norm": 0.09216587990522385,
      "learning_rate": 4.520868584320361e-05,
      "loss": 0.05,
      "step": 1700
    },
    {
      "epoch": 1.4467005076142132,
      "grad_norm": 0.03644145280122757,
      "learning_rate": 4.51804850535815e-05,
      "loss": 0.0294,
      "step": 1710
    },
    {
      "epoch": 1.455160744500846,
      "grad_norm": 0.005973259452730417,
      "learning_rate": 4.5152284263959394e-05,
      "loss": 0.0558,
      "step": 1720
    },
    {
      "epoch": 1.463620981387479,
      "grad_norm": 0.24085456132888794,
      "learning_rate": 4.512408347433728e-05,
      "loss": 0.055,
      "step": 1730
    },
    {
      "epoch": 1.4720812182741116,
      "grad_norm": 0.006745295133441687,
      "learning_rate": 4.509588268471518e-05,
      "loss": 0.0501,
      "step": 1740
    },
    {
      "epoch": 1.4805414551607445,
      "grad_norm": 0.49678128957748413,
      "learning_rate": 4.5067681895093065e-05,
      "loss": 0.0194,
      "step": 1750
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.2952556610107422,
      "learning_rate": 4.503948110547095e-05,
      "loss": 0.0893,
      "step": 1760
    },
    {
      "epoch": 1.49746192893401,
      "grad_norm": 1.9802641868591309,
      "learning_rate": 4.501128031584885e-05,
      "loss": 0.0114,
      "step": 1770
    },
    {
      "epoch": 1.505922165820643,
      "grad_norm": 0.016201358288526535,
      "learning_rate": 4.4983079526226736e-05,
      "loss": 0.1306,
      "step": 1780
    },
    {
      "epoch": 1.5143824027072759,
      "grad_norm": 0.2131015509366989,
      "learning_rate": 4.495487873660463e-05,
      "loss": 0.0282,
      "step": 1790
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 0.1275821179151535,
      "learning_rate": 4.492667794698252e-05,
      "loss": 0.0732,
      "step": 1800
    },
    {
      "epoch": 1.5313028764805414,
      "grad_norm": 32.563453674316406,
      "learning_rate": 4.4898477157360406e-05,
      "loss": 0.0461,
      "step": 1810
    },
    {
      "epoch": 1.5397631133671743,
      "grad_norm": 0.01262142974883318,
      "learning_rate": 4.48702763677383e-05,
      "loss": 0.0382,
      "step": 1820
    },
    {
      "epoch": 1.548223350253807,
      "grad_norm": 3.734633207321167,
      "learning_rate": 4.484207557811619e-05,
      "loss": 0.0036,
      "step": 1830
    },
    {
      "epoch": 1.5566835871404399,
      "grad_norm": 0.026379531249403954,
      "learning_rate": 4.4813874788494084e-05,
      "loss": 0.0045,
      "step": 1840
    },
    {
      "epoch": 1.5651438240270727,
      "grad_norm": 0.006282446440309286,
      "learning_rate": 4.478567399887197e-05,
      "loss": 0.0065,
      "step": 1850
    },
    {
      "epoch": 1.5736040609137056,
      "grad_norm": 0.3327971398830414,
      "learning_rate": 4.475747320924986e-05,
      "loss": 0.0198,
      "step": 1860
    },
    {
      "epoch": 1.5820642978003385,
      "grad_norm": 0.11799824237823486,
      "learning_rate": 4.472927241962775e-05,
      "loss": 0.1285,
      "step": 1870
    },
    {
      "epoch": 1.5905245346869712,
      "grad_norm": 0.005150949582457542,
      "learning_rate": 4.470107163000564e-05,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 1.598984771573604,
      "grad_norm": 20.945222854614258,
      "learning_rate": 4.467287084038354e-05,
      "loss": 0.0764,
      "step": 1890
    },
    {
      "epoch": 1.6074450084602367,
      "grad_norm": 14.346229553222656,
      "learning_rate": 4.4644670050761425e-05,
      "loss": 0.052,
      "step": 1900
    },
    {
      "epoch": 1.6159052453468696,
      "grad_norm": 0.4961164593696594,
      "learning_rate": 4.461646926113931e-05,
      "loss": 0.0594,
      "step": 1910
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 0.05455700308084488,
      "learning_rate": 4.45882684715172e-05,
      "loss": 0.1213,
      "step": 1920
    },
    {
      "epoch": 1.6328257191201354,
      "grad_norm": 35.61746597290039,
      "learning_rate": 4.4560067681895096e-05,
      "loss": 0.1965,
      "step": 1930
    },
    {
      "epoch": 1.6412859560067683,
      "grad_norm": 0.14853937923908234,
      "learning_rate": 4.4531866892272984e-05,
      "loss": 0.071,
      "step": 1940
    },
    {
      "epoch": 1.649746192893401,
      "grad_norm": 29.400121688842773,
      "learning_rate": 4.450366610265088e-05,
      "loss": 0.1181,
      "step": 1950
    },
    {
      "epoch": 1.6582064297800339,
      "grad_norm": 26.16289520263672,
      "learning_rate": 4.4475465313028766e-05,
      "loss": 0.0451,
      "step": 1960
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 16.397777557373047,
      "learning_rate": 4.4447264523406654e-05,
      "loss": 0.0818,
      "step": 1970
    },
    {
      "epoch": 1.6751269035532994,
      "grad_norm": 0.09849713742733002,
      "learning_rate": 4.441906373378455e-05,
      "loss": 0.0955,
      "step": 1980
    },
    {
      "epoch": 1.6835871404399323,
      "grad_norm": 7.682143211364746,
      "learning_rate": 4.439086294416244e-05,
      "loss": 0.1323,
      "step": 1990
    },
    {
      "epoch": 1.6920473773265652,
      "grad_norm": 0.6320121884346008,
      "learning_rate": 4.436266215454033e-05,
      "loss": 0.1091,
      "step": 2000
    },
    {
      "epoch": 1.700507614213198,
      "grad_norm": 0.12847696244716644,
      "learning_rate": 4.433446136491822e-05,
      "loss": 0.0281,
      "step": 2010
    },
    {
      "epoch": 1.708967851099831,
      "grad_norm": 15.028797149658203,
      "learning_rate": 4.430626057529611e-05,
      "loss": 0.0261,
      "step": 2020
    },
    {
      "epoch": 1.7174280879864636,
      "grad_norm": 0.01604713872075081,
      "learning_rate": 4.4278059785674e-05,
      "loss": 0.0013,
      "step": 2030
    },
    {
      "epoch": 1.7258883248730963,
      "grad_norm": 17.731983184814453,
      "learning_rate": 4.424985899605189e-05,
      "loss": 0.0434,
      "step": 2040
    },
    {
      "epoch": 1.7343485617597292,
      "grad_norm": 0.12152490019798279,
      "learning_rate": 4.4221658206429785e-05,
      "loss": 0.0606,
      "step": 2050
    },
    {
      "epoch": 1.742808798646362,
      "grad_norm": 0.003514975542202592,
      "learning_rate": 4.419345741680767e-05,
      "loss": 0.0556,
      "step": 2060
    },
    {
      "epoch": 1.751269035532995,
      "grad_norm": 2.6348941326141357,
      "learning_rate": 4.416525662718556e-05,
      "loss": 0.1486,
      "step": 2070
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 21.712257385253906,
      "learning_rate": 4.413705583756345e-05,
      "loss": 0.1412,
      "step": 2080
    },
    {
      "epoch": 1.7681895093062607,
      "grad_norm": 0.0020400604698807,
      "learning_rate": 4.4108855047941344e-05,
      "loss": 0.069,
      "step": 2090
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 13.40526294708252,
      "learning_rate": 4.408065425831924e-05,
      "loss": 0.0379,
      "step": 2100
    },
    {
      "epoch": 1.785109983079526,
      "grad_norm": 0.07841428369283676,
      "learning_rate": 4.4052453468697127e-05,
      "loss": 0.0338,
      "step": 2110
    },
    {
      "epoch": 1.793570219966159,
      "grad_norm": 21.989072799682617,
      "learning_rate": 4.4024252679075015e-05,
      "loss": 0.0383,
      "step": 2120
    },
    {
      "epoch": 1.8020304568527918,
      "grad_norm": 8.322708129882812,
      "learning_rate": 4.39960518894529e-05,
      "loss": 0.1942,
      "step": 2130
    },
    {
      "epoch": 1.8104906937394247,
      "grad_norm": 0.019643452018499374,
      "learning_rate": 4.39678510998308e-05,
      "loss": 0.0736,
      "step": 2140
    },
    {
      "epoch": 1.8189509306260576,
      "grad_norm": 37.64115524291992,
      "learning_rate": 4.3939650310208685e-05,
      "loss": 0.1089,
      "step": 2150
    },
    {
      "epoch": 1.8274111675126905,
      "grad_norm": 12.482965469360352,
      "learning_rate": 4.391144952058658e-05,
      "loss": 0.1011,
      "step": 2160
    },
    {
      "epoch": 1.8358714043993232,
      "grad_norm": 0.03910377621650696,
      "learning_rate": 4.3883248730964475e-05,
      "loss": 0.093,
      "step": 2170
    },
    {
      "epoch": 1.844331641285956,
      "grad_norm": 1.2610856294631958,
      "learning_rate": 4.3855047941342356e-05,
      "loss": 0.0736,
      "step": 2180
    },
    {
      "epoch": 1.8527918781725887,
      "grad_norm": 15.85295295715332,
      "learning_rate": 4.382684715172025e-05,
      "loss": 0.1832,
      "step": 2190
    },
    {
      "epoch": 1.8612521150592216,
      "grad_norm": 0.31547269225120544,
      "learning_rate": 4.379864636209814e-05,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 1.8697123519458545,
      "grad_norm": 0.3832317292690277,
      "learning_rate": 4.377044557247603e-05,
      "loss": 0.0473,
      "step": 2210
    },
    {
      "epoch": 1.8781725888324874,
      "grad_norm": 0.0396120585501194,
      "learning_rate": 4.374224478285392e-05,
      "loss": 0.0631,
      "step": 2220
    },
    {
      "epoch": 1.8866328257191203,
      "grad_norm": 0.14707453548908234,
      "learning_rate": 4.371404399323181e-05,
      "loss": 0.0929,
      "step": 2230
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 0.01668008789420128,
      "learning_rate": 4.3685843203609704e-05,
      "loss": 0.0821,
      "step": 2240
    },
    {
      "epoch": 1.9035532994923858,
      "grad_norm": 0.11122526228427887,
      "learning_rate": 4.365764241398759e-05,
      "loss": 0.1329,
      "step": 2250
    },
    {
      "epoch": 1.9120135363790185,
      "grad_norm": 35.64632797241211,
      "learning_rate": 4.362944162436549e-05,
      "loss": 0.0724,
      "step": 2260
    },
    {
      "epoch": 1.9204737732656514,
      "grad_norm": 0.12160845100879669,
      "learning_rate": 4.3601240834743375e-05,
      "loss": 0.0693,
      "step": 2270
    },
    {
      "epoch": 1.9289340101522843,
      "grad_norm": 0.010136724449694157,
      "learning_rate": 4.357304004512127e-05,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 1.9373942470389172,
      "grad_norm": 0.020088551566004753,
      "learning_rate": 4.354483925549915e-05,
      "loss": 0.0402,
      "step": 2290
    },
    {
      "epoch": 1.94585448392555,
      "grad_norm": 0.01234954409301281,
      "learning_rate": 4.3516638465877045e-05,
      "loss": 0.0293,
      "step": 2300
    },
    {
      "epoch": 1.9543147208121827,
      "grad_norm": 1.4190717935562134,
      "learning_rate": 4.348843767625494e-05,
      "loss": 0.1906,
      "step": 2310
    },
    {
      "epoch": 1.9627749576988156,
      "grad_norm": 0.010624142363667488,
      "learning_rate": 4.346023688663283e-05,
      "loss": 0.0392,
      "step": 2320
    },
    {
      "epoch": 1.9712351945854483,
      "grad_norm": 22.869890213012695,
      "learning_rate": 4.343203609701072e-05,
      "loss": 0.0536,
      "step": 2330
    },
    {
      "epoch": 1.9796954314720812,
      "grad_norm": 0.01851845346391201,
      "learning_rate": 4.3403835307388604e-05,
      "loss": 0.0733,
      "step": 2340
    },
    {
      "epoch": 1.988155668358714,
      "grad_norm": 25.321544647216797,
      "learning_rate": 4.33756345177665e-05,
      "loss": 0.0828,
      "step": 2350
    },
    {
      "epoch": 1.996615905245347,
      "grad_norm": 0.037506792694330215,
      "learning_rate": 4.334743372814439e-05,
      "loss": 0.046,
      "step": 2360
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9779629629629629,
      "eval_loss": 0.09348412603139877,
      "eval_runtime": 246.6577,
      "eval_samples_per_second": 21.893,
      "eval_steps_per_second": 2.737,
      "step": 2364
    },
    {
      "epoch": 2.00507614213198,
      "grad_norm": 0.7050085067749023,
      "learning_rate": 4.331923293852228e-05,
      "loss": 0.0019,
      "step": 2370
    },
    {
      "epoch": 2.0135363790186127,
      "grad_norm": 0.004118071403354406,
      "learning_rate": 4.3291032148900176e-05,
      "loss": 0.0297,
      "step": 2380
    },
    {
      "epoch": 2.021996615905245,
      "grad_norm": 36.45760726928711,
      "learning_rate": 4.3262831359278064e-05,
      "loss": 0.0852,
      "step": 2390
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 0.002832560334354639,
      "learning_rate": 4.323463056965595e-05,
      "loss": 0.0159,
      "step": 2400
    },
    {
      "epoch": 2.038917089678511,
      "grad_norm": 0.015435759909451008,
      "learning_rate": 4.320642978003384e-05,
      "loss": 0.0082,
      "step": 2410
    },
    {
      "epoch": 2.047377326565144,
      "grad_norm": 0.06332072615623474,
      "learning_rate": 4.3178228990411735e-05,
      "loss": 0.0096,
      "step": 2420
    },
    {
      "epoch": 2.0558375634517767,
      "grad_norm": 23.606990814208984,
      "learning_rate": 4.315002820078962e-05,
      "loss": 0.096,
      "step": 2430
    },
    {
      "epoch": 2.0642978003384096,
      "grad_norm": 16.45185089111328,
      "learning_rate": 4.312182741116752e-05,
      "loss": 0.0696,
      "step": 2440
    },
    {
      "epoch": 2.0727580372250425,
      "grad_norm": 23.556838989257812,
      "learning_rate": 4.3093626621545405e-05,
      "loss": 0.0283,
      "step": 2450
    },
    {
      "epoch": 2.081218274111675,
      "grad_norm": 0.35000672936439514,
      "learning_rate": 4.3065425831923293e-05,
      "loss": 0.0263,
      "step": 2460
    },
    {
      "epoch": 2.089678510998308,
      "grad_norm": 1.4101324081420898,
      "learning_rate": 4.303722504230119e-05,
      "loss": 0.0688,
      "step": 2470
    },
    {
      "epoch": 2.0981387478849407,
      "grad_norm": 17.108341217041016,
      "learning_rate": 4.3009024252679076e-05,
      "loss": 0.1071,
      "step": 2480
    },
    {
      "epoch": 2.1065989847715736,
      "grad_norm": 4.765998363494873,
      "learning_rate": 4.298082346305697e-05,
      "loss": 0.0024,
      "step": 2490
    },
    {
      "epoch": 2.1150592216582065,
      "grad_norm": 0.18713925778865814,
      "learning_rate": 4.295262267343486e-05,
      "loss": 0.0195,
      "step": 2500
    },
    {
      "epoch": 2.1235194585448394,
      "grad_norm": 1.4044023752212524,
      "learning_rate": 4.292442188381275e-05,
      "loss": 0.0151,
      "step": 2510
    },
    {
      "epoch": 2.1319796954314723,
      "grad_norm": 0.022990819066762924,
      "learning_rate": 4.289622109419064e-05,
      "loss": 0.0006,
      "step": 2520
    },
    {
      "epoch": 2.1404399323181047,
      "grad_norm": 0.4567020535469055,
      "learning_rate": 4.286802030456853e-05,
      "loss": 0.0272,
      "step": 2530
    },
    {
      "epoch": 2.1489001692047376,
      "grad_norm": 17.143157958984375,
      "learning_rate": 4.2839819514946424e-05,
      "loss": 0.0573,
      "step": 2540
    },
    {
      "epoch": 2.1573604060913705,
      "grad_norm": 0.5564812421798706,
      "learning_rate": 4.281161872532431e-05,
      "loss": 0.0137,
      "step": 2550
    },
    {
      "epoch": 2.1658206429780034,
      "grad_norm": 1.2734674215316772,
      "learning_rate": 4.27834179357022e-05,
      "loss": 0.0527,
      "step": 2560
    },
    {
      "epoch": 2.1742808798646363,
      "grad_norm": 0.05679820850491524,
      "learning_rate": 4.275521714608009e-05,
      "loss": 0.01,
      "step": 2570
    },
    {
      "epoch": 2.182741116751269,
      "grad_norm": 0.5252026915550232,
      "learning_rate": 4.272701635645798e-05,
      "loss": 0.0544,
      "step": 2580
    },
    {
      "epoch": 2.191201353637902,
      "grad_norm": 25.15257453918457,
      "learning_rate": 4.269881556683588e-05,
      "loss": 0.0168,
      "step": 2590
    },
    {
      "epoch": 2.199661590524535,
      "grad_norm": 20.0202579498291,
      "learning_rate": 4.2670614777213766e-05,
      "loss": 0.0555,
      "step": 2600
    },
    {
      "epoch": 2.2081218274111674,
      "grad_norm": 0.0031947263050824404,
      "learning_rate": 4.2642413987591654e-05,
      "loss": 0.005,
      "step": 2610
    },
    {
      "epoch": 2.2165820642978002,
      "grad_norm": 0.019850878044962883,
      "learning_rate": 4.261421319796954e-05,
      "loss": 0.0004,
      "step": 2620
    },
    {
      "epoch": 2.225042301184433,
      "grad_norm": 3.6412107944488525,
      "learning_rate": 4.2586012408347436e-05,
      "loss": 0.0964,
      "step": 2630
    },
    {
      "epoch": 2.233502538071066,
      "grad_norm": 1.5771880149841309,
      "learning_rate": 4.2557811618725324e-05,
      "loss": 0.0219,
      "step": 2640
    },
    {
      "epoch": 2.241962774957699,
      "grad_norm": 0.00178819231223315,
      "learning_rate": 4.252961082910322e-05,
      "loss": 0.058,
      "step": 2650
    },
    {
      "epoch": 2.250423011844332,
      "grad_norm": 17.10619354248047,
      "learning_rate": 4.250141003948111e-05,
      "loss": 0.114,
      "step": 2660
    },
    {
      "epoch": 2.2588832487309647,
      "grad_norm": 0.012720372527837753,
      "learning_rate": 4.2473209249858995e-05,
      "loss": 0.0003,
      "step": 2670
    },
    {
      "epoch": 2.267343485617597,
      "grad_norm": 0.007427964825183153,
      "learning_rate": 4.244500846023689e-05,
      "loss": 0.0313,
      "step": 2680
    },
    {
      "epoch": 2.27580372250423,
      "grad_norm": 0.01936277747154236,
      "learning_rate": 4.241680767061478e-05,
      "loss": 0.0297,
      "step": 2690
    },
    {
      "epoch": 2.284263959390863,
      "grad_norm": 9.420300483703613,
      "learning_rate": 4.238860688099267e-05,
      "loss": 0.0189,
      "step": 2700
    },
    {
      "epoch": 2.292724196277496,
      "grad_norm": 0.9173603653907776,
      "learning_rate": 4.236040609137056e-05,
      "loss": 0.0659,
      "step": 2710
    },
    {
      "epoch": 2.3011844331641287,
      "grad_norm": 0.0064922175370156765,
      "learning_rate": 4.233220530174845e-05,
      "loss": 0.0816,
      "step": 2720
    },
    {
      "epoch": 2.3096446700507616,
      "grad_norm": 2.5201611518859863,
      "learning_rate": 4.230400451212634e-05,
      "loss": 0.0159,
      "step": 2730
    },
    {
      "epoch": 2.3181049069373945,
      "grad_norm": 0.01033511571586132,
      "learning_rate": 4.227580372250423e-05,
      "loss": 0.0022,
      "step": 2740
    },
    {
      "epoch": 2.326565143824027,
      "grad_norm": 0.3796350657939911,
      "learning_rate": 4.2247602932882126e-05,
      "loss": 0.0836,
      "step": 2750
    },
    {
      "epoch": 2.33502538071066,
      "grad_norm": 12.385169982910156,
      "learning_rate": 4.2219402143260014e-05,
      "loss": 0.0703,
      "step": 2760
    },
    {
      "epoch": 2.3434856175972927,
      "grad_norm": 0.017592186108231544,
      "learning_rate": 4.21912013536379e-05,
      "loss": 0.1087,
      "step": 2770
    },
    {
      "epoch": 2.3519458544839256,
      "grad_norm": 2.3975565433502197,
      "learning_rate": 4.216300056401579e-05,
      "loss": 0.0045,
      "step": 2780
    },
    {
      "epoch": 2.3604060913705585,
      "grad_norm": 0.017607372254133224,
      "learning_rate": 4.2134799774393684e-05,
      "loss": 0.0671,
      "step": 2790
    },
    {
      "epoch": 2.3688663282571913,
      "grad_norm": 3.5394468307495117,
      "learning_rate": 4.210659898477158e-05,
      "loss": 0.0218,
      "step": 2800
    },
    {
      "epoch": 2.3773265651438242,
      "grad_norm": 0.16227824985980988,
      "learning_rate": 4.207839819514947e-05,
      "loss": 0.0023,
      "step": 2810
    },
    {
      "epoch": 2.3857868020304567,
      "grad_norm": 2.4429545402526855,
      "learning_rate": 4.2050197405527355e-05,
      "loss": 0.0355,
      "step": 2820
    },
    {
      "epoch": 2.3942470389170896,
      "grad_norm": 0.008337924256920815,
      "learning_rate": 4.202199661590524e-05,
      "loss": 0.1437,
      "step": 2830
    },
    {
      "epoch": 2.4027072758037225,
      "grad_norm": 24.83634376525879,
      "learning_rate": 4.199379582628314e-05,
      "loss": 0.0725,
      "step": 2840
    },
    {
      "epoch": 2.4111675126903553,
      "grad_norm": 0.06213049590587616,
      "learning_rate": 4.1965595036661026e-05,
      "loss": 0.0635,
      "step": 2850
    },
    {
      "epoch": 2.4196277495769882,
      "grad_norm": 0.005098477005958557,
      "learning_rate": 4.193739424703892e-05,
      "loss": 0.0236,
      "step": 2860
    },
    {
      "epoch": 2.428087986463621,
      "grad_norm": 0.012588235549628735,
      "learning_rate": 4.1909193457416815e-05,
      "loss": 0.0025,
      "step": 2870
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 17.291196823120117,
      "learning_rate": 4.1880992667794696e-05,
      "loss": 0.0647,
      "step": 2880
    },
    {
      "epoch": 2.4450084602368864,
      "grad_norm": 0.05634631961584091,
      "learning_rate": 4.185279187817259e-05,
      "loss": 0.0087,
      "step": 2890
    },
    {
      "epoch": 2.4534686971235193,
      "grad_norm": 0.00411198940128088,
      "learning_rate": 4.182459108855048e-05,
      "loss": 0.0491,
      "step": 2900
    },
    {
      "epoch": 2.4619289340101522,
      "grad_norm": 0.02043735422194004,
      "learning_rate": 4.1796390298928374e-05,
      "loss": 0.0304,
      "step": 2910
    },
    {
      "epoch": 2.470389170896785,
      "grad_norm": 0.20278824865818024,
      "learning_rate": 4.176818950930626e-05,
      "loss": 0.0616,
      "step": 2920
    },
    {
      "epoch": 2.478849407783418,
      "grad_norm": 0.005257409065961838,
      "learning_rate": 4.1739988719684157e-05,
      "loss": 0.074,
      "step": 2930
    },
    {
      "epoch": 2.487309644670051,
      "grad_norm": 0.013093408197164536,
      "learning_rate": 4.1711787930062045e-05,
      "loss": 0.0489,
      "step": 2940
    },
    {
      "epoch": 2.495769881556684,
      "grad_norm": 15.578856468200684,
      "learning_rate": 4.168358714043993e-05,
      "loss": 0.0064,
      "step": 2950
    },
    {
      "epoch": 2.504230118443316,
      "grad_norm": 0.6917970776557922,
      "learning_rate": 4.165538635081783e-05,
      "loss": 0.0027,
      "step": 2960
    },
    {
      "epoch": 2.512690355329949,
      "grad_norm": 3.800091028213501,
      "learning_rate": 4.1627185561195715e-05,
      "loss": 0.0687,
      "step": 2970
    },
    {
      "epoch": 2.521150592216582,
      "grad_norm": 14.703471183776855,
      "learning_rate": 4.159898477157361e-05,
      "loss": 0.0388,
      "step": 2980
    },
    {
      "epoch": 2.529610829103215,
      "grad_norm": 0.030179444700479507,
      "learning_rate": 4.157078398195149e-05,
      "loss": 0.0036,
      "step": 2990
    },
    {
      "epoch": 2.5380710659898478,
      "grad_norm": 0.00749274343252182,
      "learning_rate": 4.1542583192329386e-05,
      "loss": 0.0162,
      "step": 3000
    },
    {
      "epoch": 2.5465313028764807,
      "grad_norm": 5.890507698059082,
      "learning_rate": 4.151438240270728e-05,
      "loss": 0.0182,
      "step": 3010
    },
    {
      "epoch": 2.5549915397631136,
      "grad_norm": 1.79206120967865,
      "learning_rate": 4.148618161308517e-05,
      "loss": 0.0032,
      "step": 3020
    },
    {
      "epoch": 2.563451776649746,
      "grad_norm": 0.002368614310398698,
      "learning_rate": 4.145798082346306e-05,
      "loss": 0.051,
      "step": 3030
    },
    {
      "epoch": 2.571912013536379,
      "grad_norm": 0.387143075466156,
      "learning_rate": 4.142978003384095e-05,
      "loss": 0.086,
      "step": 3040
    },
    {
      "epoch": 2.5803722504230118,
      "grad_norm": 0.14291664958000183,
      "learning_rate": 4.140157924421884e-05,
      "loss": 0.0548,
      "step": 3050
    },
    {
      "epoch": 2.5888324873096447,
      "grad_norm": 0.004535431042313576,
      "learning_rate": 4.137337845459673e-05,
      "loss": 0.029,
      "step": 3060
    },
    {
      "epoch": 2.5972927241962775,
      "grad_norm": 0.10469698160886765,
      "learning_rate": 4.134517766497462e-05,
      "loss": 0.0057,
      "step": 3070
    },
    {
      "epoch": 2.6057529610829104,
      "grad_norm": 0.3293409049510956,
      "learning_rate": 4.131697687535252e-05,
      "loss": 0.0774,
      "step": 3080
    },
    {
      "epoch": 2.6142131979695433,
      "grad_norm": 32.15681076049805,
      "learning_rate": 4.1288776085730405e-05,
      "loss": 0.0603,
      "step": 3090
    },
    {
      "epoch": 2.6226734348561758,
      "grad_norm": 0.0024791238829493523,
      "learning_rate": 4.126057529610829e-05,
      "loss": 0.0064,
      "step": 3100
    },
    {
      "epoch": 2.6311336717428087,
      "grad_norm": 0.0034042412880808115,
      "learning_rate": 4.123237450648618e-05,
      "loss": 0.0128,
      "step": 3110
    },
    {
      "epoch": 2.6395939086294415,
      "grad_norm": 0.0038752921391278505,
      "learning_rate": 4.1204173716864075e-05,
      "loss": 0.0358,
      "step": 3120
    },
    {
      "epoch": 2.6480541455160744,
      "grad_norm": 0.008329003117978573,
      "learning_rate": 4.117597292724196e-05,
      "loss": 0.0334,
      "step": 3130
    },
    {
      "epoch": 2.6565143824027073,
      "grad_norm": 31.37432289123535,
      "learning_rate": 4.114777213761986e-05,
      "loss": 0.2025,
      "step": 3140
    },
    {
      "epoch": 2.66497461928934,
      "grad_norm": 0.0014850286534056067,
      "learning_rate": 4.1119571347997746e-05,
      "loss": 0.0929,
      "step": 3150
    },
    {
      "epoch": 2.673434856175973,
      "grad_norm": 4.7359771728515625,
      "learning_rate": 4.1091370558375634e-05,
      "loss": 0.0943,
      "step": 3160
    },
    {
      "epoch": 2.6818950930626055,
      "grad_norm": 0.014216204173862934,
      "learning_rate": 4.106316976875353e-05,
      "loss": 0.0145,
      "step": 3170
    },
    {
      "epoch": 2.6903553299492384,
      "grad_norm": 2.0783638954162598,
      "learning_rate": 4.103496897913142e-05,
      "loss": 0.0228,
      "step": 3180
    },
    {
      "epoch": 2.6988155668358713,
      "grad_norm": 3.2795324325561523,
      "learning_rate": 4.100676818950931e-05,
      "loss": 0.0169,
      "step": 3190
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 0.0433700792491436,
      "learning_rate": 4.09785673998872e-05,
      "loss": 0.0612,
      "step": 3200
    },
    {
      "epoch": 2.715736040609137,
      "grad_norm": 32.12123489379883,
      "learning_rate": 4.095036661026509e-05,
      "loss": 0.0217,
      "step": 3210
    },
    {
      "epoch": 2.72419627749577,
      "grad_norm": 0.8155362010002136,
      "learning_rate": 4.092216582064298e-05,
      "loss": 0.0118,
      "step": 3220
    },
    {
      "epoch": 2.732656514382403,
      "grad_norm": 0.2179349660873413,
      "learning_rate": 4.089396503102087e-05,
      "loss": 0.0145,
      "step": 3230
    },
    {
      "epoch": 2.7411167512690353,
      "grad_norm": 1.4932093620300293,
      "learning_rate": 4.0865764241398765e-05,
      "loss": 0.0233,
      "step": 3240
    },
    {
      "epoch": 2.749576988155668,
      "grad_norm": 0.00364291830919683,
      "learning_rate": 4.083756345177665e-05,
      "loss": 0.1643,
      "step": 3250
    },
    {
      "epoch": 2.758037225042301,
      "grad_norm": 0.09596369415521622,
      "learning_rate": 4.080936266215454e-05,
      "loss": 0.0446,
      "step": 3260
    },
    {
      "epoch": 2.766497461928934,
      "grad_norm": 0.9563506245613098,
      "learning_rate": 4.078116187253243e-05,
      "loss": 0.0277,
      "step": 3270
    },
    {
      "epoch": 2.774957698815567,
      "grad_norm": 1.0228968858718872,
      "learning_rate": 4.0752961082910323e-05,
      "loss": 0.0641,
      "step": 3280
    },
    {
      "epoch": 2.7834179357021998,
      "grad_norm": 0.7322272062301636,
      "learning_rate": 4.072476029328822e-05,
      "loss": 0.0704,
      "step": 3290
    },
    {
      "epoch": 2.7918781725888326,
      "grad_norm": 0.010357234627008438,
      "learning_rate": 4.0696559503666106e-05,
      "loss": 0.0566,
      "step": 3300
    },
    {
      "epoch": 2.800338409475465,
      "grad_norm": 2.28533935546875,
      "learning_rate": 4.0668358714043994e-05,
      "loss": 0.0015,
      "step": 3310
    },
    {
      "epoch": 2.808798646362098,
      "grad_norm": 71.36479187011719,
      "learning_rate": 4.064015792442188e-05,
      "loss": 0.0601,
      "step": 3320
    },
    {
      "epoch": 2.817258883248731,
      "grad_norm": 18.460063934326172,
      "learning_rate": 4.061195713479978e-05,
      "loss": 0.0596,
      "step": 3330
    },
    {
      "epoch": 2.8257191201353637,
      "grad_norm": 2.5516769886016846,
      "learning_rate": 4.0583756345177665e-05,
      "loss": 0.1339,
      "step": 3340
    },
    {
      "epoch": 2.8341793570219966,
      "grad_norm": 20.99701690673828,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0503,
      "step": 3350
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 0.01821170188486576,
      "learning_rate": 4.052735476593345e-05,
      "loss": 0.0102,
      "step": 3360
    },
    {
      "epoch": 2.8510998307952624,
      "grad_norm": 29.11432647705078,
      "learning_rate": 4.0499153976311335e-05,
      "loss": 0.1441,
      "step": 3370
    },
    {
      "epoch": 2.859560067681895,
      "grad_norm": 1.1221740245819092,
      "learning_rate": 4.047095318668923e-05,
      "loss": 0.022,
      "step": 3380
    },
    {
      "epoch": 2.868020304568528,
      "grad_norm": 0.015179646201431751,
      "learning_rate": 4.044275239706712e-05,
      "loss": 0.0715,
      "step": 3390
    },
    {
      "epoch": 2.8764805414551606,
      "grad_norm": 0.0020357100293040276,
      "learning_rate": 4.041455160744501e-05,
      "loss": 0.1299,
      "step": 3400
    },
    {
      "epoch": 2.8849407783417935,
      "grad_norm": 27.842060089111328,
      "learning_rate": 4.03863508178229e-05,
      "loss": 0.0664,
      "step": 3410
    },
    {
      "epoch": 2.8934010152284264,
      "grad_norm": 30.183269500732422,
      "learning_rate": 4.035815002820079e-05,
      "loss": 0.1413,
      "step": 3420
    },
    {
      "epoch": 2.9018612521150593,
      "grad_norm": 1.3792476654052734,
      "learning_rate": 4.0329949238578684e-05,
      "loss": 0.1381,
      "step": 3430
    },
    {
      "epoch": 2.910321489001692,
      "grad_norm": 0.004442022647708654,
      "learning_rate": 4.030174844895657e-05,
      "loss": 0.0171,
      "step": 3440
    },
    {
      "epoch": 2.9187817258883246,
      "grad_norm": 0.0026549394242465496,
      "learning_rate": 4.0273547659334466e-05,
      "loss": 0.0504,
      "step": 3450
    },
    {
      "epoch": 2.927241962774958,
      "grad_norm": 0.006903315894305706,
      "learning_rate": 4.0245346869712354e-05,
      "loss": 0.0293,
      "step": 3460
    },
    {
      "epoch": 2.9357021996615904,
      "grad_norm": 0.5951646566390991,
      "learning_rate": 4.021714608009024e-05,
      "loss": 0.0402,
      "step": 3470
    },
    {
      "epoch": 2.9441624365482233,
      "grad_norm": 0.0016850599786266685,
      "learning_rate": 4.018894529046813e-05,
      "loss": 0.0009,
      "step": 3480
    },
    {
      "epoch": 2.952622673434856,
      "grad_norm": 0.008935854770243168,
      "learning_rate": 4.0160744500846025e-05,
      "loss": 0.0011,
      "step": 3490
    },
    {
      "epoch": 2.961082910321489,
      "grad_norm": 0.0024079226423054934,
      "learning_rate": 4.013254371122392e-05,
      "loss": 0.0292,
      "step": 3500
    },
    {
      "epoch": 2.969543147208122,
      "grad_norm": 0.02782033011317253,
      "learning_rate": 4.010434292160181e-05,
      "loss": 0.1153,
      "step": 3510
    },
    {
      "epoch": 2.9780033840947544,
      "grad_norm": 0.02952849119901657,
      "learning_rate": 4.00761421319797e-05,
      "loss": 0.0547,
      "step": 3520
    },
    {
      "epoch": 2.9864636209813877,
      "grad_norm": 0.009455189108848572,
      "learning_rate": 4.0047941342357584e-05,
      "loss": 0.0483,
      "step": 3530
    },
    {
      "epoch": 2.99492385786802,
      "grad_norm": 10.323859214782715,
      "learning_rate": 4.001974055273548e-05,
      "loss": 0.0318,
      "step": 3540
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9790740740740741,
      "eval_loss": 0.10689126700162888,
      "eval_runtime": 244.4295,
      "eval_samples_per_second": 22.092,
      "eval_steps_per_second": 2.762,
      "step": 3546
    },
    {
      "epoch": 3.003384094754653,
      "grad_norm": 0.01834588684141636,
      "learning_rate": 3.9991539763113366e-05,
      "loss": 0.0424,
      "step": 3550
    },
    {
      "epoch": 3.011844331641286,
      "grad_norm": 0.010960851795971394,
      "learning_rate": 3.996333897349126e-05,
      "loss": 0.0003,
      "step": 3560
    },
    {
      "epoch": 3.020304568527919,
      "grad_norm": 0.24798567593097687,
      "learning_rate": 3.9935138183869156e-05,
      "loss": 0.0685,
      "step": 3570
    },
    {
      "epoch": 3.0287648054145517,
      "grad_norm": 0.0093618743121624,
      "learning_rate": 3.9906937394247044e-05,
      "loss": 0.0099,
      "step": 3580
    },
    {
      "epoch": 3.0372250423011846,
      "grad_norm": 9.537440299987793,
      "learning_rate": 3.987873660462493e-05,
      "loss": 0.069,
      "step": 3590
    },
    {
      "epoch": 3.045685279187817,
      "grad_norm": 5.259807109832764,
      "learning_rate": 3.985053581500282e-05,
      "loss": 0.0032,
      "step": 3600
    },
    {
      "epoch": 3.05414551607445,
      "grad_norm": 0.045542605221271515,
      "learning_rate": 3.9822335025380714e-05,
      "loss": 0.0332,
      "step": 3610
    },
    {
      "epoch": 3.062605752961083,
      "grad_norm": 31.600664138793945,
      "learning_rate": 3.97941342357586e-05,
      "loss": 0.1117,
      "step": 3620
    },
    {
      "epoch": 3.0710659898477157,
      "grad_norm": 0.3796718418598175,
      "learning_rate": 3.97659334461365e-05,
      "loss": 0.0045,
      "step": 3630
    },
    {
      "epoch": 3.0795262267343486,
      "grad_norm": 39.48462677001953,
      "learning_rate": 3.9737732656514385e-05,
      "loss": 0.0387,
      "step": 3640
    },
    {
      "epoch": 3.0879864636209815,
      "grad_norm": 0.02776162512600422,
      "learning_rate": 3.970953186689227e-05,
      "loss": 0.0462,
      "step": 3650
    },
    {
      "epoch": 3.0964467005076144,
      "grad_norm": 0.002200811170041561,
      "learning_rate": 3.968133107727017e-05,
      "loss": 0.0019,
      "step": 3660
    },
    {
      "epoch": 3.104906937394247,
      "grad_norm": 0.02475917525589466,
      "learning_rate": 3.9653130287648056e-05,
      "loss": 0.0297,
      "step": 3670
    },
    {
      "epoch": 3.1133671742808797,
      "grad_norm": 0.3228223919868469,
      "learning_rate": 3.962492949802595e-05,
      "loss": 0.0216,
      "step": 3680
    },
    {
      "epoch": 3.1218274111675126,
      "grad_norm": 0.007218979764729738,
      "learning_rate": 3.959672870840384e-05,
      "loss": 0.0551,
      "step": 3690
    },
    {
      "epoch": 3.1302876480541455,
      "grad_norm": 0.0344734825193882,
      "learning_rate": 3.9568527918781726e-05,
      "loss": 0.0286,
      "step": 3700
    },
    {
      "epoch": 3.1387478849407784,
      "grad_norm": 40.20549774169922,
      "learning_rate": 3.954032712915962e-05,
      "loss": 0.0426,
      "step": 3710
    },
    {
      "epoch": 3.1472081218274113,
      "grad_norm": 0.024796420708298683,
      "learning_rate": 3.951212633953751e-05,
      "loss": 0.0226,
      "step": 3720
    },
    {
      "epoch": 3.155668358714044,
      "grad_norm": 0.0016937133623287082,
      "learning_rate": 3.9483925549915404e-05,
      "loss": 0.0002,
      "step": 3730
    },
    {
      "epoch": 3.164128595600677,
      "grad_norm": 0.13282886147499084,
      "learning_rate": 3.945572476029329e-05,
      "loss": 0.0055,
      "step": 3740
    },
    {
      "epoch": 3.1725888324873095,
      "grad_norm": 0.001172096817754209,
      "learning_rate": 3.942752397067118e-05,
      "loss": 0.0923,
      "step": 3750
    },
    {
      "epoch": 3.1810490693739424,
      "grad_norm": 0.009804598987102509,
      "learning_rate": 3.939932318104907e-05,
      "loss": 0.0198,
      "step": 3760
    },
    {
      "epoch": 3.1895093062605753,
      "grad_norm": 0.028245095163583755,
      "learning_rate": 3.937112239142696e-05,
      "loss": 0.0061,
      "step": 3770
    },
    {
      "epoch": 3.197969543147208,
      "grad_norm": 0.06877922266721725,
      "learning_rate": 3.934292160180485e-05,
      "loss": 0.021,
      "step": 3780
    },
    {
      "epoch": 3.206429780033841,
      "grad_norm": 0.036648377776145935,
      "learning_rate": 3.9314720812182745e-05,
      "loss": 0.0543,
      "step": 3790
    },
    {
      "epoch": 3.214890016920474,
      "grad_norm": 5.26721715927124,
      "learning_rate": 3.928652002256063e-05,
      "loss": 0.0599,
      "step": 3800
    },
    {
      "epoch": 3.223350253807107,
      "grad_norm": 0.014083649031817913,
      "learning_rate": 3.925831923293852e-05,
      "loss": 0.0006,
      "step": 3810
    },
    {
      "epoch": 3.2318104906937393,
      "grad_norm": 0.0029833659064024687,
      "learning_rate": 3.9230118443316416e-05,
      "loss": 0.0447,
      "step": 3820
    },
    {
      "epoch": 3.240270727580372,
      "grad_norm": 0.026557322591543198,
      "learning_rate": 3.9201917653694304e-05,
      "loss": 0.0045,
      "step": 3830
    },
    {
      "epoch": 3.248730964467005,
      "grad_norm": 0.005659306421875954,
      "learning_rate": 3.91737168640722e-05,
      "loss": 0.001,
      "step": 3840
    },
    {
      "epoch": 3.257191201353638,
      "grad_norm": 0.03496940806508064,
      "learning_rate": 3.9145516074450087e-05,
      "loss": 0.0172,
      "step": 3850
    },
    {
      "epoch": 3.265651438240271,
      "grad_norm": 0.0023116273805499077,
      "learning_rate": 3.9117315284827975e-05,
      "loss": 0.0857,
      "step": 3860
    },
    {
      "epoch": 3.2741116751269037,
      "grad_norm": 0.37215325236320496,
      "learning_rate": 3.908911449520587e-05,
      "loss": 0.0286,
      "step": 3870
    },
    {
      "epoch": 3.2825719120135366,
      "grad_norm": 0.035301897674798965,
      "learning_rate": 3.906091370558376e-05,
      "loss": 0.0003,
      "step": 3880
    },
    {
      "epoch": 3.291032148900169,
      "grad_norm": 1.7044183015823364,
      "learning_rate": 3.903271291596165e-05,
      "loss": 0.0404,
      "step": 3890
    },
    {
      "epoch": 3.299492385786802,
      "grad_norm": 0.05944981426000595,
      "learning_rate": 3.900451212633954e-05,
      "loss": 0.0589,
      "step": 3900
    },
    {
      "epoch": 3.307952622673435,
      "grad_norm": 0.0019366999622434378,
      "learning_rate": 3.897631133671743e-05,
      "loss": 0.0014,
      "step": 3910
    },
    {
      "epoch": 3.3164128595600677,
      "grad_norm": 0.001430804724805057,
      "learning_rate": 3.8948110547095316e-05,
      "loss": 0.0209,
      "step": 3920
    },
    {
      "epoch": 3.3248730964467006,
      "grad_norm": 0.009113017469644547,
      "learning_rate": 3.891990975747321e-05,
      "loss": 0.0271,
      "step": 3930
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.013907868415117264,
      "learning_rate": 3.8891708967851105e-05,
      "loss": 0.0268,
      "step": 3940
    },
    {
      "epoch": 3.3417935702199664,
      "grad_norm": 0.12466797977685928,
      "learning_rate": 3.886350817822899e-05,
      "loss": 0.0002,
      "step": 3950
    },
    {
      "epoch": 3.350253807106599,
      "grad_norm": 0.2866568863391876,
      "learning_rate": 3.883530738860688e-05,
      "loss": 0.0004,
      "step": 3960
    },
    {
      "epoch": 3.3587140439932317,
      "grad_norm": 16.02290153503418,
      "learning_rate": 3.880710659898477e-05,
      "loss": 0.0038,
      "step": 3970
    },
    {
      "epoch": 3.3671742808798646,
      "grad_norm": 0.002139738295227289,
      "learning_rate": 3.8778905809362664e-05,
      "loss": 0.001,
      "step": 3980
    },
    {
      "epoch": 3.3756345177664975,
      "grad_norm": 0.0010046265088021755,
      "learning_rate": 3.875070501974055e-05,
      "loss": 0.0474,
      "step": 3990
    },
    {
      "epoch": 3.3840947546531304,
      "grad_norm": 0.008208019658923149,
      "learning_rate": 3.872250423011845e-05,
      "loss": 0.0046,
      "step": 4000
    },
    {
      "epoch": 3.3925549915397633,
      "grad_norm": 1.1522055864334106,
      "learning_rate": 3.8694303440496335e-05,
      "loss": 0.0077,
      "step": 4010
    },
    {
      "epoch": 3.401015228426396,
      "grad_norm": 0.01562747173011303,
      "learning_rate": 3.866610265087422e-05,
      "loss": 0.0063,
      "step": 4020
    },
    {
      "epoch": 3.4094754653130286,
      "grad_norm": 0.0014383612433448434,
      "learning_rate": 3.863790186125212e-05,
      "loss": 0.0529,
      "step": 4030
    },
    {
      "epoch": 3.4179357021996615,
      "grad_norm": 0.0016299285925924778,
      "learning_rate": 3.8609701071630005e-05,
      "loss": 0.0677,
      "step": 4040
    },
    {
      "epoch": 3.4263959390862944,
      "grad_norm": 13.122111320495605,
      "learning_rate": 3.85815002820079e-05,
      "loss": 0.0137,
      "step": 4050
    },
    {
      "epoch": 3.4348561759729273,
      "grad_norm": 0.004875198006629944,
      "learning_rate": 3.855329949238579e-05,
      "loss": 0.0128,
      "step": 4060
    },
    {
      "epoch": 3.44331641285956,
      "grad_norm": 0.02140418067574501,
      "learning_rate": 3.8525098702763676e-05,
      "loss": 0.026,
      "step": 4070
    },
    {
      "epoch": 3.451776649746193,
      "grad_norm": 0.006155872717499733,
      "learning_rate": 3.849689791314157e-05,
      "loss": 0.0184,
      "step": 4080
    },
    {
      "epoch": 3.460236886632826,
      "grad_norm": 0.2374344915151596,
      "learning_rate": 3.846869712351946e-05,
      "loss": 0.0513,
      "step": 4090
    },
    {
      "epoch": 3.4686971235194584,
      "grad_norm": 0.017507631331682205,
      "learning_rate": 3.8440496333897353e-05,
      "loss": 0.0103,
      "step": 4100
    },
    {
      "epoch": 3.4771573604060912,
      "grad_norm": 0.0015163926873356104,
      "learning_rate": 3.841229554427524e-05,
      "loss": 0.0014,
      "step": 4110
    },
    {
      "epoch": 3.485617597292724,
      "grad_norm": 22.77350616455078,
      "learning_rate": 3.838409475465313e-05,
      "loss": 0.0047,
      "step": 4120
    },
    {
      "epoch": 3.494077834179357,
      "grad_norm": 0.07426902651786804,
      "learning_rate": 3.835589396503102e-05,
      "loss": 0.0003,
      "step": 4130
    },
    {
      "epoch": 3.50253807106599,
      "grad_norm": 0.010615148581564426,
      "learning_rate": 3.832769317540891e-05,
      "loss": 0.0201,
      "step": 4140
    },
    {
      "epoch": 3.510998307952623,
      "grad_norm": 0.0011331115383654833,
      "learning_rate": 3.829949238578681e-05,
      "loss": 0.0007,
      "step": 4150
    },
    {
      "epoch": 3.5194585448392557,
      "grad_norm": 1.6333667039871216,
      "learning_rate": 3.8271291596164695e-05,
      "loss": 0.0392,
      "step": 4160
    },
    {
      "epoch": 3.527918781725888,
      "grad_norm": 0.26184895634651184,
      "learning_rate": 3.824309080654259e-05,
      "loss": 0.0205,
      "step": 4170
    },
    {
      "epoch": 3.536379018612521,
      "grad_norm": 0.006672317627817392,
      "learning_rate": 3.821489001692047e-05,
      "loss": 0.0006,
      "step": 4180
    },
    {
      "epoch": 3.544839255499154,
      "grad_norm": 0.004010564181953669,
      "learning_rate": 3.8186689227298365e-05,
      "loss": 0.0361,
      "step": 4190
    },
    {
      "epoch": 3.553299492385787,
      "grad_norm": 0.001074437634088099,
      "learning_rate": 3.8158488437676253e-05,
      "loss": 0.0033,
      "step": 4200
    },
    {
      "epoch": 3.5617597292724197,
      "grad_norm": 0.0021085531916469336,
      "learning_rate": 3.813028764805415e-05,
      "loss": 0.0007,
      "step": 4210
    },
    {
      "epoch": 3.5702199661590526,
      "grad_norm": 0.06242571026086807,
      "learning_rate": 3.810208685843204e-05,
      "loss": 0.0299,
      "step": 4220
    },
    {
      "epoch": 3.5786802030456855,
      "grad_norm": 0.02250576950609684,
      "learning_rate": 3.8073886068809924e-05,
      "loss": 0.107,
      "step": 4230
    },
    {
      "epoch": 3.587140439932318,
      "grad_norm": 0.0011083612916991115,
      "learning_rate": 3.804568527918782e-05,
      "loss": 0.0002,
      "step": 4240
    },
    {
      "epoch": 3.595600676818951,
      "grad_norm": 0.0011230985401198268,
      "learning_rate": 3.801748448956571e-05,
      "loss": 0.003,
      "step": 4250
    },
    {
      "epoch": 3.6040609137055837,
      "grad_norm": 0.009224538691341877,
      "learning_rate": 3.79892836999436e-05,
      "loss": 0.0005,
      "step": 4260
    },
    {
      "epoch": 3.6125211505922166,
      "grad_norm": 15.377131462097168,
      "learning_rate": 3.796108291032149e-05,
      "loss": 0.0193,
      "step": 4270
    },
    {
      "epoch": 3.6209813874788495,
      "grad_norm": 41.638832092285156,
      "learning_rate": 3.7932882120699384e-05,
      "loss": 0.0149,
      "step": 4280
    },
    {
      "epoch": 3.6294416243654823,
      "grad_norm": 0.004737805109471083,
      "learning_rate": 3.790468133107727e-05,
      "loss": 0.0193,
      "step": 4290
    },
    {
      "epoch": 3.6379018612521152,
      "grad_norm": 0.0011369517305865884,
      "learning_rate": 3.787648054145516e-05,
      "loss": 0.005,
      "step": 4300
    },
    {
      "epoch": 3.6463620981387477,
      "grad_norm": 0.09851745516061783,
      "learning_rate": 3.7848279751833055e-05,
      "loss": 0.0856,
      "step": 4310
    },
    {
      "epoch": 3.6548223350253806,
      "grad_norm": 0.10096631944179535,
      "learning_rate": 3.782007896221094e-05,
      "loss": 0.0082,
      "step": 4320
    },
    {
      "epoch": 3.6632825719120135,
      "grad_norm": 0.016250936314463615,
      "learning_rate": 3.779187817258884e-05,
      "loss": 0.0149,
      "step": 4330
    },
    {
      "epoch": 3.6717428087986463,
      "grad_norm": 0.010360185988247395,
      "learning_rate": 3.7763677382966726e-05,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 3.6802030456852792,
      "grad_norm": 6.11821174621582,
      "learning_rate": 3.7735476593344614e-05,
      "loss": 0.0029,
      "step": 4350
    },
    {
      "epoch": 3.688663282571912,
      "grad_norm": 0.33408334851264954,
      "learning_rate": 3.770727580372251e-05,
      "loss": 0.0364,
      "step": 4360
    },
    {
      "epoch": 3.697123519458545,
      "grad_norm": 0.10740282386541367,
      "learning_rate": 3.7679075014100396e-05,
      "loss": 0.0446,
      "step": 4370
    },
    {
      "epoch": 3.7055837563451774,
      "grad_norm": 0.10183051973581314,
      "learning_rate": 3.765087422447829e-05,
      "loss": 0.083,
      "step": 4380
    },
    {
      "epoch": 3.7140439932318103,
      "grad_norm": 41.86067199707031,
      "learning_rate": 3.762267343485618e-05,
      "loss": 0.0233,
      "step": 4390
    },
    {
      "epoch": 3.7225042301184432,
      "grad_norm": 0.002356411889195442,
      "learning_rate": 3.759447264523407e-05,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 3.730964467005076,
      "grad_norm": 38.21589660644531,
      "learning_rate": 3.7566271855611955e-05,
      "loss": 0.058,
      "step": 4410
    },
    {
      "epoch": 3.739424703891709,
      "grad_norm": 0.004705990664660931,
      "learning_rate": 3.753807106598985e-05,
      "loss": 0.0006,
      "step": 4420
    },
    {
      "epoch": 3.747884940778342,
      "grad_norm": 0.00811285711824894,
      "learning_rate": 3.7509870276367744e-05,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 3.7563451776649748,
      "grad_norm": 20.270261764526367,
      "learning_rate": 3.748166948674563e-05,
      "loss": 0.0111,
      "step": 4440
    },
    {
      "epoch": 3.764805414551607,
      "grad_norm": 2.5382938385009766,
      "learning_rate": 3.745346869712352e-05,
      "loss": 0.0652,
      "step": 4450
    },
    {
      "epoch": 3.77326565143824,
      "grad_norm": 0.007213369477540255,
      "learning_rate": 3.742526790750141e-05,
      "loss": 0.0015,
      "step": 4460
    },
    {
      "epoch": 3.781725888324873,
      "grad_norm": 0.5796733498573303,
      "learning_rate": 3.73970671178793e-05,
      "loss": 0.0982,
      "step": 4470
    },
    {
      "epoch": 3.790186125211506,
      "grad_norm": 0.007524318061769009,
      "learning_rate": 3.736886632825719e-05,
      "loss": 0.0006,
      "step": 4480
    },
    {
      "epoch": 3.7986463620981388,
      "grad_norm": 38.97788619995117,
      "learning_rate": 3.7340665538635086e-05,
      "loss": 0.0534,
      "step": 4490
    },
    {
      "epoch": 3.8071065989847717,
      "grad_norm": 0.0011714475695043802,
      "learning_rate": 3.7312464749012974e-05,
      "loss": 0.007,
      "step": 4500
    },
    {
      "epoch": 3.8155668358714045,
      "grad_norm": 0.0011707908706739545,
      "learning_rate": 3.728426395939086e-05,
      "loss": 0.0002,
      "step": 4510
    },
    {
      "epoch": 3.824027072758037,
      "grad_norm": 0.013039976358413696,
      "learning_rate": 3.7256063169768756e-05,
      "loss": 0.0423,
      "step": 4520
    },
    {
      "epoch": 3.8324873096446703,
      "grad_norm": 59.19457244873047,
      "learning_rate": 3.7227862380146644e-05,
      "loss": 0.0625,
      "step": 4530
    },
    {
      "epoch": 3.8409475465313028,
      "grad_norm": 40.03731155395508,
      "learning_rate": 3.719966159052454e-05,
      "loss": 0.0602,
      "step": 4540
    },
    {
      "epoch": 3.8494077834179357,
      "grad_norm": 0.04475225508213043,
      "learning_rate": 3.717146080090243e-05,
      "loss": 0.061,
      "step": 4550
    },
    {
      "epoch": 3.8578680203045685,
      "grad_norm": 27.82916831970215,
      "learning_rate": 3.7143260011280315e-05,
      "loss": 0.0252,
      "step": 4560
    },
    {
      "epoch": 3.8663282571912014,
      "grad_norm": 0.003097225446254015,
      "learning_rate": 3.711505922165821e-05,
      "loss": 0.0461,
      "step": 4570
    },
    {
      "epoch": 3.8747884940778343,
      "grad_norm": 0.018805798143148422,
      "learning_rate": 3.70868584320361e-05,
      "loss": 0.0006,
      "step": 4580
    },
    {
      "epoch": 3.8832487309644668,
      "grad_norm": 92.76812744140625,
      "learning_rate": 3.705865764241399e-05,
      "loss": 0.0996,
      "step": 4590
    },
    {
      "epoch": 3.8917089678511,
      "grad_norm": 0.027651218697428703,
      "learning_rate": 3.703045685279188e-05,
      "loss": 0.0005,
      "step": 4600
    },
    {
      "epoch": 3.9001692047377325,
      "grad_norm": 0.005020800977945328,
      "learning_rate": 3.700225606316977e-05,
      "loss": 0.0753,
      "step": 4610
    },
    {
      "epoch": 3.9086294416243654,
      "grad_norm": 12.201359748840332,
      "learning_rate": 3.6974055273547656e-05,
      "loss": 0.0055,
      "step": 4620
    },
    {
      "epoch": 3.9170896785109983,
      "grad_norm": 0.15659987926483154,
      "learning_rate": 3.694585448392555e-05,
      "loss": 0.0969,
      "step": 4630
    },
    {
      "epoch": 3.925549915397631,
      "grad_norm": 0.2831055819988251,
      "learning_rate": 3.6917653694303446e-05,
      "loss": 0.0543,
      "step": 4640
    },
    {
      "epoch": 3.934010152284264,
      "grad_norm": 0.0067841848358511925,
      "learning_rate": 3.6889452904681334e-05,
      "loss": 0.0524,
      "step": 4650
    },
    {
      "epoch": 3.9424703891708965,
      "grad_norm": 0.10396131128072739,
      "learning_rate": 3.686125211505922e-05,
      "loss": 0.029,
      "step": 4660
    },
    {
      "epoch": 3.95093062605753,
      "grad_norm": 0.001597329042851925,
      "learning_rate": 3.683305132543711e-05,
      "loss": 0.0005,
      "step": 4670
    },
    {
      "epoch": 3.9593908629441623,
      "grad_norm": 1.331456184387207,
      "learning_rate": 3.6804850535815005e-05,
      "loss": 0.0106,
      "step": 4680
    },
    {
      "epoch": 3.967851099830795,
      "grad_norm": 0.0009167367243207991,
      "learning_rate": 3.677664974619289e-05,
      "loss": 0.0306,
      "step": 4690
    },
    {
      "epoch": 3.976311336717428,
      "grad_norm": 0.001508068642579019,
      "learning_rate": 3.674844895657079e-05,
      "loss": 0.0086,
      "step": 4700
    },
    {
      "epoch": 3.984771573604061,
      "grad_norm": 0.03968614339828491,
      "learning_rate": 3.672024816694868e-05,
      "loss": 0.0104,
      "step": 4710
    },
    {
      "epoch": 3.993231810490694,
      "grad_norm": 0.0009144857176579535,
      "learning_rate": 3.669204737732656e-05,
      "loss": 0.0248,
      "step": 4720
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9811111111111112,
      "eval_loss": 0.0983881875872612,
      "eval_runtime": 244.1897,
      "eval_samples_per_second": 22.114,
      "eval_steps_per_second": 2.764,
      "step": 4728
    },
    {
      "epoch": 4.001692047377326,
      "grad_norm": 0.00838447269052267,
      "learning_rate": 3.666384658770446e-05,
      "loss": 0.0481,
      "step": 4730
    },
    {
      "epoch": 4.01015228426396,
      "grad_norm": 0.05189366266131401,
      "learning_rate": 3.6635645798082346e-05,
      "loss": 0.0002,
      "step": 4740
    },
    {
      "epoch": 4.018612521150592,
      "grad_norm": 0.006055421661585569,
      "learning_rate": 3.660744500846024e-05,
      "loss": 0.0999,
      "step": 4750
    },
    {
      "epoch": 4.027072758037225,
      "grad_norm": 0.17113140225410461,
      "learning_rate": 3.657924421883813e-05,
      "loss": 0.0001,
      "step": 4760
    },
    {
      "epoch": 4.035532994923858,
      "grad_norm": 0.0019412715919315815,
      "learning_rate": 3.6551043429216017e-05,
      "loss": 0.0001,
      "step": 4770
    },
    {
      "epoch": 4.04399323181049,
      "grad_norm": 0.13222156465053558,
      "learning_rate": 3.652284263959391e-05,
      "loss": 0.0591,
      "step": 4780
    },
    {
      "epoch": 4.052453468697124,
      "grad_norm": 20.808137893676758,
      "learning_rate": 3.64946418499718e-05,
      "loss": 0.0629,
      "step": 4790
    },
    {
      "epoch": 4.060913705583756,
      "grad_norm": 0.0011984440498054028,
      "learning_rate": 3.6466441060349694e-05,
      "loss": 0.0041,
      "step": 4800
    },
    {
      "epoch": 4.069373942470389,
      "grad_norm": 8.054487228393555,
      "learning_rate": 3.643824027072758e-05,
      "loss": 0.0021,
      "step": 4810
    },
    {
      "epoch": 4.077834179357022,
      "grad_norm": 10.821487426757812,
      "learning_rate": 3.641003948110548e-05,
      "loss": 0.0687,
      "step": 4820
    },
    {
      "epoch": 4.086294416243655,
      "grad_norm": 0.014579346403479576,
      "learning_rate": 3.638183869148336e-05,
      "loss": 0.0031,
      "step": 4830
    },
    {
      "epoch": 4.094754653130288,
      "grad_norm": 0.0013069623382762074,
      "learning_rate": 3.635363790186125e-05,
      "loss": 0.0278,
      "step": 4840
    },
    {
      "epoch": 4.10321489001692,
      "grad_norm": 0.004660760052502155,
      "learning_rate": 3.632543711223915e-05,
      "loss": 0.0039,
      "step": 4850
    },
    {
      "epoch": 4.111675126903553,
      "grad_norm": 44.9605598449707,
      "learning_rate": 3.6297236322617035e-05,
      "loss": 0.0522,
      "step": 4860
    },
    {
      "epoch": 4.120135363790186,
      "grad_norm": 0.03537004441022873,
      "learning_rate": 3.626903553299493e-05,
      "loss": 0.0001,
      "step": 4870
    },
    {
      "epoch": 4.128595600676819,
      "grad_norm": 0.0020748365204781294,
      "learning_rate": 3.624083474337281e-05,
      "loss": 0.0508,
      "step": 4880
    },
    {
      "epoch": 4.137055837563452,
      "grad_norm": 0.0059064943343400955,
      "learning_rate": 3.6212633953750706e-05,
      "loss": 0.0629,
      "step": 4890
    },
    {
      "epoch": 4.145516074450085,
      "grad_norm": 20.716463088989258,
      "learning_rate": 3.6184433164128594e-05,
      "loss": 0.0298,
      "step": 4900
    },
    {
      "epoch": 4.153976311336717,
      "grad_norm": 0.005600760690867901,
      "learning_rate": 3.615623237450649e-05,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 4.16243654822335,
      "grad_norm": 0.0005184190813452005,
      "learning_rate": 3.6128031584884383e-05,
      "loss": 0.0008,
      "step": 4920
    },
    {
      "epoch": 4.170896785109983,
      "grad_norm": 0.0026737540028989315,
      "learning_rate": 3.609983079526227e-05,
      "loss": 0.0003,
      "step": 4930
    },
    {
      "epoch": 4.179357021996616,
      "grad_norm": 0.018178755417466164,
      "learning_rate": 3.607163000564016e-05,
      "loss": 0.0001,
      "step": 4940
    },
    {
      "epoch": 4.187817258883249,
      "grad_norm": 0.0008468001033179462,
      "learning_rate": 3.604342921601805e-05,
      "loss": 0.0372,
      "step": 4950
    },
    {
      "epoch": 4.196277495769881,
      "grad_norm": 0.002735363319516182,
      "learning_rate": 3.601522842639594e-05,
      "loss": 0.0091,
      "step": 4960
    },
    {
      "epoch": 4.204737732656515,
      "grad_norm": 0.00459869671612978,
      "learning_rate": 3.598702763677383e-05,
      "loss": 0.0001,
      "step": 4970
    },
    {
      "epoch": 4.213197969543147,
      "grad_norm": 0.0016976207261905074,
      "learning_rate": 3.5958826847151725e-05,
      "loss": 0.0003,
      "step": 4980
    },
    {
      "epoch": 4.22165820642978,
      "grad_norm": 0.0009161622147075832,
      "learning_rate": 3.593062605752961e-05,
      "loss": 0.0002,
      "step": 4990
    },
    {
      "epoch": 4.230118443316413,
      "grad_norm": 0.0007522794185206294,
      "learning_rate": 3.59024252679075e-05,
      "loss": 0.0003,
      "step": 5000
    },
    {
      "epoch": 4.238578680203045,
      "grad_norm": 0.021669680252671242,
      "learning_rate": 3.5874224478285395e-05,
      "loss": 0.0003,
      "step": 5010
    },
    {
      "epoch": 4.247038917089679,
      "grad_norm": 0.001249210792593658,
      "learning_rate": 3.5846023688663283e-05,
      "loss": 0.0005,
      "step": 5020
    },
    {
      "epoch": 4.255499153976311,
      "grad_norm": 0.1633119136095047,
      "learning_rate": 3.581782289904118e-05,
      "loss": 0.0003,
      "step": 5030
    },
    {
      "epoch": 4.2639593908629445,
      "grad_norm": 7.556812286376953,
      "learning_rate": 3.5789622109419066e-05,
      "loss": 0.0081,
      "step": 5040
    },
    {
      "epoch": 4.272419627749577,
      "grad_norm": 0.000777612382080406,
      "learning_rate": 3.5761421319796954e-05,
      "loss": 0.0007,
      "step": 5050
    },
    {
      "epoch": 4.280879864636209,
      "grad_norm": 0.001112813246436417,
      "learning_rate": 3.573322053017485e-05,
      "loss": 0.0012,
      "step": 5060
    },
    {
      "epoch": 4.289340101522843,
      "grad_norm": 0.010047839023172855,
      "learning_rate": 3.570501974055274e-05,
      "loss": 0.0209,
      "step": 5070
    },
    {
      "epoch": 4.297800338409475,
      "grad_norm": 0.001340313465334475,
      "learning_rate": 3.567681895093063e-05,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 4.3062605752961085,
      "grad_norm": 44.0227165222168,
      "learning_rate": 3.564861816130852e-05,
      "loss": 0.0556,
      "step": 5090
    },
    {
      "epoch": 4.314720812182741,
      "grad_norm": 0.00042451993795111775,
      "learning_rate": 3.562041737168641e-05,
      "loss": 0.0702,
      "step": 5100
    },
    {
      "epoch": 4.323181049069374,
      "grad_norm": 0.01914479024708271,
      "learning_rate": 3.5592216582064295e-05,
      "loss": 0.0,
      "step": 5110
    },
    {
      "epoch": 4.331641285956007,
      "grad_norm": 0.0007154428749345243,
      "learning_rate": 3.556401579244219e-05,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 4.340101522842639,
      "grad_norm": 34.93402862548828,
      "learning_rate": 3.5535815002820085e-05,
      "loss": 0.0423,
      "step": 5130
    },
    {
      "epoch": 4.3485617597292725,
      "grad_norm": 0.0004523104871623218,
      "learning_rate": 3.550761421319797e-05,
      "loss": 0.0144,
      "step": 5140
    },
    {
      "epoch": 4.357021996615905,
      "grad_norm": 0.0022155223414301872,
      "learning_rate": 3.547941342357586e-05,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 4.365482233502538,
      "grad_norm": 0.0022550488356500864,
      "learning_rate": 3.545121263395375e-05,
      "loss": 0.0183,
      "step": 5160
    },
    {
      "epoch": 4.373942470389171,
      "grad_norm": 0.0008717403979972005,
      "learning_rate": 3.5423011844331644e-05,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 4.382402707275804,
      "grad_norm": 0.004135073162615299,
      "learning_rate": 3.539481105470953e-05,
      "loss": 0.0382,
      "step": 5180
    },
    {
      "epoch": 4.3908629441624365,
      "grad_norm": 0.0027376930229365826,
      "learning_rate": 3.5366610265087426e-05,
      "loss": 0.0115,
      "step": 5190
    },
    {
      "epoch": 4.39932318104907,
      "grad_norm": 0.0007371003157459199,
      "learning_rate": 3.5338409475465314e-05,
      "loss": 0.0002,
      "step": 5200
    },
    {
      "epoch": 4.407783417935702,
      "grad_norm": 0.035454634577035904,
      "learning_rate": 3.53102086858432e-05,
      "loss": 0.0002,
      "step": 5210
    },
    {
      "epoch": 4.416243654822335,
      "grad_norm": 0.003352323081344366,
      "learning_rate": 3.52820078962211e-05,
      "loss": 0.0207,
      "step": 5220
    },
    {
      "epoch": 4.424703891708968,
      "grad_norm": 7.48688268661499,
      "learning_rate": 3.5253807106598985e-05,
      "loss": 0.0611,
      "step": 5230
    },
    {
      "epoch": 4.4331641285956005,
      "grad_norm": 0.000511337595526129,
      "learning_rate": 3.522560631697688e-05,
      "loss": 0.0008,
      "step": 5240
    },
    {
      "epoch": 4.441624365482234,
      "grad_norm": 11.278562545776367,
      "learning_rate": 3.519740552735477e-05,
      "loss": 0.0593,
      "step": 5250
    },
    {
      "epoch": 4.450084602368866,
      "grad_norm": 2.48471999168396,
      "learning_rate": 3.5169204737732656e-05,
      "loss": 0.0177,
      "step": 5260
    },
    {
      "epoch": 4.458544839255499,
      "grad_norm": 0.05935634300112724,
      "learning_rate": 3.514100394811055e-05,
      "loss": 0.0104,
      "step": 5270
    },
    {
      "epoch": 4.467005076142132,
      "grad_norm": 7.332823276519775,
      "learning_rate": 3.511280315848844e-05,
      "loss": 0.0374,
      "step": 5280
    },
    {
      "epoch": 4.4754653130287645,
      "grad_norm": 0.002886174013838172,
      "learning_rate": 3.508460236886633e-05,
      "loss": 0.0003,
      "step": 5290
    },
    {
      "epoch": 4.483925549915398,
      "grad_norm": 0.0006390598136931658,
      "learning_rate": 3.505640157924422e-05,
      "loss": 0.0185,
      "step": 5300
    },
    {
      "epoch": 4.49238578680203,
      "grad_norm": 0.0010541939409449697,
      "learning_rate": 3.502820078962211e-05,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 4.500846023688664,
      "grad_norm": 0.0010183639824390411,
      "learning_rate": 3.5e-05,
      "loss": 0.016,
      "step": 5320
    },
    {
      "epoch": 4.509306260575296,
      "grad_norm": 0.003503310028463602,
      "learning_rate": 3.497179921037789e-05,
      "loss": 0.0505,
      "step": 5330
    },
    {
      "epoch": 4.517766497461929,
      "grad_norm": 0.011956801638007164,
      "learning_rate": 3.4943598420755786e-05,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 4.526226734348562,
      "grad_norm": 0.17480307817459106,
      "learning_rate": 3.4915397631133674e-05,
      "loss": 0.0645,
      "step": 5350
    },
    {
      "epoch": 4.534686971235194,
      "grad_norm": 13.193830490112305,
      "learning_rate": 3.488719684151157e-05,
      "loss": 0.0047,
      "step": 5360
    },
    {
      "epoch": 4.543147208121828,
      "grad_norm": 0.004032691475003958,
      "learning_rate": 3.485899605188945e-05,
      "loss": 0.0263,
      "step": 5370
    },
    {
      "epoch": 4.55160744500846,
      "grad_norm": 4.861699104309082,
      "learning_rate": 3.4830795262267345e-05,
      "loss": 0.0011,
      "step": 5380
    },
    {
      "epoch": 4.560067681895093,
      "grad_norm": 0.001978424144908786,
      "learning_rate": 3.480259447264523e-05,
      "loss": 0.049,
      "step": 5390
    },
    {
      "epoch": 4.568527918781726,
      "grad_norm": 0.006780265364795923,
      "learning_rate": 3.477439368302313e-05,
      "loss": 0.0642,
      "step": 5400
    },
    {
      "epoch": 4.576988155668358,
      "grad_norm": 0.0005791350267827511,
      "learning_rate": 3.474619289340102e-05,
      "loss": 0.0062,
      "step": 5410
    },
    {
      "epoch": 4.585448392554992,
      "grad_norm": 0.026468511670827866,
      "learning_rate": 3.4717992103778904e-05,
      "loss": 0.0514,
      "step": 5420
    },
    {
      "epoch": 4.593908629441624,
      "grad_norm": 0.0007777151768095791,
      "learning_rate": 3.46897913141568e-05,
      "loss": 0.0543,
      "step": 5430
    },
    {
      "epoch": 4.602368866328257,
      "grad_norm": 0.0011144551681354642,
      "learning_rate": 3.4661590524534686e-05,
      "loss": 0.0002,
      "step": 5440
    },
    {
      "epoch": 4.61082910321489,
      "grad_norm": 0.01665889099240303,
      "learning_rate": 3.463338973491258e-05,
      "loss": 0.0001,
      "step": 5450
    },
    {
      "epoch": 4.619289340101523,
      "grad_norm": 0.0004894139710813761,
      "learning_rate": 3.460518894529047e-05,
      "loss": 0.0001,
      "step": 5460
    },
    {
      "epoch": 4.627749576988156,
      "grad_norm": 0.0005975358071736991,
      "learning_rate": 3.4576988155668364e-05,
      "loss": 0.0618,
      "step": 5470
    },
    {
      "epoch": 4.636209813874789,
      "grad_norm": 0.0024628876708447933,
      "learning_rate": 3.454878736604625e-05,
      "loss": 0.0579,
      "step": 5480
    },
    {
      "epoch": 4.644670050761421,
      "grad_norm": 0.0017402000958099961,
      "learning_rate": 3.452058657642414e-05,
      "loss": 0.0063,
      "step": 5490
    },
    {
      "epoch": 4.653130287648054,
      "grad_norm": 0.13772323727607727,
      "learning_rate": 3.4492385786802035e-05,
      "loss": 0.001,
      "step": 5500
    },
    {
      "epoch": 4.661590524534687,
      "grad_norm": 0.0011101645650342107,
      "learning_rate": 3.446418499717992e-05,
      "loss": 0.0013,
      "step": 5510
    },
    {
      "epoch": 4.67005076142132,
      "grad_norm": 0.0012950075324624777,
      "learning_rate": 3.443598420755782e-05,
      "loss": 0.0054,
      "step": 5520
    },
    {
      "epoch": 4.678510998307953,
      "grad_norm": 0.012860757298767567,
      "learning_rate": 3.44077834179357e-05,
      "loss": 0.0018,
      "step": 5530
    },
    {
      "epoch": 4.686971235194585,
      "grad_norm": 0.10084102302789688,
      "learning_rate": 3.437958262831359e-05,
      "loss": 0.0044,
      "step": 5540
    },
    {
      "epoch": 4.695431472081218,
      "grad_norm": 0.0009529449162073433,
      "learning_rate": 3.435138183869149e-05,
      "loss": 0.0448,
      "step": 5550
    },
    {
      "epoch": 4.703891708967851,
      "grad_norm": 0.0016074383165687323,
      "learning_rate": 3.4323181049069376e-05,
      "loss": 0.0068,
      "step": 5560
    },
    {
      "epoch": 4.712351945854484,
      "grad_norm": 0.0028980509378015995,
      "learning_rate": 3.429498025944727e-05,
      "loss": 0.0327,
      "step": 5570
    },
    {
      "epoch": 4.720812182741117,
      "grad_norm": 0.0014102936256676912,
      "learning_rate": 3.426677946982516e-05,
      "loss": 0.0054,
      "step": 5580
    },
    {
      "epoch": 4.729272419627749,
      "grad_norm": 6.440666675567627,
      "learning_rate": 3.4238578680203047e-05,
      "loss": 0.0393,
      "step": 5590
    },
    {
      "epoch": 4.737732656514383,
      "grad_norm": 0.036787547171115875,
      "learning_rate": 3.4210377890580935e-05,
      "loss": 0.0029,
      "step": 5600
    },
    {
      "epoch": 4.746192893401015,
      "grad_norm": 0.0012621756177395582,
      "learning_rate": 3.418217710095883e-05,
      "loss": 0.0191,
      "step": 5610
    },
    {
      "epoch": 4.7546531302876485,
      "grad_norm": 0.010711428709328175,
      "learning_rate": 3.4153976311336724e-05,
      "loss": 0.0491,
      "step": 5620
    },
    {
      "epoch": 4.763113367174281,
      "grad_norm": 0.0010598469525575638,
      "learning_rate": 3.412577552171461e-05,
      "loss": 0.0005,
      "step": 5630
    },
    {
      "epoch": 4.771573604060913,
      "grad_norm": 0.053452666848897934,
      "learning_rate": 3.40975747320925e-05,
      "loss": 0.0001,
      "step": 5640
    },
    {
      "epoch": 4.780033840947547,
      "grad_norm": 0.32756224274635315,
      "learning_rate": 3.406937394247039e-05,
      "loss": 0.0095,
      "step": 5650
    },
    {
      "epoch": 4.788494077834179,
      "grad_norm": 0.02107892744243145,
      "learning_rate": 3.404117315284828e-05,
      "loss": 0.0125,
      "step": 5660
    },
    {
      "epoch": 4.7969543147208125,
      "grad_norm": 0.0007417812594212592,
      "learning_rate": 3.401297236322617e-05,
      "loss": 0.1002,
      "step": 5670
    },
    {
      "epoch": 4.805414551607445,
      "grad_norm": 0.0005917042144574225,
      "learning_rate": 3.3984771573604065e-05,
      "loss": 0.0092,
      "step": 5680
    },
    {
      "epoch": 4.813874788494077,
      "grad_norm": 0.014250446110963821,
      "learning_rate": 3.395657078398195e-05,
      "loss": 0.0488,
      "step": 5690
    },
    {
      "epoch": 4.822335025380711,
      "grad_norm": 0.007111320737749338,
      "learning_rate": 3.392836999435984e-05,
      "loss": 0.0635,
      "step": 5700
    },
    {
      "epoch": 4.830795262267343,
      "grad_norm": 0.0012872042134404182,
      "learning_rate": 3.3900169204737736e-05,
      "loss": 0.0113,
      "step": 5710
    },
    {
      "epoch": 4.8392554991539765,
      "grad_norm": 0.0013676137896254659,
      "learning_rate": 3.3871968415115624e-05,
      "loss": 0.0783,
      "step": 5720
    },
    {
      "epoch": 4.847715736040609,
      "grad_norm": 0.38881006836891174,
      "learning_rate": 3.384376762549352e-05,
      "loss": 0.0026,
      "step": 5730
    },
    {
      "epoch": 4.856175972927242,
      "grad_norm": 0.33584064245224,
      "learning_rate": 3.381556683587141e-05,
      "loss": 0.0004,
      "step": 5740
    },
    {
      "epoch": 4.864636209813875,
      "grad_norm": 0.3325847387313843,
      "learning_rate": 3.3787366046249295e-05,
      "loss": 0.0178,
      "step": 5750
    },
    {
      "epoch": 4.873096446700508,
      "grad_norm": 0.0362086147069931,
      "learning_rate": 3.375916525662719e-05,
      "loss": 0.0009,
      "step": 5760
    },
    {
      "epoch": 4.8815566835871405,
      "grad_norm": 0.002336557488888502,
      "learning_rate": 3.373096446700508e-05,
      "loss": 0.0365,
      "step": 5770
    },
    {
      "epoch": 4.890016920473773,
      "grad_norm": 0.0010363418841734529,
      "learning_rate": 3.370276367738297e-05,
      "loss": 0.0524,
      "step": 5780
    },
    {
      "epoch": 4.898477157360406,
      "grad_norm": 0.022306790575385094,
      "learning_rate": 3.367456288776086e-05,
      "loss": 0.0244,
      "step": 5790
    },
    {
      "epoch": 4.906937394247039,
      "grad_norm": 22.276203155517578,
      "learning_rate": 3.364636209813875e-05,
      "loss": 0.0373,
      "step": 5800
    },
    {
      "epoch": 4.915397631133672,
      "grad_norm": 0.03146412596106529,
      "learning_rate": 3.3618161308516636e-05,
      "loss": 0.0007,
      "step": 5810
    },
    {
      "epoch": 4.9238578680203045,
      "grad_norm": 0.0009572830749675632,
      "learning_rate": 3.358996051889453e-05,
      "loss": 0.0094,
      "step": 5820
    },
    {
      "epoch": 4.932318104906937,
      "grad_norm": 35.21375274658203,
      "learning_rate": 3.3561759729272425e-05,
      "loss": 0.1465,
      "step": 5830
    },
    {
      "epoch": 4.94077834179357,
      "grad_norm": 35.833221435546875,
      "learning_rate": 3.3533558939650313e-05,
      "loss": 0.0662,
      "step": 5840
    },
    {
      "epoch": 4.949238578680203,
      "grad_norm": 0.010310040786862373,
      "learning_rate": 3.35053581500282e-05,
      "loss": 0.1178,
      "step": 5850
    },
    {
      "epoch": 4.957698815566836,
      "grad_norm": 0.002540305256843567,
      "learning_rate": 3.347715736040609e-05,
      "loss": 0.0001,
      "step": 5860
    },
    {
      "epoch": 4.9661590524534684,
      "grad_norm": 0.07586555182933807,
      "learning_rate": 3.3448956570783984e-05,
      "loss": 0.0009,
      "step": 5870
    },
    {
      "epoch": 4.974619289340102,
      "grad_norm": 0.7592684626579285,
      "learning_rate": 3.342075578116187e-05,
      "loss": 0.0005,
      "step": 5880
    },
    {
      "epoch": 4.983079526226734,
      "grad_norm": 0.032136838883161545,
      "learning_rate": 3.339255499153977e-05,
      "loss": 0.0115,
      "step": 5890
    },
    {
      "epoch": 4.991539763113368,
      "grad_norm": 0.0005928167956881225,
      "learning_rate": 3.3364354201917655e-05,
      "loss": 0.0476,
      "step": 5900
    },
    {
      "epoch": 5.0,
      "grad_norm": 79.78588104248047,
      "learning_rate": 3.333615341229554e-05,
      "loss": 0.0601,
      "step": 5910
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9787037037037037,
      "eval_loss": 0.11622678488492966,
      "eval_runtime": 248.0008,
      "eval_samples_per_second": 21.774,
      "eval_steps_per_second": 2.722,
      "step": 5910
    }
  ],
  "logging_steps": 10,
  "max_steps": 17730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.71670182660096e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
