{
  "best_global_step": 3546,
  "best_metric": 0.9790740740740741,
  "best_model_checkpoint": "VPC3_TP_EutoSat_Vit/models/tiny/checkpoint-3546",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3546,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008460236886632826,
      "grad_norm": 14.466089248657227,
      "learning_rate": 4.9974619289340105e-05,
      "loss": 1.9739,
      "step": 10
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 20.900371551513672,
      "learning_rate": 4.994641849971799e-05,
      "loss": 1.1346,
      "step": 20
    },
    {
      "epoch": 0.025380710659898477,
      "grad_norm": 14.140461921691895,
      "learning_rate": 4.991821771009588e-05,
      "loss": 0.6714,
      "step": 30
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 14.910873413085938,
      "learning_rate": 4.9890016920473776e-05,
      "loss": 0.4596,
      "step": 40
    },
    {
      "epoch": 0.04230118443316413,
      "grad_norm": 35.95499801635742,
      "learning_rate": 4.986181613085167e-05,
      "loss": 0.4352,
      "step": 50
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 10.581116676330566,
      "learning_rate": 4.983361534122956e-05,
      "loss": 0.319,
      "step": 60
    },
    {
      "epoch": 0.05922165820642978,
      "grad_norm": 11.34449291229248,
      "learning_rate": 4.9805414551607446e-05,
      "loss": 0.2842,
      "step": 70
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 7.4420576095581055,
      "learning_rate": 4.9777213761985334e-05,
      "loss": 0.2789,
      "step": 80
    },
    {
      "epoch": 0.07614213197969544,
      "grad_norm": 21.182126998901367,
      "learning_rate": 4.974901297236323e-05,
      "loss": 0.2123,
      "step": 90
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 11.74959659576416,
      "learning_rate": 4.972081218274112e-05,
      "loss": 0.2109,
      "step": 100
    },
    {
      "epoch": 0.09306260575296109,
      "grad_norm": 24.90926170349121,
      "learning_rate": 4.969261139311901e-05,
      "loss": 0.1604,
      "step": 110
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.184607982635498,
      "learning_rate": 4.96644106034969e-05,
      "loss": 0.3748,
      "step": 120
    },
    {
      "epoch": 0.10998307952622674,
      "grad_norm": 12.008848190307617,
      "learning_rate": 4.963620981387479e-05,
      "loss": 0.1721,
      "step": 130
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 10.822035789489746,
      "learning_rate": 4.960800902425268e-05,
      "loss": 0.1741,
      "step": 140
    },
    {
      "epoch": 0.12690355329949238,
      "grad_norm": 3.1626784801483154,
      "learning_rate": 4.957980823463057e-05,
      "loss": 0.1298,
      "step": 150
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 6.791316032409668,
      "learning_rate": 4.9551607445008465e-05,
      "loss": 0.1967,
      "step": 160
    },
    {
      "epoch": 0.14382402707275804,
      "grad_norm": 4.2050347328186035,
      "learning_rate": 4.952340665538635e-05,
      "loss": 0.1122,
      "step": 170
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 11.0927095413208,
      "learning_rate": 4.949520586576424e-05,
      "loss": 0.1621,
      "step": 180
    },
    {
      "epoch": 0.16074450084602368,
      "grad_norm": 25.3814697265625,
      "learning_rate": 4.9467005076142136e-05,
      "loss": 0.374,
      "step": 190
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 2.0944905281066895,
      "learning_rate": 4.9438804286520024e-05,
      "loss": 0.1641,
      "step": 200
    },
    {
      "epoch": 0.17766497461928935,
      "grad_norm": 14.078400611877441,
      "learning_rate": 4.941060349689792e-05,
      "loss": 0.2302,
      "step": 210
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 13.332756996154785,
      "learning_rate": 4.9382402707275806e-05,
      "loss": 0.2209,
      "step": 220
    },
    {
      "epoch": 0.19458544839255498,
      "grad_norm": 1.499985694885254,
      "learning_rate": 4.9354201917653694e-05,
      "loss": 0.3221,
      "step": 230
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 1.4748750925064087,
      "learning_rate": 4.932600112803158e-05,
      "loss": 0.1699,
      "step": 240
    },
    {
      "epoch": 0.21150592216582065,
      "grad_norm": 28.762161254882812,
      "learning_rate": 4.929780033840948e-05,
      "loss": 0.1859,
      "step": 250
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 21.489336013793945,
      "learning_rate": 4.926959954878737e-05,
      "loss": 0.0832,
      "step": 260
    },
    {
      "epoch": 0.22842639593908629,
      "grad_norm": 1.1055177450180054,
      "learning_rate": 4.924139875916526e-05,
      "loss": 0.1289,
      "step": 270
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 22.156885147094727,
      "learning_rate": 4.921319796954315e-05,
      "loss": 0.1383,
      "step": 280
    },
    {
      "epoch": 0.24534686971235195,
      "grad_norm": 13.688899040222168,
      "learning_rate": 4.9184997179921036e-05,
      "loss": 0.1253,
      "step": 290
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 2.1891090869903564,
      "learning_rate": 4.915679639029893e-05,
      "loss": 0.1817,
      "step": 300
    },
    {
      "epoch": 0.2622673434856176,
      "grad_norm": 29.75678253173828,
      "learning_rate": 4.912859560067682e-05,
      "loss": 0.1101,
      "step": 310
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 19.95785140991211,
      "learning_rate": 4.910039481105471e-05,
      "loss": 0.1785,
      "step": 320
    },
    {
      "epoch": 0.27918781725888325,
      "grad_norm": 4.945294380187988,
      "learning_rate": 4.907219402143261e-05,
      "loss": 0.2358,
      "step": 330
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 26.60957145690918,
      "learning_rate": 4.904399323181049e-05,
      "loss": 0.1177,
      "step": 340
    },
    {
      "epoch": 0.2961082910321489,
      "grad_norm": 44.35723876953125,
      "learning_rate": 4.9015792442188384e-05,
      "loss": 0.1052,
      "step": 350
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.2594661712646484,
      "learning_rate": 4.898759165256627e-05,
      "loss": 0.1825,
      "step": 360
    },
    {
      "epoch": 0.3130287648054145,
      "grad_norm": 1.4883270263671875,
      "learning_rate": 4.8959390862944167e-05,
      "loss": 0.1231,
      "step": 370
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 17.421049118041992,
      "learning_rate": 4.8931190073322055e-05,
      "loss": 0.1644,
      "step": 380
    },
    {
      "epoch": 0.3299492385786802,
      "grad_norm": 16.858835220336914,
      "learning_rate": 4.890298928369995e-05,
      "loss": 0.1424,
      "step": 390
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 14.830533027648926,
      "learning_rate": 4.887478849407784e-05,
      "loss": 0.1687,
      "step": 400
    },
    {
      "epoch": 0.34686971235194586,
      "grad_norm": 2.4005239009857178,
      "learning_rate": 4.8846587704455725e-05,
      "loss": 0.1471,
      "step": 410
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.5430868268013,
      "learning_rate": 4.881838691483362e-05,
      "loss": 0.1136,
      "step": 420
    },
    {
      "epoch": 0.3637901861252115,
      "grad_norm": 0.6713274717330933,
      "learning_rate": 4.879018612521151e-05,
      "loss": 0.3007,
      "step": 430
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.46859073638916,
      "learning_rate": 4.87619853355894e-05,
      "loss": 0.0564,
      "step": 440
    },
    {
      "epoch": 0.38071065989847713,
      "grad_norm": 0.944525957107544,
      "learning_rate": 4.8733784545967284e-05,
      "loss": 0.1091,
      "step": 450
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.24216057360172272,
      "learning_rate": 4.870558375634518e-05,
      "loss": 0.0261,
      "step": 460
    },
    {
      "epoch": 0.3976311336717428,
      "grad_norm": 17.511394500732422,
      "learning_rate": 4.867738296672307e-05,
      "loss": 0.1677,
      "step": 470
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 13.479783058166504,
      "learning_rate": 4.864918217710096e-05,
      "loss": 0.2508,
      "step": 480
    },
    {
      "epoch": 0.41455160744500846,
      "grad_norm": 19.93234634399414,
      "learning_rate": 4.8620981387478856e-05,
      "loss": 0.0422,
      "step": 490
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 4.957183837890625,
      "learning_rate": 4.8592780597856744e-05,
      "loss": 0.0953,
      "step": 500
    },
    {
      "epoch": 0.43147208121827413,
      "grad_norm": 2.8080811500549316,
      "learning_rate": 4.856457980823463e-05,
      "loss": 0.0667,
      "step": 510
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 26.37185287475586,
      "learning_rate": 4.853637901861252e-05,
      "loss": 0.2009,
      "step": 520
    },
    {
      "epoch": 0.44839255499153974,
      "grad_norm": 1.484768033027649,
      "learning_rate": 4.8508178228990415e-05,
      "loss": 0.038,
      "step": 530
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 20.85687255859375,
      "learning_rate": 4.847997743936831e-05,
      "loss": 0.1368,
      "step": 540
    },
    {
      "epoch": 0.4653130287648054,
      "grad_norm": 2.726987361907959,
      "learning_rate": 4.84517766497462e-05,
      "loss": 0.1399,
      "step": 550
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 15.755430221557617,
      "learning_rate": 4.8423575860124085e-05,
      "loss": 0.0465,
      "step": 560
    },
    {
      "epoch": 0.48223350253807107,
      "grad_norm": 28.094520568847656,
      "learning_rate": 4.839537507050197e-05,
      "loss": 0.199,
      "step": 570
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 0.03665974736213684,
      "learning_rate": 4.836717428087987e-05,
      "loss": 0.1026,
      "step": 580
    },
    {
      "epoch": 0.49915397631133673,
      "grad_norm": 0.3312017023563385,
      "learning_rate": 4.8338973491257756e-05,
      "loss": 0.204,
      "step": 590
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 0.2591623365879059,
      "learning_rate": 4.831077270163565e-05,
      "loss": 0.1357,
      "step": 600
    },
    {
      "epoch": 0.5160744500846024,
      "grad_norm": 23.12666130065918,
      "learning_rate": 4.828257191201354e-05,
      "loss": 0.114,
      "step": 610
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.457749366760254,
      "learning_rate": 4.825437112239143e-05,
      "loss": 0.0955,
      "step": 620
    },
    {
      "epoch": 0.5329949238578681,
      "grad_norm": 19.274295806884766,
      "learning_rate": 4.822617033276932e-05,
      "loss": 0.318,
      "step": 630
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 22.72943115234375,
      "learning_rate": 4.819796954314721e-05,
      "loss": 0.146,
      "step": 640
    },
    {
      "epoch": 0.5499153976311336,
      "grad_norm": 6.262524604797363,
      "learning_rate": 4.8169768753525104e-05,
      "loss": 0.1691,
      "step": 650
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 20.436107635498047,
      "learning_rate": 4.814156796390299e-05,
      "loss": 0.1831,
      "step": 660
    },
    {
      "epoch": 0.5668358714043993,
      "grad_norm": 13.359298706054688,
      "learning_rate": 4.811336717428088e-05,
      "loss": 0.0537,
      "step": 670
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 7.079187393188477,
      "learning_rate": 4.8085166384658775e-05,
      "loss": 0.0709,
      "step": 680
    },
    {
      "epoch": 0.583756345177665,
      "grad_norm": 0.7319515347480774,
      "learning_rate": 4.805696559503666e-05,
      "loss": 0.1109,
      "step": 690
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 23.68626594543457,
      "learning_rate": 4.802876480541456e-05,
      "loss": 0.0784,
      "step": 700
    },
    {
      "epoch": 0.6006768189509306,
      "grad_norm": 0.6795468926429749,
      "learning_rate": 4.8000564015792445e-05,
      "loss": 0.1495,
      "step": 710
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 0.15101884305477142,
      "learning_rate": 4.7972363226170333e-05,
      "loss": 0.1307,
      "step": 720
    },
    {
      "epoch": 0.6175972927241963,
      "grad_norm": 10.494664192199707,
      "learning_rate": 4.794416243654822e-05,
      "loss": 0.1626,
      "step": 730
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 18.630586624145508,
      "learning_rate": 4.7915961646926116e-05,
      "loss": 0.1586,
      "step": 740
    },
    {
      "epoch": 0.6345177664974619,
      "grad_norm": 0.2620302140712738,
      "learning_rate": 4.788776085730401e-05,
      "loss": 0.0755,
      "step": 750
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 0.09258006513118744,
      "learning_rate": 4.78595600676819e-05,
      "loss": 0.1077,
      "step": 760
    },
    {
      "epoch": 0.6514382402707276,
      "grad_norm": 0.4374638497829437,
      "learning_rate": 4.783135927805979e-05,
      "loss": 0.1392,
      "step": 770
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.67353755235672,
      "learning_rate": 4.7803158488437675e-05,
      "loss": 0.0857,
      "step": 780
    },
    {
      "epoch": 0.6683587140439933,
      "grad_norm": 19.41292381286621,
      "learning_rate": 4.777495769881557e-05,
      "loss": 0.1199,
      "step": 790
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.23480162024497986,
      "learning_rate": 4.774675690919346e-05,
      "loss": 0.0371,
      "step": 800
    },
    {
      "epoch": 0.6852791878172588,
      "grad_norm": 0.12986932694911957,
      "learning_rate": 4.771855611957135e-05,
      "loss": 0.2893,
      "step": 810
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 1.1319631338119507,
      "learning_rate": 4.769035532994924e-05,
      "loss": 0.0735,
      "step": 820
    },
    {
      "epoch": 0.7021996615905245,
      "grad_norm": 9.579446792602539,
      "learning_rate": 4.766215454032713e-05,
      "loss": 0.1398,
      "step": 830
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 33.17691421508789,
      "learning_rate": 4.763395375070502e-05,
      "loss": 0.1564,
      "step": 840
    },
    {
      "epoch": 0.7191201353637902,
      "grad_norm": 7.179660797119141,
      "learning_rate": 4.760575296108291e-05,
      "loss": 0.1506,
      "step": 850
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 4.116767883300781,
      "learning_rate": 4.7577552171460806e-05,
      "loss": 0.0688,
      "step": 860
    },
    {
      "epoch": 0.7360406091370558,
      "grad_norm": 14.570455551147461,
      "learning_rate": 4.7549351381838694e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 0.619854748249054,
      "learning_rate": 4.752115059221658e-05,
      "loss": 0.1513,
      "step": 880
    },
    {
      "epoch": 0.7529610829103215,
      "grad_norm": 5.441271781921387,
      "learning_rate": 4.7492949802594476e-05,
      "loss": 0.261,
      "step": 890
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 2.6095757484436035,
      "learning_rate": 4.7464749012972364e-05,
      "loss": 0.0479,
      "step": 900
    },
    {
      "epoch": 0.7698815566835872,
      "grad_norm": 18.807838439941406,
      "learning_rate": 4.743654822335026e-05,
      "loss": 0.0865,
      "step": 910
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 19.832582473754883,
      "learning_rate": 4.740834743372815e-05,
      "loss": 0.2682,
      "step": 920
    },
    {
      "epoch": 0.7868020304568528,
      "grad_norm": 23.313390731811523,
      "learning_rate": 4.7380146644106035e-05,
      "loss": 0.1621,
      "step": 930
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 2.7553422451019287,
      "learning_rate": 4.735194585448392e-05,
      "loss": 0.1222,
      "step": 940
    },
    {
      "epoch": 0.8037225042301185,
      "grad_norm": 0.5432969331741333,
      "learning_rate": 4.732374506486182e-05,
      "loss": 0.083,
      "step": 950
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 11.276805877685547,
      "learning_rate": 4.729554427523971e-05,
      "loss": 0.0629,
      "step": 960
    },
    {
      "epoch": 0.8206429780033841,
      "grad_norm": 5.896979331970215,
      "learning_rate": 4.72673434856176e-05,
      "loss": 0.1201,
      "step": 970
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 16.9703426361084,
      "learning_rate": 4.7239142695995495e-05,
      "loss": 0.121,
      "step": 980
    },
    {
      "epoch": 0.8375634517766497,
      "grad_norm": 0.12442143261432648,
      "learning_rate": 4.7210941906373376e-05,
      "loss": 0.1755,
      "step": 990
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 0.058043692260980606,
      "learning_rate": 4.718274111675127e-05,
      "loss": 0.1251,
      "step": 1000
    },
    {
      "epoch": 0.8544839255499154,
      "grad_norm": 42.14734649658203,
      "learning_rate": 4.715454032712916e-05,
      "loss": 0.1367,
      "step": 1010
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 26.698923110961914,
      "learning_rate": 4.7126339537507054e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.871404399323181,
      "grad_norm": 3.701037645339966,
      "learning_rate": 4.709813874788495e-05,
      "loss": 0.2048,
      "step": 1030
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 12.624013900756836,
      "learning_rate": 4.706993795826283e-05,
      "loss": 0.1073,
      "step": 1040
    },
    {
      "epoch": 0.8883248730964467,
      "grad_norm": 30.081945419311523,
      "learning_rate": 4.7041737168640724e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 24.828798294067383,
      "learning_rate": 4.701353637901861e-05,
      "loss": 0.087,
      "step": 1060
    },
    {
      "epoch": 0.9052453468697124,
      "grad_norm": 27.589454650878906,
      "learning_rate": 4.698533558939651e-05,
      "loss": 0.0654,
      "step": 1070
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.207147598266602,
      "learning_rate": 4.6957134799774395e-05,
      "loss": 0.0868,
      "step": 1080
    },
    {
      "epoch": 0.922165820642978,
      "grad_norm": 1.1621407270431519,
      "learning_rate": 4.692893401015229e-05,
      "loss": 0.0359,
      "step": 1090
    },
    {
      "epoch": 0.9306260575296108,
      "grad_norm": 42.396610260009766,
      "learning_rate": 4.690073322053018e-05,
      "loss": 0.1143,
      "step": 1100
    },
    {
      "epoch": 0.9390862944162437,
      "grad_norm": 21.23570442199707,
      "learning_rate": 4.6872532430908066e-05,
      "loss": 0.1539,
      "step": 1110
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.07133467495441437,
      "learning_rate": 4.684433164128596e-05,
      "loss": 0.0776,
      "step": 1120
    },
    {
      "epoch": 0.9560067681895094,
      "grad_norm": 1.5074037313461304,
      "learning_rate": 4.681613085166385e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 18.812101364135742,
      "learning_rate": 4.678793006204174e-05,
      "loss": 0.0749,
      "step": 1140
    },
    {
      "epoch": 0.9729272419627749,
      "grad_norm": 2.423281669616699,
      "learning_rate": 4.675972927241963e-05,
      "loss": 0.2021,
      "step": 1150
    },
    {
      "epoch": 0.9813874788494078,
      "grad_norm": 2.271929979324341,
      "learning_rate": 4.673152848279752e-05,
      "loss": 0.1919,
      "step": 1160
    },
    {
      "epoch": 0.9898477157360406,
      "grad_norm": 5.057013034820557,
      "learning_rate": 4.6703327693175414e-05,
      "loss": 0.0771,
      "step": 1170
    },
    {
      "epoch": 0.9983079526226735,
      "grad_norm": 10.19404411315918,
      "learning_rate": 4.66751269035533e-05,
      "loss": 0.0594,
      "step": 1180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9690740740740741,
      "eval_loss": 0.11386065185070038,
      "eval_runtime": 246.4452,
      "eval_samples_per_second": 21.912,
      "eval_steps_per_second": 2.739,
      "step": 1182
    },
    {
      "epoch": 1.0067681895093064,
      "grad_norm": 0.0524885393679142,
      "learning_rate": 4.6646926113931197e-05,
      "loss": 0.1154,
      "step": 1190
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 0.2056097388267517,
      "learning_rate": 4.6618725324309085e-05,
      "loss": 0.0667,
      "step": 1200
    },
    {
      "epoch": 1.023688663282572,
      "grad_norm": 0.31934717297554016,
      "learning_rate": 4.659052453468697e-05,
      "loss": 0.0517,
      "step": 1210
    },
    {
      "epoch": 1.0321489001692048,
      "grad_norm": 0.44508466124534607,
      "learning_rate": 4.656232374506486e-05,
      "loss": 0.0806,
      "step": 1220
    },
    {
      "epoch": 1.0406091370558375,
      "grad_norm": 17.873205184936523,
      "learning_rate": 4.6534122955442755e-05,
      "loss": 0.1168,
      "step": 1230
    },
    {
      "epoch": 1.0490693739424704,
      "grad_norm": 0.1031579002737999,
      "learning_rate": 4.650592216582065e-05,
      "loss": 0.0885,
      "step": 1240
    },
    {
      "epoch": 1.0575296108291032,
      "grad_norm": 1.859145998954773,
      "learning_rate": 4.647772137619854e-05,
      "loss": 0.0546,
      "step": 1250
    },
    {
      "epoch": 1.0659898477157361,
      "grad_norm": 2.6971371173858643,
      "learning_rate": 4.6449520586576426e-05,
      "loss": 0.0586,
      "step": 1260
    },
    {
      "epoch": 1.0744500846023688,
      "grad_norm": 3.4226748943328857,
      "learning_rate": 4.6421319796954314e-05,
      "loss": 0.1291,
      "step": 1270
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.06498179584741592,
      "learning_rate": 4.639311900733221e-05,
      "loss": 0.0912,
      "step": 1280
    },
    {
      "epoch": 1.0913705583756346,
      "grad_norm": 2.8320469856262207,
      "learning_rate": 4.6364918217710097e-05,
      "loss": 0.0783,
      "step": 1290
    },
    {
      "epoch": 1.0998307952622675,
      "grad_norm": 0.09660017490386963,
      "learning_rate": 4.633671742808799e-05,
      "loss": 0.0907,
      "step": 1300
    },
    {
      "epoch": 1.1082910321489001,
      "grad_norm": 0.13180534541606903,
      "learning_rate": 4.630851663846588e-05,
      "loss": 0.0413,
      "step": 1310
    },
    {
      "epoch": 1.116751269035533,
      "grad_norm": 0.16015172004699707,
      "learning_rate": 4.628031584884377e-05,
      "loss": 0.0407,
      "step": 1320
    },
    {
      "epoch": 1.125211505922166,
      "grad_norm": 9.34089469909668,
      "learning_rate": 4.625211505922166e-05,
      "loss": 0.1045,
      "step": 1330
    },
    {
      "epoch": 1.1336717428087986,
      "grad_norm": 24.051116943359375,
      "learning_rate": 4.622391426959955e-05,
      "loss": 0.0467,
      "step": 1340
    },
    {
      "epoch": 1.1421319796954315,
      "grad_norm": 9.480792045593262,
      "learning_rate": 4.6195713479977445e-05,
      "loss": 0.1429,
      "step": 1350
    },
    {
      "epoch": 1.1505922165820643,
      "grad_norm": 0.2971787750720978,
      "learning_rate": 4.616751269035533e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 1.1590524534686972,
      "grad_norm": 1.4138188362121582,
      "learning_rate": 4.613931190073322e-05,
      "loss": 0.0279,
      "step": 1370
    },
    {
      "epoch": 1.16751269035533,
      "grad_norm": 26.05870246887207,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0514,
      "step": 1380
    },
    {
      "epoch": 1.1759729272419628,
      "grad_norm": 0.014784063212573528,
      "learning_rate": 4.6082910321489e-05,
      "loss": 0.0145,
      "step": 1390
    },
    {
      "epoch": 1.1844331641285957,
      "grad_norm": 3.2919983863830566,
      "learning_rate": 4.60547095318669e-05,
      "loss": 0.0022,
      "step": 1400
    },
    {
      "epoch": 1.1928934010152283,
      "grad_norm": 20.8558349609375,
      "learning_rate": 4.6026508742244786e-05,
      "loss": 0.1509,
      "step": 1410
    },
    {
      "epoch": 1.2013536379018612,
      "grad_norm": 1.2578448057174683,
      "learning_rate": 4.5998307952622674e-05,
      "loss": 0.0209,
      "step": 1420
    },
    {
      "epoch": 1.2098138747884941,
      "grad_norm": 20.923458099365234,
      "learning_rate": 4.597010716300056e-05,
      "loss": 0.0547,
      "step": 1430
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 0.0193844735622406,
      "learning_rate": 4.594190637337846e-05,
      "loss": 0.178,
      "step": 1440
    },
    {
      "epoch": 1.2267343485617597,
      "grad_norm": 0.34279999136924744,
      "learning_rate": 4.591370558375635e-05,
      "loss": 0.0055,
      "step": 1450
    },
    {
      "epoch": 1.2351945854483926,
      "grad_norm": 0.713297963142395,
      "learning_rate": 4.588550479413424e-05,
      "loss": 0.0185,
      "step": 1460
    },
    {
      "epoch": 1.2436548223350254,
      "grad_norm": 0.06155781447887421,
      "learning_rate": 4.585730400451213e-05,
      "loss": 0.0267,
      "step": 1470
    },
    {
      "epoch": 1.252115059221658,
      "grad_norm": 15.050272941589355,
      "learning_rate": 4.5829103214890015e-05,
      "loss": 0.1215,
      "step": 1480
    },
    {
      "epoch": 1.260575296108291,
      "grad_norm": 2.018648386001587,
      "learning_rate": 4.580090242526791e-05,
      "loss": 0.0928,
      "step": 1490
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 26.905744552612305,
      "learning_rate": 4.57727016356458e-05,
      "loss": 0.0494,
      "step": 1500
    },
    {
      "epoch": 1.2774957698815568,
      "grad_norm": 0.08350187540054321,
      "learning_rate": 4.574450084602369e-05,
      "loss": 0.0409,
      "step": 1510
    },
    {
      "epoch": 1.2859560067681894,
      "grad_norm": 0.1177479475736618,
      "learning_rate": 4.571630005640159e-05,
      "loss": 0.1218,
      "step": 1520
    },
    {
      "epoch": 1.2944162436548223,
      "grad_norm": 14.32288932800293,
      "learning_rate": 4.568809926677947e-05,
      "loss": 0.1414,
      "step": 1530
    },
    {
      "epoch": 1.3028764805414552,
      "grad_norm": 0.8191991448402405,
      "learning_rate": 4.5659898477157363e-05,
      "loss": 0.0487,
      "step": 1540
    },
    {
      "epoch": 1.3113367174280879,
      "grad_norm": 1.2151057720184326,
      "learning_rate": 4.563169768753525e-05,
      "loss": 0.0101,
      "step": 1550
    },
    {
      "epoch": 1.3197969543147208,
      "grad_norm": 22.795188903808594,
      "learning_rate": 4.5603496897913146e-05,
      "loss": 0.056,
      "step": 1560
    },
    {
      "epoch": 1.3282571912013537,
      "grad_norm": 24.174396514892578,
      "learning_rate": 4.5575296108291034e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 1.3367174280879865,
      "grad_norm": 20.76497459411621,
      "learning_rate": 4.554709531866892e-05,
      "loss": 0.2546,
      "step": 1580
    },
    {
      "epoch": 1.3451776649746192,
      "grad_norm": 44.310550689697266,
      "learning_rate": 4.551889452904681e-05,
      "loss": 0.1427,
      "step": 1590
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 0.04374610632658005,
      "learning_rate": 4.5490693739424705e-05,
      "loss": 0.1959,
      "step": 1600
    },
    {
      "epoch": 1.362098138747885,
      "grad_norm": 6.750633716583252,
      "learning_rate": 4.54624929498026e-05,
      "loss": 0.0342,
      "step": 1610
    },
    {
      "epoch": 1.3705583756345177,
      "grad_norm": 0.28728750348091125,
      "learning_rate": 4.543429216018049e-05,
      "loss": 0.0333,
      "step": 1620
    },
    {
      "epoch": 1.3790186125211505,
      "grad_norm": 1.095624566078186,
      "learning_rate": 4.540609137055838e-05,
      "loss": 0.055,
      "step": 1630
    },
    {
      "epoch": 1.3874788494077834,
      "grad_norm": 0.1793481707572937,
      "learning_rate": 4.5377890580936263e-05,
      "loss": 0.0789,
      "step": 1640
    },
    {
      "epoch": 1.3959390862944163,
      "grad_norm": 0.10460668057203293,
      "learning_rate": 4.534968979131416e-05,
      "loss": 0.1204,
      "step": 1650
    },
    {
      "epoch": 1.404399323181049,
      "grad_norm": 0.17484290897846222,
      "learning_rate": 4.5321489001692046e-05,
      "loss": 0.0569,
      "step": 1660
    },
    {
      "epoch": 1.4128595600676819,
      "grad_norm": 2.5536487102508545,
      "learning_rate": 4.529328821206994e-05,
      "loss": 0.0966,
      "step": 1670
    },
    {
      "epoch": 1.4213197969543148,
      "grad_norm": 0.033308885991573334,
      "learning_rate": 4.5265087422447836e-05,
      "loss": 0.0455,
      "step": 1680
    },
    {
      "epoch": 1.4297800338409474,
      "grad_norm": 0.03772977367043495,
      "learning_rate": 4.523688663282572e-05,
      "loss": 0.1548,
      "step": 1690
    },
    {
      "epoch": 1.4382402707275803,
      "grad_norm": 0.09216587990522385,
      "learning_rate": 4.520868584320361e-05,
      "loss": 0.05,
      "step": 1700
    },
    {
      "epoch": 1.4467005076142132,
      "grad_norm": 0.03644145280122757,
      "learning_rate": 4.51804850535815e-05,
      "loss": 0.0294,
      "step": 1710
    },
    {
      "epoch": 1.455160744500846,
      "grad_norm": 0.005973259452730417,
      "learning_rate": 4.5152284263959394e-05,
      "loss": 0.0558,
      "step": 1720
    },
    {
      "epoch": 1.463620981387479,
      "grad_norm": 0.24085456132888794,
      "learning_rate": 4.512408347433728e-05,
      "loss": 0.055,
      "step": 1730
    },
    {
      "epoch": 1.4720812182741116,
      "grad_norm": 0.006745295133441687,
      "learning_rate": 4.509588268471518e-05,
      "loss": 0.0501,
      "step": 1740
    },
    {
      "epoch": 1.4805414551607445,
      "grad_norm": 0.49678128957748413,
      "learning_rate": 4.5067681895093065e-05,
      "loss": 0.0194,
      "step": 1750
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.2952556610107422,
      "learning_rate": 4.503948110547095e-05,
      "loss": 0.0893,
      "step": 1760
    },
    {
      "epoch": 1.49746192893401,
      "grad_norm": 1.9802641868591309,
      "learning_rate": 4.501128031584885e-05,
      "loss": 0.0114,
      "step": 1770
    },
    {
      "epoch": 1.505922165820643,
      "grad_norm": 0.016201358288526535,
      "learning_rate": 4.4983079526226736e-05,
      "loss": 0.1306,
      "step": 1780
    },
    {
      "epoch": 1.5143824027072759,
      "grad_norm": 0.2131015509366989,
      "learning_rate": 4.495487873660463e-05,
      "loss": 0.0282,
      "step": 1790
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 0.1275821179151535,
      "learning_rate": 4.492667794698252e-05,
      "loss": 0.0732,
      "step": 1800
    },
    {
      "epoch": 1.5313028764805414,
      "grad_norm": 32.563453674316406,
      "learning_rate": 4.4898477157360406e-05,
      "loss": 0.0461,
      "step": 1810
    },
    {
      "epoch": 1.5397631133671743,
      "grad_norm": 0.01262142974883318,
      "learning_rate": 4.48702763677383e-05,
      "loss": 0.0382,
      "step": 1820
    },
    {
      "epoch": 1.548223350253807,
      "grad_norm": 3.734633207321167,
      "learning_rate": 4.484207557811619e-05,
      "loss": 0.0036,
      "step": 1830
    },
    {
      "epoch": 1.5566835871404399,
      "grad_norm": 0.026379531249403954,
      "learning_rate": 4.4813874788494084e-05,
      "loss": 0.0045,
      "step": 1840
    },
    {
      "epoch": 1.5651438240270727,
      "grad_norm": 0.006282446440309286,
      "learning_rate": 4.478567399887197e-05,
      "loss": 0.0065,
      "step": 1850
    },
    {
      "epoch": 1.5736040609137056,
      "grad_norm": 0.3327971398830414,
      "learning_rate": 4.475747320924986e-05,
      "loss": 0.0198,
      "step": 1860
    },
    {
      "epoch": 1.5820642978003385,
      "grad_norm": 0.11799824237823486,
      "learning_rate": 4.472927241962775e-05,
      "loss": 0.1285,
      "step": 1870
    },
    {
      "epoch": 1.5905245346869712,
      "grad_norm": 0.005150949582457542,
      "learning_rate": 4.470107163000564e-05,
      "loss": 0.0009,
      "step": 1880
    },
    {
      "epoch": 1.598984771573604,
      "grad_norm": 20.945222854614258,
      "learning_rate": 4.467287084038354e-05,
      "loss": 0.0764,
      "step": 1890
    },
    {
      "epoch": 1.6074450084602367,
      "grad_norm": 14.346229553222656,
      "learning_rate": 4.4644670050761425e-05,
      "loss": 0.052,
      "step": 1900
    },
    {
      "epoch": 1.6159052453468696,
      "grad_norm": 0.4961164593696594,
      "learning_rate": 4.461646926113931e-05,
      "loss": 0.0594,
      "step": 1910
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 0.05455700308084488,
      "learning_rate": 4.45882684715172e-05,
      "loss": 0.1213,
      "step": 1920
    },
    {
      "epoch": 1.6328257191201354,
      "grad_norm": 35.61746597290039,
      "learning_rate": 4.4560067681895096e-05,
      "loss": 0.1965,
      "step": 1930
    },
    {
      "epoch": 1.6412859560067683,
      "grad_norm": 0.14853937923908234,
      "learning_rate": 4.4531866892272984e-05,
      "loss": 0.071,
      "step": 1940
    },
    {
      "epoch": 1.649746192893401,
      "grad_norm": 29.400121688842773,
      "learning_rate": 4.450366610265088e-05,
      "loss": 0.1181,
      "step": 1950
    },
    {
      "epoch": 1.6582064297800339,
      "grad_norm": 26.16289520263672,
      "learning_rate": 4.4475465313028766e-05,
      "loss": 0.0451,
      "step": 1960
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 16.397777557373047,
      "learning_rate": 4.4447264523406654e-05,
      "loss": 0.0818,
      "step": 1970
    },
    {
      "epoch": 1.6751269035532994,
      "grad_norm": 0.09849713742733002,
      "learning_rate": 4.441906373378455e-05,
      "loss": 0.0955,
      "step": 1980
    },
    {
      "epoch": 1.6835871404399323,
      "grad_norm": 7.682143211364746,
      "learning_rate": 4.439086294416244e-05,
      "loss": 0.1323,
      "step": 1990
    },
    {
      "epoch": 1.6920473773265652,
      "grad_norm": 0.6320121884346008,
      "learning_rate": 4.436266215454033e-05,
      "loss": 0.1091,
      "step": 2000
    },
    {
      "epoch": 1.700507614213198,
      "grad_norm": 0.12847696244716644,
      "learning_rate": 4.433446136491822e-05,
      "loss": 0.0281,
      "step": 2010
    },
    {
      "epoch": 1.708967851099831,
      "grad_norm": 15.028797149658203,
      "learning_rate": 4.430626057529611e-05,
      "loss": 0.0261,
      "step": 2020
    },
    {
      "epoch": 1.7174280879864636,
      "grad_norm": 0.01604713872075081,
      "learning_rate": 4.4278059785674e-05,
      "loss": 0.0013,
      "step": 2030
    },
    {
      "epoch": 1.7258883248730963,
      "grad_norm": 17.731983184814453,
      "learning_rate": 4.424985899605189e-05,
      "loss": 0.0434,
      "step": 2040
    },
    {
      "epoch": 1.7343485617597292,
      "grad_norm": 0.12152490019798279,
      "learning_rate": 4.4221658206429785e-05,
      "loss": 0.0606,
      "step": 2050
    },
    {
      "epoch": 1.742808798646362,
      "grad_norm": 0.003514975542202592,
      "learning_rate": 4.419345741680767e-05,
      "loss": 0.0556,
      "step": 2060
    },
    {
      "epoch": 1.751269035532995,
      "grad_norm": 2.6348941326141357,
      "learning_rate": 4.416525662718556e-05,
      "loss": 0.1486,
      "step": 2070
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 21.712257385253906,
      "learning_rate": 4.413705583756345e-05,
      "loss": 0.1412,
      "step": 2080
    },
    {
      "epoch": 1.7681895093062607,
      "grad_norm": 0.0020400604698807,
      "learning_rate": 4.4108855047941344e-05,
      "loss": 0.069,
      "step": 2090
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 13.40526294708252,
      "learning_rate": 4.408065425831924e-05,
      "loss": 0.0379,
      "step": 2100
    },
    {
      "epoch": 1.785109983079526,
      "grad_norm": 0.07841428369283676,
      "learning_rate": 4.4052453468697127e-05,
      "loss": 0.0338,
      "step": 2110
    },
    {
      "epoch": 1.793570219966159,
      "grad_norm": 21.989072799682617,
      "learning_rate": 4.4024252679075015e-05,
      "loss": 0.0383,
      "step": 2120
    },
    {
      "epoch": 1.8020304568527918,
      "grad_norm": 8.322708129882812,
      "learning_rate": 4.39960518894529e-05,
      "loss": 0.1942,
      "step": 2130
    },
    {
      "epoch": 1.8104906937394247,
      "grad_norm": 0.019643452018499374,
      "learning_rate": 4.39678510998308e-05,
      "loss": 0.0736,
      "step": 2140
    },
    {
      "epoch": 1.8189509306260576,
      "grad_norm": 37.64115524291992,
      "learning_rate": 4.3939650310208685e-05,
      "loss": 0.1089,
      "step": 2150
    },
    {
      "epoch": 1.8274111675126905,
      "grad_norm": 12.482965469360352,
      "learning_rate": 4.391144952058658e-05,
      "loss": 0.1011,
      "step": 2160
    },
    {
      "epoch": 1.8358714043993232,
      "grad_norm": 0.03910377621650696,
      "learning_rate": 4.3883248730964475e-05,
      "loss": 0.093,
      "step": 2170
    },
    {
      "epoch": 1.844331641285956,
      "grad_norm": 1.2610856294631958,
      "learning_rate": 4.3855047941342356e-05,
      "loss": 0.0736,
      "step": 2180
    },
    {
      "epoch": 1.8527918781725887,
      "grad_norm": 15.85295295715332,
      "learning_rate": 4.382684715172025e-05,
      "loss": 0.1832,
      "step": 2190
    },
    {
      "epoch": 1.8612521150592216,
      "grad_norm": 0.31547269225120544,
      "learning_rate": 4.379864636209814e-05,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 1.8697123519458545,
      "grad_norm": 0.3832317292690277,
      "learning_rate": 4.377044557247603e-05,
      "loss": 0.0473,
      "step": 2210
    },
    {
      "epoch": 1.8781725888324874,
      "grad_norm": 0.0396120585501194,
      "learning_rate": 4.374224478285392e-05,
      "loss": 0.0631,
      "step": 2220
    },
    {
      "epoch": 1.8866328257191203,
      "grad_norm": 0.14707453548908234,
      "learning_rate": 4.371404399323181e-05,
      "loss": 0.0929,
      "step": 2230
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 0.01668008789420128,
      "learning_rate": 4.3685843203609704e-05,
      "loss": 0.0821,
      "step": 2240
    },
    {
      "epoch": 1.9035532994923858,
      "grad_norm": 0.11122526228427887,
      "learning_rate": 4.365764241398759e-05,
      "loss": 0.1329,
      "step": 2250
    },
    {
      "epoch": 1.9120135363790185,
      "grad_norm": 35.64632797241211,
      "learning_rate": 4.362944162436549e-05,
      "loss": 0.0724,
      "step": 2260
    },
    {
      "epoch": 1.9204737732656514,
      "grad_norm": 0.12160845100879669,
      "learning_rate": 4.3601240834743375e-05,
      "loss": 0.0693,
      "step": 2270
    },
    {
      "epoch": 1.9289340101522843,
      "grad_norm": 0.010136724449694157,
      "learning_rate": 4.357304004512127e-05,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 1.9373942470389172,
      "grad_norm": 0.020088551566004753,
      "learning_rate": 4.354483925549915e-05,
      "loss": 0.0402,
      "step": 2290
    },
    {
      "epoch": 1.94585448392555,
      "grad_norm": 0.01234954409301281,
      "learning_rate": 4.3516638465877045e-05,
      "loss": 0.0293,
      "step": 2300
    },
    {
      "epoch": 1.9543147208121827,
      "grad_norm": 1.4190717935562134,
      "learning_rate": 4.348843767625494e-05,
      "loss": 0.1906,
      "step": 2310
    },
    {
      "epoch": 1.9627749576988156,
      "grad_norm": 0.010624142363667488,
      "learning_rate": 4.346023688663283e-05,
      "loss": 0.0392,
      "step": 2320
    },
    {
      "epoch": 1.9712351945854483,
      "grad_norm": 22.869890213012695,
      "learning_rate": 4.343203609701072e-05,
      "loss": 0.0536,
      "step": 2330
    },
    {
      "epoch": 1.9796954314720812,
      "grad_norm": 0.01851845346391201,
      "learning_rate": 4.3403835307388604e-05,
      "loss": 0.0733,
      "step": 2340
    },
    {
      "epoch": 1.988155668358714,
      "grad_norm": 25.321544647216797,
      "learning_rate": 4.33756345177665e-05,
      "loss": 0.0828,
      "step": 2350
    },
    {
      "epoch": 1.996615905245347,
      "grad_norm": 0.037506792694330215,
      "learning_rate": 4.334743372814439e-05,
      "loss": 0.046,
      "step": 2360
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9779629629629629,
      "eval_loss": 0.09348412603139877,
      "eval_runtime": 246.6577,
      "eval_samples_per_second": 21.893,
      "eval_steps_per_second": 2.737,
      "step": 2364
    },
    {
      "epoch": 2.00507614213198,
      "grad_norm": 0.7050085067749023,
      "learning_rate": 4.331923293852228e-05,
      "loss": 0.0019,
      "step": 2370
    },
    {
      "epoch": 2.0135363790186127,
      "grad_norm": 0.004118071403354406,
      "learning_rate": 4.3291032148900176e-05,
      "loss": 0.0297,
      "step": 2380
    },
    {
      "epoch": 2.021996615905245,
      "grad_norm": 36.45760726928711,
      "learning_rate": 4.3262831359278064e-05,
      "loss": 0.0852,
      "step": 2390
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 0.002832560334354639,
      "learning_rate": 4.323463056965595e-05,
      "loss": 0.0159,
      "step": 2400
    },
    {
      "epoch": 2.038917089678511,
      "grad_norm": 0.015435759909451008,
      "learning_rate": 4.320642978003384e-05,
      "loss": 0.0082,
      "step": 2410
    },
    {
      "epoch": 2.047377326565144,
      "grad_norm": 0.06332072615623474,
      "learning_rate": 4.3178228990411735e-05,
      "loss": 0.0096,
      "step": 2420
    },
    {
      "epoch": 2.0558375634517767,
      "grad_norm": 23.606990814208984,
      "learning_rate": 4.315002820078962e-05,
      "loss": 0.096,
      "step": 2430
    },
    {
      "epoch": 2.0642978003384096,
      "grad_norm": 16.45185089111328,
      "learning_rate": 4.312182741116752e-05,
      "loss": 0.0696,
      "step": 2440
    },
    {
      "epoch": 2.0727580372250425,
      "grad_norm": 23.556838989257812,
      "learning_rate": 4.3093626621545405e-05,
      "loss": 0.0283,
      "step": 2450
    },
    {
      "epoch": 2.081218274111675,
      "grad_norm": 0.35000672936439514,
      "learning_rate": 4.3065425831923293e-05,
      "loss": 0.0263,
      "step": 2460
    },
    {
      "epoch": 2.089678510998308,
      "grad_norm": 1.4101324081420898,
      "learning_rate": 4.303722504230119e-05,
      "loss": 0.0688,
      "step": 2470
    },
    {
      "epoch": 2.0981387478849407,
      "grad_norm": 17.108341217041016,
      "learning_rate": 4.3009024252679076e-05,
      "loss": 0.1071,
      "step": 2480
    },
    {
      "epoch": 2.1065989847715736,
      "grad_norm": 4.765998363494873,
      "learning_rate": 4.298082346305697e-05,
      "loss": 0.0024,
      "step": 2490
    },
    {
      "epoch": 2.1150592216582065,
      "grad_norm": 0.18713925778865814,
      "learning_rate": 4.295262267343486e-05,
      "loss": 0.0195,
      "step": 2500
    },
    {
      "epoch": 2.1235194585448394,
      "grad_norm": 1.4044023752212524,
      "learning_rate": 4.292442188381275e-05,
      "loss": 0.0151,
      "step": 2510
    },
    {
      "epoch": 2.1319796954314723,
      "grad_norm": 0.022990819066762924,
      "learning_rate": 4.289622109419064e-05,
      "loss": 0.0006,
      "step": 2520
    },
    {
      "epoch": 2.1404399323181047,
      "grad_norm": 0.4567020535469055,
      "learning_rate": 4.286802030456853e-05,
      "loss": 0.0272,
      "step": 2530
    },
    {
      "epoch": 2.1489001692047376,
      "grad_norm": 17.143157958984375,
      "learning_rate": 4.2839819514946424e-05,
      "loss": 0.0573,
      "step": 2540
    },
    {
      "epoch": 2.1573604060913705,
      "grad_norm": 0.5564812421798706,
      "learning_rate": 4.281161872532431e-05,
      "loss": 0.0137,
      "step": 2550
    },
    {
      "epoch": 2.1658206429780034,
      "grad_norm": 1.2734674215316772,
      "learning_rate": 4.27834179357022e-05,
      "loss": 0.0527,
      "step": 2560
    },
    {
      "epoch": 2.1742808798646363,
      "grad_norm": 0.05679820850491524,
      "learning_rate": 4.275521714608009e-05,
      "loss": 0.01,
      "step": 2570
    },
    {
      "epoch": 2.182741116751269,
      "grad_norm": 0.5252026915550232,
      "learning_rate": 4.272701635645798e-05,
      "loss": 0.0544,
      "step": 2580
    },
    {
      "epoch": 2.191201353637902,
      "grad_norm": 25.15257453918457,
      "learning_rate": 4.269881556683588e-05,
      "loss": 0.0168,
      "step": 2590
    },
    {
      "epoch": 2.199661590524535,
      "grad_norm": 20.0202579498291,
      "learning_rate": 4.2670614777213766e-05,
      "loss": 0.0555,
      "step": 2600
    },
    {
      "epoch": 2.2081218274111674,
      "grad_norm": 0.0031947263050824404,
      "learning_rate": 4.2642413987591654e-05,
      "loss": 0.005,
      "step": 2610
    },
    {
      "epoch": 2.2165820642978002,
      "grad_norm": 0.019850878044962883,
      "learning_rate": 4.261421319796954e-05,
      "loss": 0.0004,
      "step": 2620
    },
    {
      "epoch": 2.225042301184433,
      "grad_norm": 3.6412107944488525,
      "learning_rate": 4.2586012408347436e-05,
      "loss": 0.0964,
      "step": 2630
    },
    {
      "epoch": 2.233502538071066,
      "grad_norm": 1.5771880149841309,
      "learning_rate": 4.2557811618725324e-05,
      "loss": 0.0219,
      "step": 2640
    },
    {
      "epoch": 2.241962774957699,
      "grad_norm": 0.00178819231223315,
      "learning_rate": 4.252961082910322e-05,
      "loss": 0.058,
      "step": 2650
    },
    {
      "epoch": 2.250423011844332,
      "grad_norm": 17.10619354248047,
      "learning_rate": 4.250141003948111e-05,
      "loss": 0.114,
      "step": 2660
    },
    {
      "epoch": 2.2588832487309647,
      "grad_norm": 0.012720372527837753,
      "learning_rate": 4.2473209249858995e-05,
      "loss": 0.0003,
      "step": 2670
    },
    {
      "epoch": 2.267343485617597,
      "grad_norm": 0.007427964825183153,
      "learning_rate": 4.244500846023689e-05,
      "loss": 0.0313,
      "step": 2680
    },
    {
      "epoch": 2.27580372250423,
      "grad_norm": 0.01936277747154236,
      "learning_rate": 4.241680767061478e-05,
      "loss": 0.0297,
      "step": 2690
    },
    {
      "epoch": 2.284263959390863,
      "grad_norm": 9.420300483703613,
      "learning_rate": 4.238860688099267e-05,
      "loss": 0.0189,
      "step": 2700
    },
    {
      "epoch": 2.292724196277496,
      "grad_norm": 0.9173603653907776,
      "learning_rate": 4.236040609137056e-05,
      "loss": 0.0659,
      "step": 2710
    },
    {
      "epoch": 2.3011844331641287,
      "grad_norm": 0.0064922175370156765,
      "learning_rate": 4.233220530174845e-05,
      "loss": 0.0816,
      "step": 2720
    },
    {
      "epoch": 2.3096446700507616,
      "grad_norm": 2.5201611518859863,
      "learning_rate": 4.230400451212634e-05,
      "loss": 0.0159,
      "step": 2730
    },
    {
      "epoch": 2.3181049069373945,
      "grad_norm": 0.01033511571586132,
      "learning_rate": 4.227580372250423e-05,
      "loss": 0.0022,
      "step": 2740
    },
    {
      "epoch": 2.326565143824027,
      "grad_norm": 0.3796350657939911,
      "learning_rate": 4.2247602932882126e-05,
      "loss": 0.0836,
      "step": 2750
    },
    {
      "epoch": 2.33502538071066,
      "grad_norm": 12.385169982910156,
      "learning_rate": 4.2219402143260014e-05,
      "loss": 0.0703,
      "step": 2760
    },
    {
      "epoch": 2.3434856175972927,
      "grad_norm": 0.017592186108231544,
      "learning_rate": 4.21912013536379e-05,
      "loss": 0.1087,
      "step": 2770
    },
    {
      "epoch": 2.3519458544839256,
      "grad_norm": 2.3975565433502197,
      "learning_rate": 4.216300056401579e-05,
      "loss": 0.0045,
      "step": 2780
    },
    {
      "epoch": 2.3604060913705585,
      "grad_norm": 0.017607372254133224,
      "learning_rate": 4.2134799774393684e-05,
      "loss": 0.0671,
      "step": 2790
    },
    {
      "epoch": 2.3688663282571913,
      "grad_norm": 3.5394468307495117,
      "learning_rate": 4.210659898477158e-05,
      "loss": 0.0218,
      "step": 2800
    },
    {
      "epoch": 2.3773265651438242,
      "grad_norm": 0.16227824985980988,
      "learning_rate": 4.207839819514947e-05,
      "loss": 0.0023,
      "step": 2810
    },
    {
      "epoch": 2.3857868020304567,
      "grad_norm": 2.4429545402526855,
      "learning_rate": 4.2050197405527355e-05,
      "loss": 0.0355,
      "step": 2820
    },
    {
      "epoch": 2.3942470389170896,
      "grad_norm": 0.008337924256920815,
      "learning_rate": 4.202199661590524e-05,
      "loss": 0.1437,
      "step": 2830
    },
    {
      "epoch": 2.4027072758037225,
      "grad_norm": 24.83634376525879,
      "learning_rate": 4.199379582628314e-05,
      "loss": 0.0725,
      "step": 2840
    },
    {
      "epoch": 2.4111675126903553,
      "grad_norm": 0.06213049590587616,
      "learning_rate": 4.1965595036661026e-05,
      "loss": 0.0635,
      "step": 2850
    },
    {
      "epoch": 2.4196277495769882,
      "grad_norm": 0.005098477005958557,
      "learning_rate": 4.193739424703892e-05,
      "loss": 0.0236,
      "step": 2860
    },
    {
      "epoch": 2.428087986463621,
      "grad_norm": 0.012588235549628735,
      "learning_rate": 4.1909193457416815e-05,
      "loss": 0.0025,
      "step": 2870
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 17.291196823120117,
      "learning_rate": 4.1880992667794696e-05,
      "loss": 0.0647,
      "step": 2880
    },
    {
      "epoch": 2.4450084602368864,
      "grad_norm": 0.05634631961584091,
      "learning_rate": 4.185279187817259e-05,
      "loss": 0.0087,
      "step": 2890
    },
    {
      "epoch": 2.4534686971235193,
      "grad_norm": 0.00411198940128088,
      "learning_rate": 4.182459108855048e-05,
      "loss": 0.0491,
      "step": 2900
    },
    {
      "epoch": 2.4619289340101522,
      "grad_norm": 0.02043735422194004,
      "learning_rate": 4.1796390298928374e-05,
      "loss": 0.0304,
      "step": 2910
    },
    {
      "epoch": 2.470389170896785,
      "grad_norm": 0.20278824865818024,
      "learning_rate": 4.176818950930626e-05,
      "loss": 0.0616,
      "step": 2920
    },
    {
      "epoch": 2.478849407783418,
      "grad_norm": 0.005257409065961838,
      "learning_rate": 4.1739988719684157e-05,
      "loss": 0.074,
      "step": 2930
    },
    {
      "epoch": 2.487309644670051,
      "grad_norm": 0.013093408197164536,
      "learning_rate": 4.1711787930062045e-05,
      "loss": 0.0489,
      "step": 2940
    },
    {
      "epoch": 2.495769881556684,
      "grad_norm": 15.578856468200684,
      "learning_rate": 4.168358714043993e-05,
      "loss": 0.0064,
      "step": 2950
    },
    {
      "epoch": 2.504230118443316,
      "grad_norm": 0.6917970776557922,
      "learning_rate": 4.165538635081783e-05,
      "loss": 0.0027,
      "step": 2960
    },
    {
      "epoch": 2.512690355329949,
      "grad_norm": 3.800091028213501,
      "learning_rate": 4.1627185561195715e-05,
      "loss": 0.0687,
      "step": 2970
    },
    {
      "epoch": 2.521150592216582,
      "grad_norm": 14.703471183776855,
      "learning_rate": 4.159898477157361e-05,
      "loss": 0.0388,
      "step": 2980
    },
    {
      "epoch": 2.529610829103215,
      "grad_norm": 0.030179444700479507,
      "learning_rate": 4.157078398195149e-05,
      "loss": 0.0036,
      "step": 2990
    },
    {
      "epoch": 2.5380710659898478,
      "grad_norm": 0.00749274343252182,
      "learning_rate": 4.1542583192329386e-05,
      "loss": 0.0162,
      "step": 3000
    },
    {
      "epoch": 2.5465313028764807,
      "grad_norm": 5.890507698059082,
      "learning_rate": 4.151438240270728e-05,
      "loss": 0.0182,
      "step": 3010
    },
    {
      "epoch": 2.5549915397631136,
      "grad_norm": 1.79206120967865,
      "learning_rate": 4.148618161308517e-05,
      "loss": 0.0032,
      "step": 3020
    },
    {
      "epoch": 2.563451776649746,
      "grad_norm": 0.002368614310398698,
      "learning_rate": 4.145798082346306e-05,
      "loss": 0.051,
      "step": 3030
    },
    {
      "epoch": 2.571912013536379,
      "grad_norm": 0.387143075466156,
      "learning_rate": 4.142978003384095e-05,
      "loss": 0.086,
      "step": 3040
    },
    {
      "epoch": 2.5803722504230118,
      "grad_norm": 0.14291664958000183,
      "learning_rate": 4.140157924421884e-05,
      "loss": 0.0548,
      "step": 3050
    },
    {
      "epoch": 2.5888324873096447,
      "grad_norm": 0.004535431042313576,
      "learning_rate": 4.137337845459673e-05,
      "loss": 0.029,
      "step": 3060
    },
    {
      "epoch": 2.5972927241962775,
      "grad_norm": 0.10469698160886765,
      "learning_rate": 4.134517766497462e-05,
      "loss": 0.0057,
      "step": 3070
    },
    {
      "epoch": 2.6057529610829104,
      "grad_norm": 0.3293409049510956,
      "learning_rate": 4.131697687535252e-05,
      "loss": 0.0774,
      "step": 3080
    },
    {
      "epoch": 2.6142131979695433,
      "grad_norm": 32.15681076049805,
      "learning_rate": 4.1288776085730405e-05,
      "loss": 0.0603,
      "step": 3090
    },
    {
      "epoch": 2.6226734348561758,
      "grad_norm": 0.0024791238829493523,
      "learning_rate": 4.126057529610829e-05,
      "loss": 0.0064,
      "step": 3100
    },
    {
      "epoch": 2.6311336717428087,
      "grad_norm": 0.0034042412880808115,
      "learning_rate": 4.123237450648618e-05,
      "loss": 0.0128,
      "step": 3110
    },
    {
      "epoch": 2.6395939086294415,
      "grad_norm": 0.0038752921391278505,
      "learning_rate": 4.1204173716864075e-05,
      "loss": 0.0358,
      "step": 3120
    },
    {
      "epoch": 2.6480541455160744,
      "grad_norm": 0.008329003117978573,
      "learning_rate": 4.117597292724196e-05,
      "loss": 0.0334,
      "step": 3130
    },
    {
      "epoch": 2.6565143824027073,
      "grad_norm": 31.37432289123535,
      "learning_rate": 4.114777213761986e-05,
      "loss": 0.2025,
      "step": 3140
    },
    {
      "epoch": 2.66497461928934,
      "grad_norm": 0.0014850286534056067,
      "learning_rate": 4.1119571347997746e-05,
      "loss": 0.0929,
      "step": 3150
    },
    {
      "epoch": 2.673434856175973,
      "grad_norm": 4.7359771728515625,
      "learning_rate": 4.1091370558375634e-05,
      "loss": 0.0943,
      "step": 3160
    },
    {
      "epoch": 2.6818950930626055,
      "grad_norm": 0.014216204173862934,
      "learning_rate": 4.106316976875353e-05,
      "loss": 0.0145,
      "step": 3170
    },
    {
      "epoch": 2.6903553299492384,
      "grad_norm": 2.0783638954162598,
      "learning_rate": 4.103496897913142e-05,
      "loss": 0.0228,
      "step": 3180
    },
    {
      "epoch": 2.6988155668358713,
      "grad_norm": 3.2795324325561523,
      "learning_rate": 4.100676818950931e-05,
      "loss": 0.0169,
      "step": 3190
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 0.0433700792491436,
      "learning_rate": 4.09785673998872e-05,
      "loss": 0.0612,
      "step": 3200
    },
    {
      "epoch": 2.715736040609137,
      "grad_norm": 32.12123489379883,
      "learning_rate": 4.095036661026509e-05,
      "loss": 0.0217,
      "step": 3210
    },
    {
      "epoch": 2.72419627749577,
      "grad_norm": 0.8155362010002136,
      "learning_rate": 4.092216582064298e-05,
      "loss": 0.0118,
      "step": 3220
    },
    {
      "epoch": 2.732656514382403,
      "grad_norm": 0.2179349660873413,
      "learning_rate": 4.089396503102087e-05,
      "loss": 0.0145,
      "step": 3230
    },
    {
      "epoch": 2.7411167512690353,
      "grad_norm": 1.4932093620300293,
      "learning_rate": 4.0865764241398765e-05,
      "loss": 0.0233,
      "step": 3240
    },
    {
      "epoch": 2.749576988155668,
      "grad_norm": 0.00364291830919683,
      "learning_rate": 4.083756345177665e-05,
      "loss": 0.1643,
      "step": 3250
    },
    {
      "epoch": 2.758037225042301,
      "grad_norm": 0.09596369415521622,
      "learning_rate": 4.080936266215454e-05,
      "loss": 0.0446,
      "step": 3260
    },
    {
      "epoch": 2.766497461928934,
      "grad_norm": 0.9563506245613098,
      "learning_rate": 4.078116187253243e-05,
      "loss": 0.0277,
      "step": 3270
    },
    {
      "epoch": 2.774957698815567,
      "grad_norm": 1.0228968858718872,
      "learning_rate": 4.0752961082910323e-05,
      "loss": 0.0641,
      "step": 3280
    },
    {
      "epoch": 2.7834179357021998,
      "grad_norm": 0.7322272062301636,
      "learning_rate": 4.072476029328822e-05,
      "loss": 0.0704,
      "step": 3290
    },
    {
      "epoch": 2.7918781725888326,
      "grad_norm": 0.010357234627008438,
      "learning_rate": 4.0696559503666106e-05,
      "loss": 0.0566,
      "step": 3300
    },
    {
      "epoch": 2.800338409475465,
      "grad_norm": 2.28533935546875,
      "learning_rate": 4.0668358714043994e-05,
      "loss": 0.0015,
      "step": 3310
    },
    {
      "epoch": 2.808798646362098,
      "grad_norm": 71.36479187011719,
      "learning_rate": 4.064015792442188e-05,
      "loss": 0.0601,
      "step": 3320
    },
    {
      "epoch": 2.817258883248731,
      "grad_norm": 18.460063934326172,
      "learning_rate": 4.061195713479978e-05,
      "loss": 0.0596,
      "step": 3330
    },
    {
      "epoch": 2.8257191201353637,
      "grad_norm": 2.5516769886016846,
      "learning_rate": 4.0583756345177665e-05,
      "loss": 0.1339,
      "step": 3340
    },
    {
      "epoch": 2.8341793570219966,
      "grad_norm": 20.99701690673828,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0503,
      "step": 3350
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 0.01821170188486576,
      "learning_rate": 4.052735476593345e-05,
      "loss": 0.0102,
      "step": 3360
    },
    {
      "epoch": 2.8510998307952624,
      "grad_norm": 29.11432647705078,
      "learning_rate": 4.0499153976311335e-05,
      "loss": 0.1441,
      "step": 3370
    },
    {
      "epoch": 2.859560067681895,
      "grad_norm": 1.1221740245819092,
      "learning_rate": 4.047095318668923e-05,
      "loss": 0.022,
      "step": 3380
    },
    {
      "epoch": 2.868020304568528,
      "grad_norm": 0.015179646201431751,
      "learning_rate": 4.044275239706712e-05,
      "loss": 0.0715,
      "step": 3390
    },
    {
      "epoch": 2.8764805414551606,
      "grad_norm": 0.0020357100293040276,
      "learning_rate": 4.041455160744501e-05,
      "loss": 0.1299,
      "step": 3400
    },
    {
      "epoch": 2.8849407783417935,
      "grad_norm": 27.842060089111328,
      "learning_rate": 4.03863508178229e-05,
      "loss": 0.0664,
      "step": 3410
    },
    {
      "epoch": 2.8934010152284264,
      "grad_norm": 30.183269500732422,
      "learning_rate": 4.035815002820079e-05,
      "loss": 0.1413,
      "step": 3420
    },
    {
      "epoch": 2.9018612521150593,
      "grad_norm": 1.3792476654052734,
      "learning_rate": 4.0329949238578684e-05,
      "loss": 0.1381,
      "step": 3430
    },
    {
      "epoch": 2.910321489001692,
      "grad_norm": 0.004442022647708654,
      "learning_rate": 4.030174844895657e-05,
      "loss": 0.0171,
      "step": 3440
    },
    {
      "epoch": 2.9187817258883246,
      "grad_norm": 0.0026549394242465496,
      "learning_rate": 4.0273547659334466e-05,
      "loss": 0.0504,
      "step": 3450
    },
    {
      "epoch": 2.927241962774958,
      "grad_norm": 0.006903315894305706,
      "learning_rate": 4.0245346869712354e-05,
      "loss": 0.0293,
      "step": 3460
    },
    {
      "epoch": 2.9357021996615904,
      "grad_norm": 0.5951646566390991,
      "learning_rate": 4.021714608009024e-05,
      "loss": 0.0402,
      "step": 3470
    },
    {
      "epoch": 2.9441624365482233,
      "grad_norm": 0.0016850599786266685,
      "learning_rate": 4.018894529046813e-05,
      "loss": 0.0009,
      "step": 3480
    },
    {
      "epoch": 2.952622673434856,
      "grad_norm": 0.008935854770243168,
      "learning_rate": 4.0160744500846025e-05,
      "loss": 0.0011,
      "step": 3490
    },
    {
      "epoch": 2.961082910321489,
      "grad_norm": 0.0024079226423054934,
      "learning_rate": 4.013254371122392e-05,
      "loss": 0.0292,
      "step": 3500
    },
    {
      "epoch": 2.969543147208122,
      "grad_norm": 0.02782033011317253,
      "learning_rate": 4.010434292160181e-05,
      "loss": 0.1153,
      "step": 3510
    },
    {
      "epoch": 2.9780033840947544,
      "grad_norm": 0.02952849119901657,
      "learning_rate": 4.00761421319797e-05,
      "loss": 0.0547,
      "step": 3520
    },
    {
      "epoch": 2.9864636209813877,
      "grad_norm": 0.009455189108848572,
      "learning_rate": 4.0047941342357584e-05,
      "loss": 0.0483,
      "step": 3530
    },
    {
      "epoch": 2.99492385786802,
      "grad_norm": 10.323859214782715,
      "learning_rate": 4.001974055273548e-05,
      "loss": 0.0318,
      "step": 3540
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9790740740740741,
      "eval_loss": 0.10689126700162888,
      "eval_runtime": 244.4295,
      "eval_samples_per_second": 22.092,
      "eval_steps_per_second": 2.762,
      "step": 3546
    }
  ],
  "logging_steps": 10,
  "max_steps": 17730,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.830021095960576e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
